start
Sun Feb 19 19:39:26 CET 2023
2023-02-19 19:39:27.837468: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-19 19:40:07,116 - modnet - INFO - Loaded <modnet.preprocessing.MODData object at 0x7f1e1de3afd0> object, created with modnet version 0.1.12
NAN values: 12054
NAN values remaining: 0
        AtomicOrbitals|HOMO_character  ...  BondFractions|B - B bond frac.
id                                     ...                                
0                                 3.0  ...                             0.0
1                                 3.0  ...                             0.0
2                                 2.0  ...                             0.0
3                                 2.0  ...                             0.0
4                                 2.0  ...                             0.0
...                               ...  ...                             ...
106108                            3.0  ...                             0.0
106109                            2.0  ...                             0.0
106110                            3.0  ...                             0.0
106111                            3.0  ...                             0.0
106112                            1.0  ...                             0.0

[106113 rows x 1336 columns]
[1.9 210 0.0008 256 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
2023-02-19 19:40:11.673358: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-19 19:40:12.139179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78935 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:81:00.0, compute capability: 8.0
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/210
2023-02-19 19:40:20.576315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-02-19 19:40:20.685111: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f1aac020e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-02-19 19:40:20.685136: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0
2023-02-19 19:40:20.928551: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-02-19 19:40:23.145238: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
374/374 - 13s - loss: 0.0382 - val_loss: 0.0212 - 13s/epoch - 35ms/step
Epoch 2/210
374/374 - 2s - loss: 0.0170 - val_loss: 0.0263 - 2s/epoch - 5ms/step
Epoch 3/210
374/374 - 2s - loss: 0.0152 - val_loss: 0.0182 - 2s/epoch - 5ms/step
Epoch 4/210
374/374 - 2s - loss: 0.0146 - val_loss: 0.0194 - 2s/epoch - 6ms/step
Epoch 5/210
374/374 - 2s - loss: 0.0140 - val_loss: 0.0174 - 2s/epoch - 5ms/step
Epoch 6/210
374/374 - 2s - loss: 0.0139 - val_loss: 0.0167 - 2s/epoch - 5ms/step
Epoch 7/210
374/374 - 2s - loss: 0.0134 - val_loss: 0.0179 - 2s/epoch - 5ms/step
Epoch 8/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0175 - 2s/epoch - 5ms/step
Epoch 9/210
374/374 - 2s - loss: 0.0125 - val_loss: 0.0325 - 2s/epoch - 5ms/step
Epoch 10/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0152 - 2s/epoch - 6ms/step
Epoch 11/210
374/374 - 2s - loss: 0.0121 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 12/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0179 - 2s/epoch - 5ms/step
Epoch 13/210
374/374 - 2s - loss: 0.0122 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 14/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 15/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0181 - 2s/epoch - 6ms/step
Epoch 16/210
374/374 - 2s - loss: 0.0124 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 17/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 18/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 19/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 20/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 21/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 22/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0119 - 2s/epoch - 6ms/step
Epoch 23/210
374/374 - 2s - loss: 0.0132 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 24/210
374/374 - 2s - loss: 0.0164 - val_loss: 0.0130 - 2s/epoch - 6ms/step
Epoch 25/210
374/374 - 2s - loss: 0.0340 - val_loss: 0.0147 - 2s/epoch - 5ms/step
Epoch 26/210
374/374 - 2s - loss: 0.0298 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 27/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 28/210
374/374 - 2s - loss: 0.0184 - val_loss: 0.0141 - 2s/epoch - 6ms/step
Epoch 29/210
374/374 - 2s - loss: 0.0271 - val_loss: 0.0131 - 2s/epoch - 6ms/step
Epoch 30/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 31/210
374/374 - 2s - loss: 0.0134 - val_loss: 0.0148 - 2s/epoch - 5ms/step
Epoch 32/210
374/374 - 2s - loss: 0.0352 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 33/210
374/374 - 2s - loss: 0.0146 - val_loss: 0.0148 - 2s/epoch - 6ms/step
Epoch 34/210
374/374 - 2s - loss: 0.0273 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 35/210
374/374 - 2s - loss: 0.0135 - val_loss: 0.0127 - 2s/epoch - 6ms/step
Epoch 36/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 37/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0121 - 2s/epoch - 6ms/step
Epoch 38/210
374/374 - 2s - loss: 0.0124 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 39/210
374/374 - 2s - loss: 0.0123 - val_loss: 0.0118 - 2s/epoch - 6ms/step
Epoch 40/210
374/374 - 2s - loss: 0.0121 - val_loss: 0.0117 - 2s/epoch - 6ms/step
Epoch 41/210
374/374 - 2s - loss: 0.0118 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 42/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 43/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 44/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0278 - 2s/epoch - 5ms/step
Epoch 45/210
374/374 - 2s - loss: 0.0250 - val_loss: 0.0124 - 2s/epoch - 6ms/step
Epoch 46/210
374/374 - 2s - loss: 0.0120 - val_loss: 0.0119 - 2s/epoch - 6ms/step
Epoch 47/210
374/374 - 2s - loss: 0.0123 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 48/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0142 - 2s/epoch - 6ms/step
Epoch 49/210
374/374 - 2s - loss: 0.0169 - val_loss: 0.0153 - 2s/epoch - 6ms/step
Epoch 50/210
374/374 - 2s - loss: 0.0218 - val_loss: 0.0131 - 2s/epoch - 6ms/step
Epoch 51/210
374/374 - 2s - loss: 0.0138 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 52/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 53/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 54/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 55/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 56/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 57/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 58/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 59/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 60/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0152 - 2s/epoch - 5ms/step
Epoch 61/210
374/374 - 2s - loss: 0.0166 - val_loss: 0.0144 - 2s/epoch - 5ms/step
Epoch 62/210
374/374 - 2s - loss: 0.0169 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 63/210
374/374 - 2s - loss: 0.0174 - val_loss: 0.0241 - 2s/epoch - 6ms/step
Epoch 64/210
374/374 - 2s - loss: 0.0363 - val_loss: 0.0190 - 2s/epoch - 5ms/step
Epoch 65/210
374/374 - 2s - loss: 0.0455 - val_loss: 0.0135 - 2s/epoch - 6ms/step
Epoch 66/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 67/210
374/374 - 2s - loss: 0.0123 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 68/210
374/374 - 2s - loss: 0.0119 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 69/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 70/210
374/374 - 2s - loss: 0.0116 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 71/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 72/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0112 - 2s/epoch - 6ms/step
Epoch 73/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 74/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 75/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 76/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 77/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 78/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 79/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 80/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 81/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 82/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 83/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 84/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 85/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 86/210
374/374 - 2s - loss: 0.0121 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 87/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 88/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0134 - 2s/epoch - 6ms/step
Epoch 89/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 90/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 91/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0132 - 2s/epoch - 6ms/step
Epoch 92/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 93/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 94/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 95/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 96/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 97/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0213 - 2s/epoch - 5ms/step
Epoch 98/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 99/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 100/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 101/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 102/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 103/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0139 - 2s/epoch - 6ms/step
Epoch 104/210
374/374 - 2s - loss: 0.0205 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 105/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 106/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 107/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 108/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0158 - 2s/epoch - 5ms/step
Epoch 109/210
374/374 - 2s - loss: 0.0152 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 110/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 111/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 112/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 113/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 114/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 115/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 116/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 117/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 118/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 119/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0121 - 2s/epoch - 6ms/step
Epoch 120/210
374/374 - 2s - loss: 0.0122 - val_loss: 0.0195 - 2s/epoch - 6ms/step
Epoch 121/210
374/374 - 2s - loss: 0.0173 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 122/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 123/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 124/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 125/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 126/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 127/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 128/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 129/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 130/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 131/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0202 - 2s/epoch - 6ms/step
Epoch 132/210
374/374 - 2s - loss: 0.0141 - val_loss: 0.0181 - 2s/epoch - 6ms/step
Epoch 133/210
374/374 - 2s - loss: 0.0295 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 134/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 135/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 136/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 137/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 138/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 139/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 140/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 141/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 142/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 143/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 144/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 145/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 146/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 147/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 148/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 149/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 150/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 151/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 152/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 153/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 154/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 155/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 156/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 157/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0176 - 2s/epoch - 6ms/step
Epoch 158/210
374/374 - 2s - loss: 0.0357 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 159/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 160/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 161/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 162/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 163/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 164/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 165/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 166/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 167/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 168/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 169/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 170/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 171/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 172/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 173/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 174/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 175/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 176/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 177/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 178/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0195 - 2s/epoch - 6ms/step
Epoch 179/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 180/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 181/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 182/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 183/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 184/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 185/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 186/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 187/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 188/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 189/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 190/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 191/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0193 - 2s/epoch - 6ms/step
Epoch 192/210
374/374 - 2s - loss: 0.0174 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 193/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 194/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 195/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 196/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 197/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0216 - 2s/epoch - 6ms/step
Epoch 198/210
374/374 - 2s - loss: 0.0147 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 199/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 200/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 201/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0226 - 2s/epoch - 6ms/step
Epoch 202/210
374/374 - 2s - loss: 0.0181 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 203/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 204/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 205/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 206/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 207/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 208/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0131 - 2s/epoch - 6ms/step
Epoch 209/210
374/374 - 2s - loss: 0.0138 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 210/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009751655161380768
  1/332 [..............................] - ETA: 49s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s227/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s317/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07846612299315399
cosine 0.061590764265756
MAE: 0.036593564
RMSE: 0.0803167
r2: 0.5815228989155964
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 256, 210, 0.0008, 0.2, 252, 0.009958836250007153, 0.009751655161380768, 0.07846612299315399, 0.061590764265756, 0.036593563854694366, 0.0803167000412941, 0.5815228989155964, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.001 64 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 10s - loss: 0.0137 - val_loss: 0.0118 - 10s/epoch - 7ms/step
Epoch 2/210
1493/1493 - 6s - loss: 0.0082 - val_loss: 0.0090 - 6s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 6s - loss: 0.0072 - val_loss: 0.0069 - 6s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 6s - loss: 0.0067 - val_loss: 0.0066 - 6s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 6s - loss: 0.0065 - val_loss: 0.0063 - 6s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 6s - loss: 0.0064 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 9/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 16/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 22/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 23/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 29/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 36/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 43/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 44/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 50/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 57/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 58/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 63/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 64/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 71/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 78/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 85/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 93/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 94/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 101/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 102/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 109/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 172/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 174/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 175/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 176/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 178/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 179/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 181/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 183/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 184/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 185/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 188/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 189/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 190/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 191/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 192/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005907947197556496
  1/332 [..............................] - ETA: 55s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s266/332 [=======================>......] - ETA: 0s303/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1143631673998263
cosine 0.08952352730364248
MAE: 0.044530947
RMSE: 0.0963436
r2: 0.39784834885188164
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'logcosh', 64, 210, 0.001, 0.2, 252, 0.0059533133171498775, 0.005907947197556496, 0.1143631673998263, 0.08952352730364248, 0.044530946761369705, 0.09634359925985336, 0.39784834885188164, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.0008 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/210
747/747 - 6s - loss: 0.0297 - val_loss: 0.0190 - 6s/epoch - 8ms/step
Epoch 2/210
747/747 - 3s - loss: 0.0156 - val_loss: 0.0255 - 3s/epoch - 5ms/step
Epoch 3/210
747/747 - 3s - loss: 0.0143 - val_loss: 0.0159 - 3s/epoch - 5ms/step
Epoch 4/210
747/747 - 3s - loss: 0.0135 - val_loss: 0.0174 - 3s/epoch - 5ms/step
Epoch 5/210
747/747 - 3s - loss: 0.0130 - val_loss: 0.0132 - 3s/epoch - 5ms/step
Epoch 6/210
747/747 - 3s - loss: 0.0122 - val_loss: 0.0118 - 3s/epoch - 5ms/step
Epoch 7/210
747/747 - 4s - loss: 0.0117 - val_loss: 0.0119 - 4s/epoch - 5ms/step
Epoch 8/210
747/747 - 4s - loss: 0.0115 - val_loss: 0.0118 - 4s/epoch - 5ms/step
Epoch 9/210
747/747 - 3s - loss: 0.0116 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 10/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 11/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 12/210
747/747 - 4s - loss: 0.0113 - val_loss: 0.0106 - 4s/epoch - 5ms/step
Epoch 13/210
747/747 - 4s - loss: 0.0111 - val_loss: 0.0120 - 4s/epoch - 5ms/step
Epoch 14/210
747/747 - 3s - loss: 0.0128 - val_loss: 0.0109 - 3s/epoch - 5ms/step
Epoch 15/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 16/210
747/747 - 4s - loss: 0.0108 - val_loss: 0.0113 - 4s/epoch - 5ms/step
Epoch 17/210
747/747 - 3s - loss: 0.0125 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 18/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0114 - 3s/epoch - 5ms/step
Epoch 19/210
747/747 - 3s - loss: 0.0126 - val_loss: 0.0123 - 3s/epoch - 5ms/step
Epoch 20/210
747/747 - 4s - loss: 0.0150 - val_loss: 0.0112 - 4s/epoch - 5ms/step
Epoch 21/210
747/747 - 4s - loss: 0.0119 - val_loss: 0.0108 - 4s/epoch - 5ms/step
Epoch 22/210
747/747 - 3s - loss: 0.0113 - val_loss: 0.0107 - 3s/epoch - 5ms/step
Epoch 23/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 24/210
747/747 - 4s - loss: 0.0114 - val_loss: 0.0107 - 4s/epoch - 5ms/step
Epoch 25/210
747/747 - 4s - loss: 0.0107 - val_loss: 0.0103 - 4s/epoch - 5ms/step
Epoch 26/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0104 - 3s/epoch - 5ms/step
Epoch 27/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 28/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 29/210
747/747 - 4s - loss: 0.0103 - val_loss: 0.0102 - 4s/epoch - 5ms/step
Epoch 30/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 31/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0108 - 3s/epoch - 5ms/step
Epoch 32/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 5ms/step
Epoch 33/210
747/747 - 4s - loss: 0.0102 - val_loss: 0.0127 - 4s/epoch - 5ms/step
Epoch 34/210
747/747 - 4s - loss: 0.0107 - val_loss: 0.0108 - 4s/epoch - 5ms/step
Epoch 35/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 36/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 37/210
747/747 - 4s - loss: 0.0101 - val_loss: 0.0101 - 4s/epoch - 5ms/step
Epoch 38/210
747/747 - 4s - loss: 0.0102 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 39/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 40/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 41/210
747/747 - 4s - loss: 0.0100 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 42/210
747/747 - 4s - loss: 0.0100 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 43/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0100 - 3s/epoch - 5ms/step
Epoch 44/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 45/210
747/747 - 4s - loss: 0.0099 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 46/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 47/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 48/210
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 49/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 50/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 51/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 52/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 53/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 54/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 55/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 56/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 57/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 58/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 59/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 60/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 61/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 62/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 63/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 64/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 65/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 66/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 67/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 68/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 69/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 70/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 71/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 72/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 73/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 74/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 75/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 76/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 77/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 78/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 79/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 80/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 81/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 82/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 83/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 84/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 85/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 86/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 87/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 88/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 89/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 90/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 91/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 92/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 93/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 94/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 95/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 96/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 97/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 98/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 99/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 100/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 101/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 102/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 103/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 104/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 105/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 106/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 107/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 108/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 109/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 110/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 111/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 112/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 113/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 114/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 115/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 116/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 117/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 118/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 119/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 120/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 121/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 122/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 123/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 124/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 125/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 126/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 127/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 128/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 129/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 130/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 131/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 132/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 133/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 134/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 135/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 136/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 137/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 138/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 139/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 140/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 141/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 142/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 143/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 144/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 145/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 146/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 147/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 148/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 149/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 150/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 151/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 152/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 153/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 154/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 155/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 156/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 157/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 158/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 159/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 160/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 161/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 162/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 163/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 164/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 165/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 166/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 167/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 168/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 169/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 170/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 171/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 172/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 173/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 174/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 175/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 176/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 177/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 178/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 179/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 180/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 181/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 182/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 183/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 184/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 185/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 186/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 187/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 188/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 189/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 190/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 191/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 192/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 193/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 194/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 195/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 196/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 197/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 198/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 199/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 200/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 201/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 202/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 203/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 204/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 205/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 206/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 207/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 208/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 209/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 210/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009218868799507618
  1/332 [..............................] - ETA: 54s 44/332 [==>...........................] - ETA: 0s  87/332 [======>.......................] - ETA: 0s131/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s215/332 [==================>...........] - ETA: 0s258/332 [======================>.......] - ETA: 0s302/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0718659490762546
cosine 0.056416510575185215
MAE: 0.035057932
RMSE: 0.07711774
r2: 0.6141943261242676
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'mse', 128, 210, 0.0008, 0.2, 252, 0.009373047389090061, 0.009218868799507618, 0.0718659490762546, 0.056416510575185215, 0.03505793213844299, 0.07711774110794067, 0.6141943261242676, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 210 0.0008 256 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE1.9_cr0.2_bs256_ep210_loss_mse_lr0.0008_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 52s 44/332 [==>...........................] - ETA: 0s  88/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s176/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s265/332 [======================>.......] - ETA: 0s308/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07846612299315399
cosine 0.061590764265756
MAE: 0.036593564
RMSE: 0.0803167
r2: 0.5815228989155964
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['1.9custom_VAE', 'mse', 256, 210, 0.0008, 0.2, 252, '--', '--', 0.07846612299315399, 0.061590764265756, 0.036593563854694366, 0.0803167000412941, 0.5815228989155964, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 205 0.001 64 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/205
1493/1493 - 9s - loss: 0.0259 - val_loss: 0.0326 - 9s/epoch - 6ms/step
Epoch 2/205
1493/1493 - 6s - loss: 0.0146 - val_loss: 0.0132 - 6s/epoch - 4ms/step
Epoch 3/205
1493/1493 - 6s - loss: 0.0128 - val_loss: 0.0123 - 6s/epoch - 4ms/step
Epoch 4/205
1493/1493 - 6s - loss: 0.0120 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/205
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0115 - 6s/epoch - 4ms/step
Epoch 6/205
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/205
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/205
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/205
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/205
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/205
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/205
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/205
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/205
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 20/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 24/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 29/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 30/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 31/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 32/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 34/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 37/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 38/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 39/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 40/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 41/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 42/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 43/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 44/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 46/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 52/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 53/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 54/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 55/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 56/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 57/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 59/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 60/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 64/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 79/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 80/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 81/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 84/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 86/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 99/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/205
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 127/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 131/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 134/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 135/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/205
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 147/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/205
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 159/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/205
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 161/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 197/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 200/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 202/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 204/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 205/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009229444898664951
  1/332 [..............................] - ETA: 54s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s141/332 [===========>..................] - ETA: 0s188/332 [===============>..............] - ETA: 0s235/332 [====================>.........] - ETA: 0s282/332 [========================>.....] - ETA: 0s329/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07101792198754328
cosine 0.055733971233148646
MAE: 0.034892622
RMSE: 0.07675916
r2: 0.6177738051573138
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'mse', 64, 205, 0.001, 0.2, 252, 0.009489858523011208, 0.009229444898664951, 0.07101792198754328, 0.055733971233148646, 0.034892622381448746, 0.07675915956497192, 0.6177738051573138, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 210 0.0008 128 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/210
747/747 - 8s - loss: 0.0310 - val_loss: 0.0179 - 8s/epoch - 10ms/step
Epoch 2/210
747/747 - 3s - loss: 0.0155 - val_loss: 0.0304 - 3s/epoch - 4ms/step
Epoch 3/210
747/747 - 3s - loss: 0.0145 - val_loss: 0.0160 - 3s/epoch - 4ms/step
Epoch 4/210
747/747 - 3s - loss: 0.0134 - val_loss: 0.0152 - 3s/epoch - 4ms/step
Epoch 5/210
747/747 - 3s - loss: 0.0126 - val_loss: 0.0126 - 3s/epoch - 4ms/step
Epoch 6/210
747/747 - 3s - loss: 0.0121 - val_loss: 0.0145 - 3s/epoch - 4ms/step
Epoch 7/210
747/747 - 3s - loss: 0.0119 - val_loss: 0.0133 - 3s/epoch - 4ms/step
Epoch 8/210
747/747 - 3s - loss: 0.0127 - val_loss: 0.0137 - 3s/epoch - 4ms/step
Epoch 9/210
747/747 - 3s - loss: 0.0132 - val_loss: 0.0596 - 3s/epoch - 4ms/step
Epoch 10/210
747/747 - 3s - loss: 0.0127 - val_loss: 0.0137 - 3s/epoch - 4ms/step
Epoch 11/210
747/747 - 3s - loss: 0.0154 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 12/210
747/747 - 3s - loss: 0.0122 - val_loss: 0.0280 - 3s/epoch - 4ms/step
Epoch 13/210
747/747 - 3s - loss: 0.0118 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 14/210
747/747 - 3s - loss: 0.0117 - val_loss: 0.0130 - 3s/epoch - 4ms/step
Epoch 15/210
747/747 - 3s - loss: 0.0118 - val_loss: 0.0130 - 3s/epoch - 4ms/step
Epoch 16/210
747/747 - 3s - loss: 0.0199 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 17/210
747/747 - 3s - loss: 0.0117 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 18/210
747/747 - 3s - loss: 0.0118 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 19/210
747/747 - 3s - loss: 0.0117 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 20/210
747/747 - 3s - loss: 0.0112 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 21/210
747/747 - 3s - loss: 0.0115 - val_loss: 0.0142 - 3s/epoch - 4ms/step
Epoch 22/210
747/747 - 3s - loss: 0.0189 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 23/210
747/747 - 3s - loss: 0.0123 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 24/210
747/747 - 3s - loss: 0.0115 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 25/210
747/747 - 3s - loss: 0.0111 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 26/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 27/210
747/747 - 3s - loss: 0.0108 - val_loss: 0.0122 - 3s/epoch - 4ms/step
Epoch 28/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 29/210
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 30/210
747/747 - 3s - loss: 0.0107 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 31/210
747/747 - 3s - loss: 0.0108 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 32/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0160 - 3s/epoch - 4ms/step
Epoch 33/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 34/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 35/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0136 - 3s/epoch - 4ms/step
Epoch 36/210
747/747 - 3s - loss: 0.0122 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 37/210
747/747 - 3s - loss: 0.0108 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 38/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 39/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 40/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 41/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 42/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 43/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 44/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 45/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 46/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 47/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0133 - 3s/epoch - 4ms/step
Epoch 48/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 49/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 50/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 51/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 52/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 53/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 54/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 55/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 56/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 57/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 58/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 59/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 60/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 61/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 62/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 63/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 64/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 65/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 66/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 67/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 68/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 69/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 70/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 71/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 72/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 73/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 75/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 76/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 77/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 78/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 79/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 80/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 81/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 82/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 83/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 84/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 85/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 86/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 87/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 89/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 90/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 92/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 94/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 95/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 96/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 97/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 98/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 100/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 101/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 102/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 104/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 105/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 106/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 107/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 108/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 109/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 110/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 111/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 112/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 113/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 114/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 115/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 116/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 117/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 118/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 119/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 120/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 121/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 122/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 123/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 124/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 127/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 142/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 147/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 152/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 153/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 154/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 155/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 156/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 157/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 158/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 159/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 160/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 161/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 162/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 163/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 164/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 165/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 166/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 167/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 168/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 169/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 170/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 171/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 172/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 173/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 174/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 175/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 176/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 177/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 178/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 179/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 180/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 181/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 182/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 183/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 184/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 185/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 186/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 187/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 188/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 189/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 190/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 191/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 192/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 193/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 195/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 196/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 197/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 198/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 199/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 200/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 201/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 202/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 203/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 204/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 205/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 206/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 207/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 208/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 209/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 210/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009243875741958618
  1/332 [..............................] - ETA: 46s 47/332 [===>..........................] - ETA: 0s  95/332 [=======>......................] - ETA: 0s142/332 [===========>..................] - ETA: 0s189/332 [================>.............] - ETA: 0s236/332 [====================>.........] - ETA: 0s283/332 [========================>.....] - ETA: 0s330/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07110044893187664
cosine 0.05584171738460115
MAE: 0.03487954
RMSE: 0.076710016
r2: 0.6182630380674905
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 128, 210, 0.0008, 0.2, 252, 0.009407483041286469, 0.009243875741958618, 0.07110044893187664, 0.05584171738460115, 0.03487953916192055, 0.07671001553535461, 0.6182630380674905, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 205 0.0008 64 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/205
1493/1493 - 8s - loss: 0.0253 - val_loss: 0.0173 - 8s/epoch - 5ms/step
Epoch 2/205
1493/1493 - 5s - loss: 0.0146 - val_loss: 0.0163 - 5s/epoch - 4ms/step
Epoch 3/205
1493/1493 - 5s - loss: 0.0133 - val_loss: 0.0120 - 5s/epoch - 4ms/step
Epoch 4/205
1493/1493 - 6s - loss: 0.0119 - val_loss: 0.0113 - 6s/epoch - 4ms/step
Epoch 5/205
1493/1493 - 6s - loss: 0.0116 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 6/205
1493/1493 - 5s - loss: 0.0114 - val_loss: 0.0110 - 5s/epoch - 4ms/step
Epoch 7/205
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/205
1493/1493 - 5s - loss: 0.0110 - val_loss: 0.0106 - 5s/epoch - 4ms/step
Epoch 9/205
1493/1493 - 5s - loss: 0.0109 - val_loss: 0.0105 - 5s/epoch - 4ms/step
Epoch 10/205
1493/1493 - 5s - loss: 0.0108 - val_loss: 0.0104 - 5s/epoch - 4ms/step
Epoch 11/205
1493/1493 - 5s - loss: 0.0106 - val_loss: 0.0103 - 5s/epoch - 4ms/step
Epoch 12/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/205
1493/1493 - 5s - loss: 0.0104 - val_loss: 0.0101 - 5s/epoch - 4ms/step
Epoch 15/205
1493/1493 - 5s - loss: 0.0103 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 16/205
1493/1493 - 5s - loss: 0.0103 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 17/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/205
1493/1493 - 5s - loss: 0.0102 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 19/205
1493/1493 - 5s - loss: 0.0102 - val_loss: 0.0099 - 5s/epoch - 4ms/step
Epoch 20/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/205
1493/1493 - 5s - loss: 0.0101 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 23/205
1493/1493 - 5s - loss: 0.0101 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 24/205
1493/1493 - 5s - loss: 0.0101 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 25/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/205
1493/1493 - 5s - loss: 0.0100 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 27/205
1493/1493 - 5s - loss: 0.0100 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 28/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/205
1493/1493 - 5s - loss: 0.0100 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 30/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 34/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 35/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 37/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 38/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 39/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 40/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 43/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 44/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 48/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 49/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 50/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 55/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 58/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 59/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 60/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 62/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 66/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 68/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 69/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 70/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 71/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 72/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 75/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 76/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 77/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 79/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 80/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 81/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 82/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 84/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 86/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 87/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 88/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 89/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 90/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 92/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 93/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 97/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 98/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 100/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 103/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 104/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 105/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 106/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 110/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 112/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 114/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 115/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 121/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 122/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 123/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 124/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 125/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 126/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 127/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 128/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 129/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 132/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 133/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 134/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 137/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 141/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 142/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 143/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 144/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 145/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 146/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 153/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 154/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 160/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 163/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 165/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 167/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 168/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 171/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 173/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 175/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 176/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 177/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 178/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 179/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 180/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 181/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 187/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 188/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 189/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 190/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 191/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 197/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 198/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 200/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 202/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 204/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 205/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009274642914533615
  1/332 [..............................] - ETA: 39s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s141/332 [===========>..................] - ETA: 0s188/332 [===============>..............] - ETA: 0s235/332 [====================>.........] - ETA: 0s281/332 [========================>.....] - ETA: 0s328/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07214032651072307
cosine 0.05663681499269653
MAE: 0.03521646
RMSE: 0.07727191
r2: 0.6126501701040995
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'mse', 64, 205, 0.0008, 0.2, 252, 0.009505624882876873, 0.009274642914533615, 0.07214032651072307, 0.05663681499269653, 0.03521645814180374, 0.07727190852165222, 0.6126501701040995, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_1.pkl
[1.9 210 0.001 128 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/210
747/747 - 6s - loss: 0.0301 - val_loss: 0.0197 - 6s/epoch - 8ms/step
Epoch 2/210
747/747 - 3s - loss: 0.0155 - val_loss: 0.0163 - 3s/epoch - 4ms/step
Epoch 3/210
747/747 - 3s - loss: 0.0140 - val_loss: 0.0151 - 3s/epoch - 4ms/step
Epoch 4/210
747/747 - 3s - loss: 0.0130 - val_loss: 0.0157 - 3s/epoch - 4ms/step
Epoch 5/210
747/747 - 3s - loss: 0.0124 - val_loss: 0.0126 - 3s/epoch - 4ms/step
Epoch 6/210
747/747 - 3s - loss: 0.0120 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 7/210
747/747 - 3s - loss: 0.0118 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 8/210
747/747 - 3s - loss: 0.0116 - val_loss: 0.0140 - 3s/epoch - 4ms/step
Epoch 9/210
747/747 - 3s - loss: 0.0117 - val_loss: 0.0114 - 3s/epoch - 5ms/step
Epoch 10/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 11/210
747/747 - 3s - loss: 0.0113 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 12/210
747/747 - 3s - loss: 0.0120 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 13/210
747/747 - 3s - loss: 0.0113 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 14/210
747/747 - 3s - loss: 0.0123 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 15/210
747/747 - 3s - loss: 0.0131 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 16/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 17/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 18/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 19/210
747/747 - 3s - loss: 0.0113 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 20/210
747/747 - 3s - loss: 0.0132 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 21/210
747/747 - 3s - loss: 0.0116 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 22/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 23/210
747/747 - 3s - loss: 0.0108 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 24/210
747/747 - 3s - loss: 0.0112 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 25/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 26/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 27/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 28/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 29/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 30/210
747/747 - 3s - loss: 0.0124 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 31/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 32/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 33/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 34/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 35/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 36/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 37/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 38/210
747/747 - 3s - loss: 0.0107 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 39/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 40/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 41/210
747/747 - 3s - loss: 0.0107 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 42/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 43/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 44/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 45/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 46/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 47/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 48/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 49/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 50/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 51/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 52/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 53/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 54/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 55/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 56/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 57/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 58/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 59/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 60/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 61/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 62/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 63/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 64/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 65/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 66/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 67/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 68/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 69/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 71/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 72/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 73/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 75/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 76/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 77/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 78/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 79/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 80/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 81/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 82/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 84/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 86/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 88/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 89/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 92/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 94/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 95/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 96/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 97/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 98/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 100/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 101/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 102/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 104/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 105/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 106/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 107/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 108/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 109/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 110/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 111/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 113/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 114/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 115/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 116/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 119/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 120/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 121/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 142/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 147/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 152/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 153/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 154/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 155/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 156/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 157/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 158/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 159/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 160/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 161/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 162/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 163/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 164/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 166/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 167/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 168/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 169/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 171/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 172/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 173/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 175/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 176/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 177/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 178/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 182/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 183/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 186/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 188/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 189/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 190/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 196/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 197/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 198/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 199/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 200/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 201/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 202/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 203/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 204/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 205/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 206/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 207/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 208/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 209/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 210/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009242471307516098
  1/332 [..............................] - ETA: 47s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s221/332 [==================>...........] - ETA: 0s264/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07102422039889858
cosine 0.05575143432127409
MAE: 0.034774262
RMSE: 0.07668467
r2: 0.618515267746678
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 128, 210, 0.001, 0.2, 252, 0.009394129738211632, 0.009242471307516098, 0.07102422039889858, 0.05575143432127409, 0.034774262458086014, 0.07668466866016388, 0.618515267746678, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.001 128 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE2.0_cr0.2_bs128_ep210_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 43s 39/332 [==>...........................] - ETA: 0s  83/332 [======>.......................] - ETA: 0s128/332 [==========>...................] - ETA: 0s174/332 [==============>...............] - ETA: 0s219/332 [==================>...........] - ETA: 0s265/332 [======================>.......] - ETA: 0s310/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07199157431828405
cosine 0.056547287777150484
MAE: 0.035177678
RMSE: 0.077130355
r2: 0.6140680360952954
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['2.0custom_VAE', 'mse', 128, 210, 0.001, 0.2, 252, '--', '--', 0.07199157431828405, 0.056547287777150484, 0.03517767786979675, 0.07713035494089127, 0.6140680360952954, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 210 0.0008 64 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 9s - loss: 0.0258 - val_loss: 0.0205 - 9s/epoch - 6ms/step
Epoch 2/210
1493/1493 - 6s - loss: 0.0148 - val_loss: 0.0138 - 6s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 6s - loss: 0.0130 - val_loss: 0.0121 - 6s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0113 - 6s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 6s - loss: 0.0115 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/210
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009278226643800735
  1/332 [..............................] - ETA: 39s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s177/332 [==============>...............] - ETA: 0s222/332 [===================>..........] - ETA: 0s268/332 [=======================>......] - ETA: 0s315/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07219990629027395
cosine 0.05669087781530482
MAE: 0.035192654
RMSE: 0.07735594
r2: 0.6118072694723254
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 64, 210, 0.0008, 0.2, 252, 0.009512444026768208, 0.009278226643800735, 0.07219990629027395, 0.05669087781530482, 0.03519265353679657, 0.07735594362020493, 0.6118072694723254, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 210 0.0008 128 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/210
747/747 - 6s - loss: 0.0160 - val_loss: 0.0094 - 6s/epoch - 7ms/step
Epoch 2/210
747/747 - 3s - loss: 0.0082 - val_loss: 0.0182 - 3s/epoch - 4ms/step
Epoch 3/210
747/747 - 3s - loss: 0.0077 - val_loss: 0.0283 - 3s/epoch - 4ms/step
Epoch 4/210
747/747 - 3s - loss: 0.0073 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 5/210
747/747 - 3s - loss: 0.0068 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 6/210
747/747 - 3s - loss: 0.0066 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 7/210
747/747 - 3s - loss: 0.0065 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 8/210
747/747 - 3s - loss: 0.0066 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0068 - 3s/epoch - 4ms/step
Epoch 10/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 11/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 14/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/210
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 16/210
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 21/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 25/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 26/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 27/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 29/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 39/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 41/210
747/747 - 3s - loss: 0.0063 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/210
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 45/210
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 73/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/210
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 186/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 189/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 191/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 194/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 195/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 196/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 197/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 198/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 199/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 200/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 201/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 202/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 203/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 204/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 205/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 206/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 207/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 208/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 209/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 210/210
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005885124672204256
  1/332 [..............................] - ETA: 39s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s269/332 [=======================>......] - ETA: 0s315/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11517323142979849
cosine 0.09009876453534998
MAE: 0.044606153
RMSE: 0.09664529
r2: 0.3940712578830644
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'logcosh', 128, 210, 0.0008, 0.2, 252, 0.005925987847149372, 0.005885124672204256, 0.11517323142979849, 0.09009876453534998, 0.044606152921915054, 0.096645288169384, 0.3940712578830644, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 210 0.001 64 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 8s - loss: 0.0262 - val_loss: 0.0179 - 8s/epoch - 5ms/step
Epoch 2/210
1493/1493 - 5s - loss: 0.0149 - val_loss: 0.0145 - 5s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 6s - loss: 0.0128 - val_loss: 0.0120 - 6s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 5s - loss: 0.0120 - val_loss: 0.0116 - 5s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 5s - loss: 0.0117 - val_loss: 0.0113 - 5s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 5s - loss: 0.0116 - val_loss: 0.0110 - 5s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 9/210
1493/1493 - 6s - loss: 0.0120 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 5s - loss: 0.0110 - val_loss: 0.0107 - 5s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 5s - loss: 0.0109 - val_loss: 0.0110 - 5s/epoch - 4ms/step
Epoch 16/210
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 22/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 23/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 29/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 57/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 85/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 176/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 183/210
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 5ms/step
Epoch 184/210
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0094 - 7s/epoch - 5ms/step
Epoch 185/210
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009295383468270302
  1/332 [..............................] - ETA: 59s 46/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s231/332 [===================>..........] - ETA: 0s278/332 [========================>.....] - ETA: 0s321/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07240670401556645
cosine 0.05687491215493065
MAE: 0.035225715
RMSE: 0.07741621
r2: 0.6112021485358768
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 64, 210, 0.001, 0.2, 252, 0.009502703323960304, 0.009295383468270302, 0.07240670401556645, 0.05687491215493065, 0.03522571548819542, 0.07741621136665344, 0.6112021485358768, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 210 0.0008 64 2] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 11s - loss: 0.0131 - val_loss: 0.0097 - 11s/epoch - 8ms/step
Epoch 2/210
1493/1493 - 7s - loss: 0.0080 - val_loss: 0.0095 - 7s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 7s - loss: 0.0072 - val_loss: 0.0072 - 7s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 6s - loss: 0.0067 - val_loss: 0.0065 - 6s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 7s - loss: 0.0065 - val_loss: 0.0063 - 7s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 6s - loss: 0.0064 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 7s - loss: 0.0063 - val_loss: 0.0062 - 7s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 7s - loss: 0.0063 - val_loss: 0.0062 - 7s/epoch - 5ms/step
Epoch 9/210
1493/1493 - 7s - loss: 0.0063 - val_loss: 0.0062 - 7s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 7s - loss: 0.0062 - val_loss: 0.0061 - 7s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 7s - loss: 0.0062 - val_loss: 0.0062 - 7s/epoch - 5ms/step
Epoch 16/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 7s - loss: 0.0062 - val_loss: 0.0061 - 7s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 7s - loss: 0.0062 - val_loss: 0.0061 - 7s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 7s - loss: 0.0062 - val_loss: 0.0061 - 7s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0061 - 7s/epoch - 5ms/step
Epoch 22/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0061 - 7s/epoch - 5ms/step
Epoch 23/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 5ms/step
Epoch 29/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 5ms/step
Epoch 36/210
1493/1493 - 7s - loss: 0.0061 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 5ms/step
Epoch 43/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 5ms/step
Epoch 44/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 50/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0060 - 7s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 57/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 58/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 63/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 64/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 71/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 78/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 85/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 93/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 94/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 101/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 102/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 5ms/step
Epoch 109/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 7s - loss: 0.0060 - val_loss: 0.0059 - 7s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 172/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 174/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 175/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 176/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 178/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 179/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 181/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 183/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 184/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 185/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 188/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 189/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 190/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 191/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 192/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058949189260602
  1/332 [..............................] - ETA: 42s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s117/332 [=========>....................] - ETA: 0s163/332 [=============>................] - ETA: 0s209/332 [=================>............] - ETA: 0s255/332 [======================>.......] - ETA: 0s301/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1139102500736646
cosine 0.08915758259872468
MAE: 0.044404685
RMSE: 0.09614661
r2: 0.4003081136149173
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 64, 210, 0.0008, 0.2, 252, 0.005946216639131308, 0.0058949189260602, 0.1139102500736646, 0.08915758259872468, 0.044404685497283936, 0.0961466133594513, 0.4003081136149173, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_2.pkl
[2.0 210 0.0008 64 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 8s - loss: 0.0136 - val_loss: 0.0102 - 8s/epoch - 5ms/step
Epoch 2/210
1493/1493 - 5s - loss: 0.0083 - val_loss: 0.0107 - 5s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 5s - loss: 0.0072 - val_loss: 0.0069 - 5s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 5s - loss: 0.0066 - val_loss: 0.0064 - 5s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 5s - loss: 0.0064 - val_loss: 0.0063 - 5s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 5s - loss: 0.0064 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 9/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 16/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 22/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 23/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 29/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 36/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 43/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 44/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 50/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 57/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 58/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 63/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 64/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 71/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 78/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 85/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 93/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 94/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 101/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 102/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 109/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 172/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 174/210
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 175/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 176/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 178/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 179/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 181/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 183/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 184/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 185/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 188/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 189/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 190/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 191/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 3ms/step
Epoch 192/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005892385728657246
  1/332 [..............................] - ETA: 38s 49/332 [===>..........................] - ETA: 0s  97/332 [=======>......................] - ETA: 0s143/332 [===========>..................] - ETA: 0s189/332 [================>.............] - ETA: 0s237/332 [====================>.........] - ETA: 0s286/332 [========================>.....] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11498384923585352
cosine 0.09000107178115593
MAE: 0.04450844
RMSE: 0.09651927
r2: 0.3956504271683907
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'logcosh', 64, 210, 0.0008, 0.2, 252, 0.005944235250353813, 0.005892385728657246, 0.11498384923585352, 0.09000107178115593, 0.0445084385573864, 0.09651926904916763, 0.3956504271683907, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 205 0.001 64 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/205
1493/1493 - 8s - loss: 0.0257 - val_loss: 0.0178 - 8s/epoch - 6ms/step
Epoch 2/205
1493/1493 - 5s - loss: 0.0149 - val_loss: 0.0138 - 5s/epoch - 4ms/step
Epoch 3/205
1493/1493 - 5s - loss: 0.0129 - val_loss: 0.0122 - 5s/epoch - 4ms/step
Epoch 4/205
1493/1493 - 5s - loss: 0.0120 - val_loss: 0.0114 - 5s/epoch - 4ms/step
Epoch 5/205
1493/1493 - 5s - loss: 0.0115 - val_loss: 0.0113 - 5s/epoch - 4ms/step
Epoch 6/205
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/205
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 8/205
1493/1493 - 5s - loss: 0.0110 - val_loss: 0.0107 - 5s/epoch - 4ms/step
Epoch 9/205
1493/1493 - 5s - loss: 0.0108 - val_loss: 0.0105 - 5s/epoch - 4ms/step
Epoch 10/205
1493/1493 - 5s - loss: 0.0107 - val_loss: 0.0104 - 5s/epoch - 4ms/step
Epoch 11/205
1493/1493 - 5s - loss: 0.0106 - val_loss: 0.0104 - 5s/epoch - 4ms/step
Epoch 12/205
1493/1493 - 5s - loss: 0.0106 - val_loss: 0.0103 - 5s/epoch - 4ms/step
Epoch 13/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/205
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/205
1493/1493 - 5s - loss: 0.0104 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 16/205
1493/1493 - 5s - loss: 0.0103 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 17/205
1493/1493 - 5s - loss: 0.0103 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 18/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/205
1493/1493 - 5s - loss: 0.0102 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 20/205
1493/1493 - 5s - loss: 0.0102 - val_loss: 0.0099 - 5s/epoch - 4ms/step
Epoch 21/205
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 24/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/205
1493/1493 - 5s - loss: 0.0100 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 27/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/205
1493/1493 - 5s - loss: 0.0100 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 30/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 32/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 33/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 34/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0097 - 5s/epoch - 4ms/step
Epoch 35/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 36/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 37/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 38/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 39/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 40/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 44/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 45/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 46/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 47/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 52/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 54/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 55/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 58/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 64/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 65/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 66/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 67/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 69/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 75/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 76/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 78/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 84/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 85/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 86/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 87/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 88/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 89/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 94/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 96/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 98/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 99/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 105/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 106/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 107/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 109/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 115/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 116/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 117/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 118/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 126/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 127/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 128/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 134/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 135/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 136/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 137/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 138/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 139/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 144/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 145/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 146/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 147/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 148/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 149/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 156/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 157/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 158/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 159/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 160/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 175/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 176/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 184/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 185/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 186/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 195/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 197/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 200/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 202/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 204/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 205/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00926279928535223
  1/332 [..............................] - ETA: 38s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s222/332 [===================>..........] - ETA: 0s267/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07223331451955221
cosine 0.05671266534060655
MAE: 0.0351436
RMSE: 0.07731495
r2: 0.6122185716474359
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 64, 205, 0.001, 0.2, 252, 0.009489242918789387, 0.00926279928535223, 0.07223331451955221, 0.05671266534060655, 0.03514359891414642, 0.07731495052576065, 0.6122185716474359, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.0008 64 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE2.0_cr0.2_bs64_ep210_loss_logcosh_lr0.0008_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 38s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s141/332 [===========>..................] - ETA: 0s188/332 [===============>..............] - ETA: 0s235/332 [====================>.........] - ETA: 0s282/332 [========================>.....] - ETA: 0s329/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11498384923585352
cosine 0.09000107178115593
MAE: 0.04450844
RMSE: 0.09651927
r2: 0.3956504271683907
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['2.0custom_VAE', 'logcosh', 64, 210, 0.0008, 0.2, 252, '--', '--', 0.11498384923585352, 0.09000107178115593, 0.0445084385573864, 0.09651926904916763, 0.3956504271683907, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 205 0.001 256 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 5s - loss: 0.0391 - val_loss: 0.0190 - 5s/epoch - 14ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0173 - val_loss: 0.0214 - 2s/epoch - 5ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0154 - val_loss: 0.0230 - 2s/epoch - 5ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0149 - val_loss: 0.0184 - 2s/epoch - 5ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0211 - 2s/epoch - 5ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0138 - val_loss: 0.0162 - 2s/epoch - 5ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0135 - val_loss: 0.0147 - 2s/epoch - 5ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0132 - val_loss: 0.0160 - 2s/epoch - 5ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0133 - 2s/epoch - 5ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0192 - 2s/epoch - 5ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0131 - 2s/epoch - 5ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0191 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0175 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0159 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0124 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0134 - val_loss: 0.0142 - 2s/epoch - 5ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0236 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0150 - val_loss: 0.0232 - 2s/epoch - 5ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0450 - val_loss: 0.0164 - 2s/epoch - 5ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0267 - val_loss: 0.0141 - 2s/epoch - 5ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0132 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0134 - 2s/epoch - 5ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0169 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0142 - 2s/epoch - 5ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0170 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0131 - 2s/epoch - 5ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0125 - val_loss: 0.0238 - 2s/epoch - 5ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0500 - val_loss: 0.0215 - 2s/epoch - 5ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0485 - val_loss: 0.0147 - 2s/epoch - 5ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0137 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0172 - 2s/epoch - 5ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0409 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0134 - 2s/epoch - 5ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0139 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0165 - 2s/epoch - 5ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0215 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0165 - 2s/epoch - 5ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0222 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0162 - 2s/epoch - 5ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0204 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0135 - 2s/epoch - 5ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0166 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0179 - 2s/epoch - 5ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0171 - 2s/epoch - 5ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0125 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009347660467028618
  1/332 [..............................] - ETA: 42s 45/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s181/332 [===============>..............] - ETA: 0s226/332 [===================>..........] - ETA: 0s271/332 [=======================>......] - ETA: 0s312/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07384049301546473
cosine 0.057927667021841274
MAE: 0.03571328
RMSE: 0.07811065
r2: 0.6041957212528319
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 256, 205, 0.001, 0.2, 252, 0.009445936419069767, 0.009347660467028618, 0.07384049301546473, 0.057927667021841274, 0.035713281482458115, 0.07811065018177032, 0.6041957212528319, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_3.pkl
[1.7999999999999998 205 0.0006000000000000001 256 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 8s - loss: 0.0390 - val_loss: 0.0219 - 8s/epoch - 21ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0166 - val_loss: 0.0252 - 2s/epoch - 5ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0156 - val_loss: 0.0212 - 2s/epoch - 5ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0151 - val_loss: 0.0182 - 2s/epoch - 5ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0144 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0139 - val_loss: 0.0163 - 2s/epoch - 5ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0136 - val_loss: 0.0208 - 2s/epoch - 5ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0138 - val_loss: 0.0160 - 2s/epoch - 5ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0864 - 2s/epoch - 6ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0143 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0156 - 2s/epoch - 5ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0351 - 2s/epoch - 6ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0166 - 2s/epoch - 5ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0234 - 2s/epoch - 5ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0144 - 2s/epoch - 5ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0158 - 2s/epoch - 5ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0172 - 2s/epoch - 5ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0144 - val_loss: 0.0200 - 2s/epoch - 5ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0251 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0137 - 2s/epoch - 6ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0140 - val_loss: 0.0111 - 2s/epoch - 6ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0180 - 2s/epoch - 5ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0276 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0292 - val_loss: 0.0238 - 2s/epoch - 5ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0930 - val_loss: 0.0176 - 2s/epoch - 6ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0188 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0139 - val_loss: 0.0152 - 2s/epoch - 5ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0187 - val_loss: 0.0132 - 2s/epoch - 5ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0129 - 2s/epoch - 5ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0135 - val_loss: 0.0192 - 2s/epoch - 5ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0405 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0136 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0119 - 2s/epoch - 6ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0142 - 2s/epoch - 5ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0129 - 2s/epoch - 6ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0178 - 2s/epoch - 6ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0200 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0135 - 2s/epoch - 6ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0125 - val_loss: 0.0229 - 2s/epoch - 5ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0280 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0139 - 2s/epoch - 6ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0155 - 2s/epoch - 5ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0150 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0125 - 2s/epoch - 6ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00918230228126049
  1/332 [..............................] - ETA: 43s 43/332 [==>...........................] - ETA: 0s  86/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07054500573318588
cosine 0.05540412366727231
MAE: 0.034724314
RMSE: 0.076410554
r2: 0.6212376494414618
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 205, 0.0006000000000000001, 0.2, 252, 0.009269635193049908, 0.00918230228126049, 0.07054500573318588, 0.05540412366727231, 0.034724313765764236, 0.07641055434942245, 0.6212376494414618, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 205 0.001 128 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/205
747/747 - 6s - loss: 0.0169 - val_loss: 0.0120 - 6s/epoch - 8ms/step
Epoch 2/205
747/747 - 3s - loss: 0.0090 - val_loss: 0.0135 - 3s/epoch - 4ms/step
Epoch 3/205
747/747 - 3s - loss: 0.0082 - val_loss: 0.0088 - 3s/epoch - 4ms/step
Epoch 4/205
747/747 - 3s - loss: 0.0077 - val_loss: 0.0182 - 3s/epoch - 4ms/step
Epoch 5/205
747/747 - 3s - loss: 0.0072 - val_loss: 0.0075 - 3s/epoch - 4ms/step
Epoch 6/205
747/747 - 3s - loss: 0.0068 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 7/205
747/747 - 3s - loss: 0.0066 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 8/205
747/747 - 3s - loss: 0.0065 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 9/205
747/747 - 3s - loss: 0.0065 - val_loss: 0.1009 - 3s/epoch - 5ms/step
Epoch 10/205
747/747 - 3s - loss: 0.0079 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/205
747/747 - 3s - loss: 0.0063 - val_loss: 0.0163 - 3s/epoch - 4ms/step
Epoch 12/205
747/747 - 3s - loss: 0.0070 - val_loss: 0.0196 - 3s/epoch - 4ms/step
Epoch 13/205
747/747 - 3s - loss: 0.0077 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 14/205
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/205
747/747 - 3s - loss: 0.0063 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 16/205
747/747 - 3s - loss: 0.0067 - val_loss: 0.0083 - 3s/epoch - 4ms/step
Epoch 17/205
747/747 - 3s - loss: 0.0069 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/205
747/747 - 3s - loss: 0.0062 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 19/205
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/205
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 21/205
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 22/205
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 23/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 25/205
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 26/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 29/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 31/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 32/205
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 33/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 41/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 43/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/205
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 50/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 51/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/205
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 61/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 62/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 70/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 71/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 72/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 80/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/205
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 82/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 90/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 91/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/205
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 103/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/205
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 186/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 189/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 191/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 194/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 195/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 196/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 197/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 198/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 199/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 200/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 201/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 202/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 203/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 204/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 205/205
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005870512221008539
  1/332 [..............................] - ETA: 45s 42/332 [==>...........................] - ETA: 0s  86/332 [======>.......................] - ETA: 0s131/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s219/332 [==================>...........] - ETA: 0s264/332 [======================>.......] - ETA: 0s309/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11557963785644841
cosine 0.09038406754276952
MAE: 0.044620864
RMSE: 0.09680003
r2: 0.39212937648713947
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'logcosh', 128, 205, 0.001, 0.2, 252, 0.005917628761380911, 0.005870512221008539, 0.11557963785644841, 0.09038406754276952, 0.04462086409330368, 0.09680002927780151, 0.39212937648713947, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.1 200 0.0008 256 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2654)         3357310     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2654)        10616       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2654)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          669060      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4102762     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,808,808
Trainable params: 8,797,688
Non-trainable params: 11,120
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 4s - loss: 0.0391 - val_loss: 0.0210 - 4s/epoch - 12ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0164 - val_loss: 0.0231 - 2s/epoch - 5ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0149 - val_loss: 0.0529 - 2s/epoch - 4ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0158 - val_loss: 0.0171 - 2s/epoch - 4ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0138 - val_loss: 0.0158 - 2s/epoch - 4ms/step
Epoch 6/200
374/374 - 1s - loss: 0.0135 - val_loss: 0.0172 - 1s/epoch - 4ms/step
Epoch 7/200
374/374 - 1s - loss: 0.0132 - val_loss: 0.0137 - 1s/epoch - 4ms/step
Epoch 8/200
374/374 - 1s - loss: 0.0125 - val_loss: 0.0164 - 1s/epoch - 4ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 10/200
374/374 - 1s - loss: 0.0120 - val_loss: 0.2635 - 1s/epoch - 4ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0170 - val_loss: 0.0216 - 2s/epoch - 4ms/step
Epoch 12/200
374/374 - 1s - loss: 0.0141 - val_loss: 0.0121 - 1s/epoch - 4ms/step
Epoch 13/200
374/374 - 1s - loss: 0.0118 - val_loss: 0.0182 - 1s/epoch - 4ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 15/200
374/374 - 1s - loss: 0.0118 - val_loss: 0.0160 - 1s/epoch - 4ms/step
Epoch 16/200
374/374 - 1s - loss: 0.0127 - val_loss: 0.0111 - 1s/epoch - 4ms/step
Epoch 17/200
374/374 - 1s - loss: 0.0112 - val_loss: 0.0112 - 1s/epoch - 4ms/step
Epoch 18/200
374/374 - 1s - loss: 0.0112 - val_loss: 0.0109 - 1s/epoch - 4ms/step
Epoch 19/200
374/374 - 1s - loss: 0.0109 - val_loss: 0.0113 - 1s/epoch - 4ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 21/200
374/374 - 1s - loss: 0.0132 - val_loss: 0.0121 - 1s/epoch - 4ms/step
Epoch 22/200
374/374 - 1s - loss: 0.0141 - val_loss: 0.0112 - 1s/epoch - 4ms/step
Epoch 23/200
374/374 - 1s - loss: 0.0117 - val_loss: 0.0120 - 1s/epoch - 4ms/step
Epoch 24/200
374/374 - 1s - loss: 0.0149 - val_loss: 0.0113 - 1s/epoch - 4ms/step
Epoch 25/200
374/374 - 1s - loss: 0.0112 - val_loss: 0.0115 - 1s/epoch - 4ms/step
Epoch 26/200
374/374 - 1s - loss: 0.0124 - val_loss: 0.0115 - 1s/epoch - 4ms/step
Epoch 27/200
374/374 - 1s - loss: 0.0118 - val_loss: 0.0114 - 1s/epoch - 4ms/step
Epoch 28/200
374/374 - 1s - loss: 0.0121 - val_loss: 0.0108 - 1s/epoch - 4ms/step
Epoch 29/200
374/374 - 1s - loss: 0.0109 - val_loss: 0.0106 - 1s/epoch - 4ms/step
Epoch 30/200
374/374 - 1s - loss: 0.0108 - val_loss: 0.0109 - 1s/epoch - 4ms/step
Epoch 31/200
374/374 - 1s - loss: 0.0119 - val_loss: 0.0116 - 1s/epoch - 4ms/step
Epoch 32/200
374/374 - 1s - loss: 0.0141 - val_loss: 0.0109 - 1s/epoch - 4ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 35/200
374/374 - 1s - loss: 0.0141 - val_loss: 0.0119 - 1s/epoch - 4ms/step
Epoch 36/200
374/374 - 1s - loss: 0.0141 - val_loss: 0.0109 - 1s/epoch - 4ms/step
Epoch 37/200
374/374 - 1s - loss: 0.0110 - val_loss: 0.0107 - 1s/epoch - 4ms/step
Epoch 38/200
374/374 - 1s - loss: 0.0108 - val_loss: 0.0111 - 1s/epoch - 4ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 41/200
374/374 - 1s - loss: 0.0106 - val_loss: 0.0104 - 1s/epoch - 4ms/step
Epoch 42/200
374/374 - 1s - loss: 0.0105 - val_loss: 0.0104 - 1s/epoch - 4ms/step
Epoch 43/200
374/374 - 1s - loss: 0.0105 - val_loss: 0.0126 - 1s/epoch - 4ms/step
Epoch 44/200
374/374 - 1s - loss: 0.0137 - val_loss: 0.0120 - 1s/epoch - 4ms/step
Epoch 45/200
374/374 - 1s - loss: 0.0129 - val_loss: 0.0107 - 1s/epoch - 4ms/step
Epoch 46/200
374/374 - 1s - loss: 0.0109 - val_loss: 0.0105 - 1s/epoch - 4ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0126 - 2s/epoch - 4ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0162 - val_loss: 0.0134 - 2s/epoch - 4ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0147 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0308 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0152 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0191 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0200 - 2s/epoch - 5ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0219 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0135 - 2s/epoch - 4ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0205 - 2s/epoch - 5ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0180 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0176 - 2s/epoch - 5ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0132 - 2s/epoch - 5ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0129 - 2s/epoch - 4ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009342235513031483
  1/332 [..............................] - ETA: 52s 41/332 [==>...........................] - ETA: 0s  85/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s263/332 [======================>.......] - ETA: 0s309/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07419184033955173
cosine 0.058221418510236427
MAE: 0.03589724
RMSE: 0.0782846
r2: 0.6024309279513124
RMSE zero-vector: 0.23411466903540806
['2.1custom_VAE', 'mse', 256, 200, 0.0008, 0.2, 252, 0.009474474005401134, 0.009342235513031483, 0.07419184033955173, 0.058221418510236427, 0.03589724004268646, 0.0782845988869667, 0.6024309279513124, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.2 205 0.001 64 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2780)         3516700     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2780)        11120       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2780)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          700812      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          700812      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         4294408     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 9,223,852
Trainable params: 9,212,228
Non-trainable params: 11,624
__________________________________________________________________________________________________
Epoch 1/205
1493/1493 - 12s - loss: 0.0260 - val_loss: 0.0220 - 12s/epoch - 8ms/step
Epoch 2/205
1493/1493 - 6s - loss: 0.0149 - val_loss: 0.0140 - 6s/epoch - 4ms/step
Epoch 3/205
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0123 - 6s/epoch - 4ms/step
Epoch 4/205
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0117 - 6s/epoch - 4ms/step
Epoch 5/205
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0114 - 6s/epoch - 4ms/step
Epoch 6/205
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/205
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/205
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 9/205
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/205
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 11/205
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/205
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/205
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 14/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 15/205
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 16/205
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 17/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/205
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/205
1493/1493 - 5s - loss: 0.0103 - val_loss: 0.0100 - 5s/epoch - 4ms/step
Epoch 20/205
1493/1493 - 5s - loss: 0.0102 - val_loss: 0.0099 - 5s/epoch - 4ms/step
Epoch 21/205
1493/1493 - 5s - loss: 0.0101 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 22/205
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/205
1493/1493 - 5s - loss: 0.0101 - val_loss: 0.0098 - 5s/epoch - 4ms/step
Epoch 24/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/205
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 36/205
1493/1493 - 5s - loss: 0.0099 - val_loss: 0.0096 - 5s/epoch - 4ms/step
Epoch 37/205
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 45/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 49/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/205
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/205
1493/1493 - 5s - loss: 0.0098 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 52/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0095 - 5s/epoch - 4ms/step
Epoch 53/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 61/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/205
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 65/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/205
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 77/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 79/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 80/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 81/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 82/205
1493/1493 - 5s - loss: 0.0096 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 83/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 92/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 97/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 109/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/205
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 137/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 138/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 139/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 140/205
1493/1493 - 5s - loss: 0.0095 - val_loss: 0.0093 - 5s/epoch - 4ms/step
Epoch 141/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 155/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 167/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 169/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 171/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 178/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 180/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 183/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 184/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 187/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 188/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 189/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 190/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 191/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 192/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 195/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 196/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 197/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 199/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 200/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 201/205
1493/1493 - 6s - loss: 0.0094 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 202/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 203/205
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 204/205
1493/1493 - 6s - loss: 0.0094 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 205/205
1493/1493 - 6s - loss: 0.0094 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009242843836545944
  1/332 [..............................] - ETA: 52s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s177/332 [==============>...............] - ETA: 0s222/332 [===================>..........] - ETA: 0s257/332 [======================>.......] - ETA: 0s301/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07005881136469333
cosine 0.05502212292465946
MAE: 0.03474535
RMSE: 0.07624047
r2: 0.6229221499615102
RMSE zero-vector: 0.23411466903540806
['2.2custom_VAE', 'mse', 64, 205, 0.001, 0.2, 252, 0.009443104267120361, 0.009242843836545944, 0.07005881136469333, 0.05502212292465946, 0.03474535048007965, 0.07624047249555588, 0.6229221499615102, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_4.pkl
[1.9 205 0.0006000000000000001 128 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/205
747/747 - 6s - loss: 0.0301 - val_loss: 0.0190 - 6s/epoch - 8ms/step
Epoch 2/205
747/747 - 3s - loss: 0.0157 - val_loss: 0.0190 - 3s/epoch - 4ms/step
Epoch 3/205
747/747 - 3s - loss: 0.0148 - val_loss: 0.0182 - 3s/epoch - 4ms/step
Epoch 4/205
747/747 - 3s - loss: 0.0139 - val_loss: 0.0183 - 3s/epoch - 4ms/step
Epoch 5/205
747/747 - 3s - loss: 0.0129 - val_loss: 0.0135 - 3s/epoch - 4ms/step
Epoch 6/205
747/747 - 3s - loss: 0.0122 - val_loss: 0.0739 - 3s/epoch - 4ms/step
Epoch 7/205
747/747 - 3s - loss: 0.0144 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 8/205
747/747 - 3s - loss: 0.0116 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 9/205
747/747 - 3s - loss: 0.0115 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 10/205
747/747 - 3s - loss: 0.0112 - val_loss: 0.0109 - 3s/epoch - 5ms/step
Epoch 11/205
747/747 - 3s - loss: 0.0109 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 12/205
747/747 - 3s - loss: 0.0118 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 13/205
747/747 - 3s - loss: 0.0130 - val_loss: 0.0115 - 3s/epoch - 5ms/step
Epoch 14/205
747/747 - 3s - loss: 0.0127 - val_loss: 0.0109 - 3s/epoch - 5ms/step
Epoch 15/205
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 16/205
747/747 - 3s - loss: 0.0108 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 17/205
747/747 - 3s - loss: 0.0123 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 18/205
747/747 - 3s - loss: 0.0124 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 19/205
747/747 - 3s - loss: 0.0142 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 20/205
747/747 - 3s - loss: 0.0113 - val_loss: 0.0136 - 3s/epoch - 4ms/step
Epoch 21/205
747/747 - 3s - loss: 0.0138 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 22/205
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 23/205
747/747 - 3s - loss: 0.0108 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 24/205
747/747 - 3s - loss: 0.0107 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 25/205
747/747 - 3s - loss: 0.0108 - val_loss: 0.0104 - 3s/epoch - 5ms/step
Epoch 26/205
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 27/205
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 28/205
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 29/205
747/747 - 3s - loss: 0.0104 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 30/205
747/747 - 3s - loss: 0.0104 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 31/205
747/747 - 3s - loss: 0.0105 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 32/205
747/747 - 3s - loss: 0.0108 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 33/205
747/747 - 3s - loss: 0.0110 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 34/205
747/747 - 4s - loss: 0.0112 - val_loss: 0.0102 - 4s/epoch - 5ms/step
Epoch 35/205
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 36/205
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 37/205
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 5ms/step
Epoch 38/205
747/747 - 3s - loss: 0.0102 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 39/205
747/747 - 3s - loss: 0.0108 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 40/205
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 41/205
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 42/205
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 43/205
747/747 - 3s - loss: 0.0100 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 44/205
747/747 - 4s - loss: 0.0102 - val_loss: 0.0115 - 4s/epoch - 5ms/step
Epoch 45/205
747/747 - 3s - loss: 0.0109 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 46/205
747/747 - 3s - loss: 0.0101 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 47/205
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 48/205
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 49/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 50/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 51/205
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 52/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 53/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 54/205
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 55/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 56/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 57/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 58/205
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 59/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 60/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 61/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 62/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 63/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 64/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 65/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 66/205
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 67/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 68/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 69/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 70/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 71/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 72/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 73/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 74/205
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 75/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 76/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 77/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 78/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 79/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 80/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 81/205
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 82/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 83/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 84/205
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 85/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 86/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 87/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 88/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 89/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 90/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 91/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 92/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 93/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 94/205
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 95/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 96/205
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 97/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 98/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 99/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 100/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 101/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 102/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 103/205
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 104/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 105/205
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 106/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 107/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 108/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 109/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 110/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 111/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 112/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 113/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 114/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 115/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 116/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 117/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 118/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 119/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 120/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 121/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 122/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 123/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 124/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 125/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 126/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 127/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 128/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 129/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 130/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 131/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 132/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 133/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 134/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 135/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 136/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 137/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 138/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 139/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 140/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 141/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 142/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 143/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 144/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 145/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 146/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 147/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 148/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 149/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 150/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 151/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 152/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 153/205
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 154/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 155/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 156/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 157/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 158/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 159/205
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 160/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 161/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 162/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 163/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 164/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 165/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 166/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 167/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 168/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 169/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 170/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 171/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 172/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 173/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 174/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 175/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 176/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 177/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 178/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 179/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 180/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 181/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 182/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 183/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 184/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 185/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 186/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 187/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 188/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 189/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 190/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 191/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 192/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 193/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 194/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 195/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 196/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 197/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 198/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 199/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 200/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 201/205
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 202/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 203/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 204/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 205/205
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009226982481777668
  1/332 [..............................] - ETA: 49s 41/332 [==>...........................] - ETA: 0s  85/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s174/332 [==============>...............] - ETA: 0s219/332 [==================>...........] - ETA: 0s263/332 [======================>.......] - ETA: 0s298/332 [=========================>....] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07139170750599289
cosine 0.056055914904097996
MAE: 0.034952287
RMSE: 0.076861545
r2: 0.6167533830659635
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 128, 205, 0.0006000000000000001, 0.2, 252, 0.009398513473570347, 0.009226982481777668, 0.07139170750599289, 0.056055914904097996, 0.03495228663086891, 0.07686154544353485, 0.6167533830659635, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.0006000000000000001 256 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 5s - loss: 0.0377 - val_loss: 0.0229 - 5s/epoch - 13ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0161 - val_loss: 0.0188 - 2s/epoch - 5ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0149 - val_loss: 0.0302 - 2s/epoch - 6ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0146 - val_loss: 0.0192 - 2s/epoch - 5ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0138 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0132 - val_loss: 0.0154 - 2s/epoch - 5ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0129 - val_loss: 0.0155 - 2s/epoch - 6ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0125 - val_loss: 0.0255 - 2s/epoch - 6ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0125 - val_loss: 0.2083 - 2s/epoch - 5ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0168 - val_loss: 0.0118 - 2s/epoch - 6ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0163 - 2s/epoch - 6ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0128 - val_loss: 0.0122 - 2s/epoch - 6ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0111 - 2s/epoch - 6ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0193 - 2s/epoch - 6ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0151 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0156 - 2s/epoch - 5ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0147 - val_loss: 0.0155 - 2s/epoch - 6ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0229 - val_loss: 0.0165 - 2s/epoch - 5ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0227 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0118 - 2s/epoch - 6ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0138 - 2s/epoch - 6ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0230 - val_loss: 0.0137 - 2s/epoch - 6ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0229 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0126 - val_loss: 0.0165 - 2s/epoch - 6ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0432 - val_loss: 0.0207 - 2s/epoch - 6ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0771 - val_loss: 0.0171 - 2s/epoch - 6ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0156 - val_loss: 0.0155 - 2s/epoch - 6ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0216 - val_loss: 0.0141 - 2s/epoch - 6ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0142 - val_loss: 0.0134 - 2s/epoch - 6ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0136 - val_loss: 0.0130 - 2s/epoch - 6ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0132 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0128 - val_loss: 0.0124 - 2s/epoch - 6ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0126 - val_loss: 0.0121 - 2s/epoch - 6ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0119 - 2s/epoch - 6ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0118 - 2s/epoch - 6ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0117 - val_loss: 0.0143 - 2s/epoch - 6ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0142 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0120 - 2s/epoch - 6ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0127 - val_loss: 0.0155 - 2s/epoch - 6ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0190 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0128 - val_loss: 0.0117 - 2s/epoch - 6ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0112 - 2s/epoch - 6ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0117 - 2s/epoch - 6ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0140 - 2s/epoch - 6ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0149 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0180 - val_loss: 0.0157 - 2s/epoch - 6ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0228 - val_loss: 0.0120 - 2s/epoch - 6ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0124 - 2s/epoch - 6ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0139 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0133 - 2s/epoch - 6ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0160 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0146 - 2s/epoch - 6ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0161 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0126 - 2s/epoch - 6ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00931326113641262
  1/332 [..............................] - ETA: 44s 44/332 [==>...........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s168/332 [==============>...............] - ETA: 0s212/332 [==================>...........] - ETA: 0s255/332 [======================>.......] - ETA: 0s299/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07471597741178598
cosine 0.058666296446498636
MAE: 0.035753544
RMSE: 0.07846029
r2: 0.6006443271268062
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 200, 0.0006000000000000001, 0.2, 252, 0.009444987401366234, 0.00931326113641262, 0.07471597741178598, 0.058666296446498636, 0.03575354442000389, 0.07846029102802277, 0.6006443271268062, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.0006000000000000001 128 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
747/747 - 6s - loss: 0.0290 - val_loss: 0.0206 - 6s/epoch - 8ms/step
Epoch 2/200
747/747 - 3s - loss: 0.0158 - val_loss: 0.0301 - 3s/epoch - 4ms/step
Epoch 3/200
747/747 - 3s - loss: 0.0153 - val_loss: 0.0171 - 3s/epoch - 4ms/step
Epoch 4/200
747/747 - 3s - loss: 0.0137 - val_loss: 0.0156 - 3s/epoch - 4ms/step
Epoch 5/200
747/747 - 3s - loss: 0.0128 - val_loss: 0.0139 - 3s/epoch - 4ms/step
Epoch 6/200
747/747 - 3s - loss: 0.0123 - val_loss: 0.0357 - 3s/epoch - 5ms/step
Epoch 7/200
747/747 - 3s - loss: 0.0128 - val_loss: 0.0126 - 3s/epoch - 5ms/step
Epoch 8/200
747/747 - 3s - loss: 0.0121 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 9/200
747/747 - 3s - loss: 0.0113 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 10/200
747/747 - 3s - loss: 0.0111 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 11/200
747/747 - 3s - loss: 0.0110 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 12/200
747/747 - 3s - loss: 0.0111 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 13/200
747/747 - 3s - loss: 0.0117 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 14/200
747/747 - 3s - loss: 0.0109 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 15/200
747/747 - 3s - loss: 0.0107 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 16/200
747/747 - 4s - loss: 0.0111 - val_loss: 0.0104 - 4s/epoch - 5ms/step
Epoch 17/200
747/747 - 4s - loss: 0.0109 - val_loss: 0.0112 - 4s/epoch - 5ms/step
Epoch 18/200
747/747 - 3s - loss: 0.0120 - val_loss: 0.0107 - 3s/epoch - 5ms/step
Epoch 19/200
747/747 - 3s - loss: 0.0107 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 20/200
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 21/200
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 22/200
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 23/200
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 24/200
747/747 - 3s - loss: 0.0103 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 25/200
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 26/200
747/747 - 4s - loss: 0.0102 - val_loss: 0.0102 - 4s/epoch - 5ms/step
Epoch 27/200
747/747 - 3s - loss: 0.0105 - val_loss: 0.0100 - 3s/epoch - 5ms/step
Epoch 28/200
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 29/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 30/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 31/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 32/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 33/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 34/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 35/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 36/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 37/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 38/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 39/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 40/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 42/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 44/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 45/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 49/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 50/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 51/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 52/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 53/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 54/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 56/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 58/200
747/747 - 4s - loss: 0.0097 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 59/200
747/747 - 4s - loss: 0.0096 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 60/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 61/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 62/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 63/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 64/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 65/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 66/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 67/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 68/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 69/200
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 70/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 71/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 72/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 73/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 74/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 75/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 76/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 77/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 78/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 79/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 80/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 81/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 82/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 83/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 84/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 85/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 86/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 87/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 88/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 89/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 90/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 91/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 92/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 93/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 94/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 95/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 96/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 97/200
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 98/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 99/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 100/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 101/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 102/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 103/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 104/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 105/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 106/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 107/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 108/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 109/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 110/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 111/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 112/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 113/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 114/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 115/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 116/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 117/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 118/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 119/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 120/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 121/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 122/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 123/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 124/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 125/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 126/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 127/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 128/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 129/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 130/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 131/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 132/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 133/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 134/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 135/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 136/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 137/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 138/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 139/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 140/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 141/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 142/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 143/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 144/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 145/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 146/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 147/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 148/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 149/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 150/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 151/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 152/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 153/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 154/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 155/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 156/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 157/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 158/200
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 159/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 160/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 161/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 162/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 163/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 164/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 165/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 166/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 167/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 168/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 169/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 170/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 171/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 172/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 173/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 174/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 175/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 176/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 177/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 178/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 179/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 180/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 181/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 182/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 183/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 184/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 185/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 186/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 187/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 188/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 189/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 190/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 191/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 192/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 193/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 194/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 195/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 196/200
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 197/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 198/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 199/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 200/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009159381501376629
  1/332 [..............................] - ETA: 53s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s225/332 [===================>..........] - ETA: 0s270/332 [=======================>......] - ETA: 0s314/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0698773558751799
cosine 0.054849531036747924
MAE: 0.0343713
RMSE: 0.07610163
r2: 0.62429411749585
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 200, 0.0006000000000000001, 0.2, 252, 0.009301499463617802, 0.009159381501376629, 0.0698773558751799, 0.054849531036747924, 0.03437130153179169, 0.0761016309261322, 0.62429411749585, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_5.pkl
[1.7999999999999998 200 0.0008 256 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 5s - loss: 0.0372 - val_loss: 0.0205 - 5s/epoch - 12ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0191 - val_loss: 0.0169 - 2s/epoch - 6ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0144 - val_loss: 0.0168 - 2s/epoch - 5ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0142 - val_loss: 0.0176 - 2s/epoch - 6ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0141 - val_loss: 0.0166 - 2s/epoch - 6ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0136 - val_loss: 0.0168 - 2s/epoch - 6ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0158 - 2s/epoch - 6ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0126 - val_loss: 0.0143 - 2s/epoch - 6ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0221 - 2s/epoch - 6ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0255 - 2s/epoch - 5ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0816 - 2s/epoch - 5ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0165 - val_loss: 0.0142 - 2s/epoch - 6ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0155 - 2s/epoch - 5ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0122 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 6ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0115 - 2s/epoch - 6ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0125 - 2s/epoch - 6ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0144 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0149 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0111 - 2s/epoch - 6ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0120 - 2s/epoch - 6ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0179 - val_loss: 0.0123 - 2s/epoch - 6ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 6ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0127 - val_loss: 0.0137 - 2s/epoch - 6ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0275 - val_loss: 0.0118 - 2s/epoch - 6ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0117 - val_loss: 0.0117 - 2s/epoch - 6ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0137 - val_loss: 0.0111 - 2s/epoch - 6ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0140 - 2s/epoch - 6ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0187 - val_loss: 0.0116 - 2s/epoch - 6ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0120 - 2s/epoch - 6ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0148 - val_loss: 0.0125 - 2s/epoch - 6ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0154 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0129 - 2s/epoch - 5ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0158 - val_loss: 0.0110 - 2s/epoch - 6ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0127 - 2s/epoch - 6ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0134 - val_loss: 0.0114 - 2s/epoch - 6ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0109 - 2s/epoch - 6ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0111 - 2s/epoch - 6ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 6ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0117 - 2s/epoch - 6ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0139 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0123 - 2s/epoch - 6ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0155 - val_loss: 0.0128 - 2s/epoch - 6ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0154 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0113 - 2s/epoch - 6ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0129 - val_loss: 0.0103 - 2s/epoch - 6ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 6ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0102 - 2s/epoch - 6ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0100 - 2s/epoch - 6ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0104 - 2s/epoch - 6ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0107 - 2s/epoch - 6ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 6ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0108 - 2s/epoch - 6ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 6ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 6ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 6ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 6ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009187433868646622
  1/332 [..............................] - ETA: 45s 46/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s267/332 [=======================>......] - ETA: 0s311/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07102624021113885
cosine 0.05576058407235136
MAE: 0.03483385
RMSE: 0.07659215
r2: 0.6194353229134376
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 200, 0.0008, 0.2, 252, 0.009316942654550076, 0.009187433868646622, 0.07102624021113885, 0.05576058407235136, 0.03483384847640991, 0.07659214735031128, 0.6194353229134376, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 210 0.0004000000000000001 128 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/210
747/747 - 6s - loss: 0.0297 - val_loss: 0.0222 - 6s/epoch - 8ms/step
Epoch 2/210
747/747 - 3s - loss: 0.0154 - val_loss: 0.0216 - 3s/epoch - 5ms/step
Epoch 3/210
747/747 - 3s - loss: 0.0143 - val_loss: 0.0144 - 3s/epoch - 5ms/step
Epoch 4/210
747/747 - 3s - loss: 0.0132 - val_loss: 0.0162 - 3s/epoch - 4ms/step
Epoch 5/210
747/747 - 3s - loss: 0.0125 - val_loss: 0.0161 - 3s/epoch - 4ms/step
Epoch 6/210
747/747 - 3s - loss: 0.0121 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 7/210
747/747 - 3s - loss: 0.0118 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 8/210
747/747 - 3s - loss: 0.0116 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 9/210
747/747 - 3s - loss: 0.0114 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 10/210
747/747 - 3s - loss: 0.0111 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 11/210
747/747 - 3s - loss: 0.0113 - val_loss: 0.0108 - 3s/epoch - 5ms/step
Epoch 12/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0107 - 3s/epoch - 5ms/step
Epoch 13/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 14/210
747/747 - 3s - loss: 0.0111 - val_loss: 0.0108 - 3s/epoch - 5ms/step
Epoch 15/210
747/747 - 3s - loss: 0.0127 - val_loss: 0.0120 - 3s/epoch - 5ms/step
Epoch 16/210
747/747 - 3s - loss: 0.0119 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 17/210
747/747 - 3s - loss: 0.0126 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 18/210
747/747 - 3s - loss: 0.0126 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 19/210
747/747 - 3s - loss: 0.0112 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 20/210
747/747 - 3s - loss: 0.0111 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 21/210
747/747 - 3s - loss: 0.0112 - val_loss: 0.0105 - 3s/epoch - 5ms/step
Epoch 22/210
747/747 - 4s - loss: 0.0107 - val_loss: 0.0109 - 4s/epoch - 5ms/step
Epoch 23/210
747/747 - 3s - loss: 0.0116 - val_loss: 0.0105 - 3s/epoch - 5ms/step
Epoch 24/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0108 - 3s/epoch - 5ms/step
Epoch 25/210
747/747 - 3s - loss: 0.0110 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 26/210
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 5ms/step
Epoch 27/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 28/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 29/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 30/210
747/747 - 3s - loss: 0.0111 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 31/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 32/210
747/747 - 3s - loss: 0.0126 - val_loss: 0.0106 - 3s/epoch - 5ms/step
Epoch 33/210
747/747 - 3s - loss: 0.0106 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 34/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 35/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 5ms/step
Epoch 36/210
747/747 - 3s - loss: 0.0102 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 37/210
747/747 - 3s - loss: 0.0103 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 38/210
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 39/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 40/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 41/210
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 42/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 43/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 44/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 45/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0111 - 3s/epoch - 5ms/step
Epoch 46/210
747/747 - 3s - loss: 0.0109 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 47/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 48/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 49/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 50/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 51/210
747/747 - 4s - loss: 0.0100 - val_loss: 0.0101 - 4s/epoch - 5ms/step
Epoch 52/210
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 53/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 54/210
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 55/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 56/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 57/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 58/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 59/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 60/210
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 61/210
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 62/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 63/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 64/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 65/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 66/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 67/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 69/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 71/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 72/210
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 73/210
747/747 - 4s - loss: 0.0097 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 74/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 75/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 76/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 77/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 78/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 79/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 80/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 81/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 82/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 83/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 84/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 85/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 86/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 87/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 88/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 89/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 90/210
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 91/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 92/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 93/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 94/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 95/210
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 96/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 97/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 98/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 99/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 100/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 101/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 102/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 103/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 104/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 105/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 106/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 107/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 108/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 109/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 110/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 111/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 112/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 113/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 114/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 115/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 116/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 117/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 118/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 119/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 120/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 121/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 122/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 123/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 124/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 125/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 126/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 127/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 128/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 129/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 130/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 131/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 132/210
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 133/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 134/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 135/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 136/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 137/210
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 138/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 139/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 140/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 141/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 142/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 143/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 144/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 145/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 146/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 147/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 148/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 149/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 150/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 151/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 152/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 153/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 154/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 155/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 156/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 157/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 158/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 159/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 160/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 161/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 162/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 163/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 164/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 165/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 166/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 167/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 168/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 169/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 170/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 171/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 172/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 173/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 174/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 175/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 176/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 177/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 178/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 179/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 180/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 181/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 182/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 183/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 184/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 185/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 186/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 187/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 188/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 189/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 190/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 191/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 192/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 193/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 194/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 195/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 196/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 197/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 198/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 199/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 200/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 201/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 202/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 203/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 204/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 205/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 206/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 207/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 208/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 209/210
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 210/210
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009193525649607182
  1/332 [..............................] - ETA: 53s 44/332 [==>...........................] - ETA: 0s  84/332 [======>.......................] - ETA: 0s127/332 [==========>...................] - ETA: 0s170/332 [==============>...............] - ETA: 0s213/332 [==================>...........] - ETA: 0s256/332 [======================>.......] - ETA: 0s300/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07152786925631652
cosine 0.05615911900974695
MAE: 0.03487779
RMSE: 0.07695736
r2: 0.6157972764796164
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 128, 210, 0.0004000000000000001, 0.2, 252, 0.009355448186397552, 0.009193525649607182, 0.07152786925631652, 0.05615911900974695, 0.03487778827548027, 0.07695735991001129, 0.6157972764796164, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.0004000000000000001 256 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 4s - loss: 0.0374 - val_loss: 0.0205 - 4s/epoch - 11ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0162 - val_loss: 0.0196 - 2s/epoch - 5ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0148 - val_loss: 0.0174 - 2s/epoch - 4ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0144 - val_loss: 0.0188 - 2s/epoch - 4ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0140 - val_loss: 0.0161 - 2s/epoch - 4ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0138 - val_loss: 0.0159 - 2s/epoch - 4ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0133 - val_loss: 0.0150 - 2s/epoch - 4ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0129 - val_loss: 0.0433 - 2s/epoch - 4ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0133 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0162 - 2s/epoch - 5ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0272 - 2s/epoch - 5ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0127 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0152 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0174 - val_loss: 0.0125 - 2s/epoch - 4ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0141 - val_loss: 0.0128 - 2s/epoch - 4ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0200 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0122 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0129 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0134 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0154 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0170 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0143 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0132 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0161 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0127 - 2s/epoch - 5ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0125 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00930518377572298
  1/332 [..............................] - ETA: 50s 44/332 [==>...........................] - ETA: 0s  87/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s176/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s265/332 [======================>.......] - ETA: 0s309/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07322149887495656
cosine 0.05743419283792472
MAE: 0.035566185
RMSE: 0.07778236
r2: 0.6075157481637962
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 200, 0.0004000000000000001, 0.2, 252, 0.009422081522643566, 0.00930518377572298, 0.07322149887495656, 0.05743419283792472, 0.03556618466973305, 0.07778236269950867, 0.6075157481637962, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.0004000000000000001 256 1] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/210
374/374 - 5s - loss: 0.0407 - val_loss: 0.0254 - 5s/epoch - 12ms/step
Epoch 2/210
374/374 - 2s - loss: 0.0157 - val_loss: 0.0215 - 2s/epoch - 5ms/step
Epoch 3/210
374/374 - 2s - loss: 0.0154 - val_loss: 0.0180 - 2s/epoch - 5ms/step
Epoch 4/210
374/374 - 2s - loss: 0.0142 - val_loss: 0.0194 - 2s/epoch - 4ms/step
Epoch 5/210
374/374 - 2s - loss: 0.0139 - val_loss: 0.0160 - 2s/epoch - 5ms/step
Epoch 6/210
374/374 - 2s - loss: 0.0134 - val_loss: 0.0150 - 2s/epoch - 4ms/step
Epoch 7/210
374/374 - 2s - loss: 0.0128 - val_loss: 0.0290 - 2s/epoch - 5ms/step
Epoch 8/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0155 - 2s/epoch - 4ms/step
Epoch 9/210
374/374 - 2s - loss: 0.0121 - val_loss: 0.0683 - 2s/epoch - 5ms/step
Epoch 10/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0333 - 2s/epoch - 5ms/step
Epoch 11/210
374/374 - 2s - loss: 0.0126 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 12/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0378 - 2s/epoch - 4ms/step
Epoch 13/210
374/374 - 2s - loss: 0.0147 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 14/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 15/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 16/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 17/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 18/210
374/374 - 2s - loss: 0.0116 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 19/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 20/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0145 - 2s/epoch - 5ms/step
Epoch 21/210
374/374 - 2s - loss: 0.0178 - val_loss: 0.0158 - 2s/epoch - 5ms/step
Epoch 22/210
374/374 - 2s - loss: 0.0210 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 23/210
374/374 - 2s - loss: 0.0122 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 24/210
374/374 - 2s - loss: 0.0119 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 25/210
374/374 - 2s - loss: 0.0119 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 26/210
374/374 - 2s - loss: 0.0148 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 27/210
374/374 - 2s - loss: 0.0146 - val_loss: 0.0148 - 2s/epoch - 5ms/step
Epoch 28/210
374/374 - 2s - loss: 0.0541 - val_loss: 0.0170 - 2s/epoch - 5ms/step
Epoch 29/210
374/374 - 2s - loss: 0.0474 - val_loss: 0.0156 - 2s/epoch - 5ms/step
Epoch 30/210
374/374 - 2s - loss: 0.0143 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 31/210
374/374 - 2s - loss: 0.0190 - val_loss: 0.0133 - 2s/epoch - 5ms/step
Epoch 32/210
374/374 - 2s - loss: 0.0165 - val_loss: 0.0156 - 2s/epoch - 5ms/step
Epoch 33/210
374/374 - 2s - loss: 0.0371 - val_loss: 0.0162 - 2s/epoch - 5ms/step
Epoch 34/210
374/374 - 2s - loss: 0.0233 - val_loss: 0.0147 - 2s/epoch - 5ms/step
Epoch 35/210
374/374 - 2s - loss: 0.0142 - val_loss: 0.0134 - 2s/epoch - 5ms/step
Epoch 36/210
374/374 - 2s - loss: 0.0138 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 37/210
374/374 - 2s - loss: 0.0168 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 38/210
374/374 - 2s - loss: 0.0132 - val_loss: 0.0153 - 2s/epoch - 5ms/step
Epoch 39/210
374/374 - 2s - loss: 0.0205 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 40/210
374/374 - 2s - loss: 0.0130 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 41/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 42/210
374/374 - 2s - loss: 0.0124 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 43/210
374/374 - 2s - loss: 0.0122 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 44/210
374/374 - 2s - loss: 0.0137 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 45/210
374/374 - 2s - loss: 0.0120 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 46/210
374/374 - 2s - loss: 0.0118 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 47/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 48/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 49/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 50/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 51/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 52/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 53/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 54/210
374/374 - 2s - loss: 0.0149 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 55/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 56/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 57/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 58/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0207 - 2s/epoch - 5ms/step
Epoch 59/210
374/374 - 2s - loss: 0.0215 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 60/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 61/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 62/210
374/374 - 2s - loss: 0.0143 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 63/210
374/374 - 2s - loss: 0.0221 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 64/210
374/374 - 2s - loss: 0.0173 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 65/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 66/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 67/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0132 - 2s/epoch - 5ms/step
Epoch 68/210
374/374 - 2s - loss: 0.0141 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 69/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 70/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 71/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 72/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 73/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 74/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 75/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 76/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 77/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0153 - 2s/epoch - 5ms/step
Epoch 78/210
374/374 - 2s - loss: 0.0145 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 79/210
374/374 - 2s - loss: 0.0200 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 80/210
374/374 - 2s - loss: 0.0113 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 81/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 82/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 83/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 84/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 85/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 86/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0160 - 2s/epoch - 5ms/step
Epoch 87/210
374/374 - 2s - loss: 0.0211 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 88/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 89/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 90/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 91/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 92/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 93/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0164 - 2s/epoch - 5ms/step
Epoch 94/210
374/374 - 2s - loss: 0.0260 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 95/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 96/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 97/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 98/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 99/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 100/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 101/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 102/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 103/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 104/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 105/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 106/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 107/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 108/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 109/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 110/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 111/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 112/210
374/374 - 2s - loss: 0.0145 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 113/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 114/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 115/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 116/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 117/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 118/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 119/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 120/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 121/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 122/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 123/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 124/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 125/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 126/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 127/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 128/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 129/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 130/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 131/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 132/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 133/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 134/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 135/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 136/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 137/210
374/374 - 2s - loss: 0.0117 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 138/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 139/210
374/374 - 2s - loss: 0.0127 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 140/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 141/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 142/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 143/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 144/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 145/210
374/374 - 2s - loss: 0.0126 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 146/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 147/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 148/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 149/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 150/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 151/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 152/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 153/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 154/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 155/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 156/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 157/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 158/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 159/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 160/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 161/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 162/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 163/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 164/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 165/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 166/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 167/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 168/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 169/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 170/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 171/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 172/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 173/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 174/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 175/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 176/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 177/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 178/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 179/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 180/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 181/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 182/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 183/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 184/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 185/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 186/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 187/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 188/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 189/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 190/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 191/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 192/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 193/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 194/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 195/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 196/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 197/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 198/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 199/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 200/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 201/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 202/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 203/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 204/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 205/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 206/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 207/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 208/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 209/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 210/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009426946751773357
  1/332 [..............................] - ETA: 53s 44/332 [==>...........................] - ETA: 0s  88/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s306/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07700044139124428
cosine 0.06038844838732825
MAE: 0.03652171
RMSE: 0.079717174
r2: 0.5877469411184598
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'mse', 256, 210, 0.0004000000000000001, 0.2, 252, 0.00954229012131691, 0.009426946751773357, 0.07700044139124428, 0.06038844838732825, 0.03652171045541763, 0.07971717417240143, 0.5877469411184598, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 200 0.0008 256 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 4s - loss: 0.0381 - val_loss: 0.0204 - 4s/epoch - 11ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0160 - val_loss: 0.0250 - 2s/epoch - 4ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0154 - val_loss: 0.0170 - 2s/epoch - 4ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0143 - val_loss: 0.0244 - 2s/epoch - 5ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0143 - val_loss: 0.0151 - 2s/epoch - 4ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0150 - 2s/epoch - 4ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0129 - val_loss: 0.0501 - 2s/epoch - 5ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0136 - val_loss: 0.0770 - 2s/epoch - 4ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0136 - val_loss: 0.0179 - 2s/epoch - 4ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0136 - 2s/epoch - 4ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0135 - 2s/epoch - 5ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0134 - 2s/epoch - 5ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0121 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0115 - val_loss: 0.0135 - 2s/epoch - 4ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0127 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0129 - 2s/epoch - 5ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0151 - val_loss: 0.0126 - 2s/epoch - 4ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0152 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0210 - val_loss: 0.0155 - 2s/epoch - 5ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0303 - val_loss: 0.0140 - 2s/epoch - 5ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0159 - val_loss: 0.0139 - 2s/epoch - 4ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0242 - val_loss: 0.0141 - 2s/epoch - 4ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0156 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0127 - 2s/epoch - 5ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0136 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0124 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0122 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0148 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0128 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0125 - val_loss: 0.0131 - 2s/epoch - 4ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0231 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0122 - val_loss: 0.0126 - 2s/epoch - 4ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0130 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0116 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0118 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0132 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0128 - 2s/epoch - 4ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0156 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0131 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0150 - 2s/epoch - 4ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0147 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0120 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0389 - val_loss: 0.0133 - 2s/epoch - 4ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0215 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0119 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0113 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0109 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0112 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0135 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0104 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0106 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0147 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0108 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0105 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0114 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0107 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009358660317957401
  1/332 [..............................] - ETA: 53s 47/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s231/332 [===================>..........] - ETA: 0s277/332 [========================>.....] - ETA: 0s321/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07564639316115611
cosine 0.05934491491838981
MAE: 0.036182657
RMSE: 0.079073474
r2: 0.594377840559166
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 256, 200, 0.0008, 0.2, 252, 0.009462060406804085, 0.009358660317957401, 0.07564639316115611, 0.05934491491838981, 0.03618265688419342, 0.0790734738111496, 0.594377840559166, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.001 64 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
Epoch 1/210
1493/1493 - 8s - loss: 0.0255 - val_loss: 0.0162 - 8s/epoch - 6ms/step
Epoch 2/210
1493/1493 - 6s - loss: 0.0147 - val_loss: 0.0176 - 6s/epoch - 4ms/step
Epoch 3/210
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0121 - 6s/epoch - 4ms/step
Epoch 4/210
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0118 - 6s/epoch - 4ms/step
Epoch 5/210
1493/1493 - 6s - loss: 0.0125 - val_loss: 0.0114 - 6s/epoch - 4ms/step
Epoch 6/210
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/210
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 8/210
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/210
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/210
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 11/210
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/210
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/210
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/210
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/210
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/210
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/210
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/210
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/210
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/210
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/210
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 75/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 76/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 77/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 78/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 79/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 80/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 81/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 82/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 84/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 87/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 88/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 91/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 92/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 94/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 99/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 100/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 104/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/210
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 125/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 126/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 128/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 129/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 130/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 131/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 132/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 133/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 134/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 135/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 136/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 137/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 138/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 139/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 140/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 141/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 142/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 143/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 144/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 145/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 146/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 147/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 148/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 150/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 151/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 152/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 153/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 154/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 159/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 160/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 161/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 163/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 164/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 165/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 166/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 167/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 168/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 169/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 171/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 173/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 177/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 178/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 180/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 183/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 186/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 191/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 196/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 197/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 198/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 199/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 200/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 201/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 202/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 203/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 204/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 205/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 206/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 207/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 208/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 209/210
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 210/210
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009355803951621056
  1/332 [..............................] - ETA: 53s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s267/332 [=======================>......] - ETA: 0s312/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0735351537202288
cosine 0.05778214947664194
MAE: 0.035795234
RMSE: 0.07803519
r2: 0.6049601359281478
RMSE zero-vector: 0.23411466903540806
['2.0custom_VAE', 'mse', 64, 210, 0.001, 0.2, 252, 0.009548991918563843, 0.009355803951621056, 0.0735351537202288, 0.05778214947664194, 0.03579523414373398, 0.07803519070148468, 0.6049601359281478, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 210 0.001 256 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/210
374/374 - 4s - loss: 0.0377 - val_loss: 0.0185 - 4s/epoch - 11ms/step
Epoch 2/210
374/374 - 2s - loss: 0.0160 - val_loss: 0.0261 - 2s/epoch - 4ms/step
Epoch 3/210
374/374 - 2s - loss: 0.0148 - val_loss: 0.0174 - 2s/epoch - 4ms/step
Epoch 4/210
374/374 - 2s - loss: 0.0143 - val_loss: 0.0208 - 2s/epoch - 4ms/step
Epoch 5/210
374/374 - 2s - loss: 0.0140 - val_loss: 0.0163 - 2s/epoch - 5ms/step
Epoch 6/210
374/374 - 2s - loss: 0.0136 - val_loss: 0.0162 - 2s/epoch - 4ms/step
Epoch 7/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0406 - 2s/epoch - 4ms/step
Epoch 8/210
374/374 - 2s - loss: 0.0128 - val_loss: 0.0167 - 2s/epoch - 4ms/step
Epoch 9/210
374/374 - 2s - loss: 0.0123 - val_loss: 0.3113 - 2s/epoch - 4ms/step
Epoch 10/210
374/374 - 2s - loss: 0.0173 - val_loss: 0.0200 - 2s/epoch - 4ms/step
Epoch 11/210
374/374 - 2s - loss: 0.0132 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 12/210
374/374 - 2s - loss: 0.0115 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 13/210
374/374 - 2s - loss: 0.0114 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 14/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 15/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0187 - 2s/epoch - 5ms/step
Epoch 16/210
374/374 - 2s - loss: 0.0128 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 17/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0127 - 2s/epoch - 5ms/step
Epoch 18/210
374/374 - 2s - loss: 0.0126 - val_loss: 0.0135 - 2s/epoch - 5ms/step
Epoch 19/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 20/210
374/374 - 2s - loss: 0.0124 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 21/210
374/374 - 2s - loss: 0.0129 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 22/210
374/374 - 2s - loss: 0.0137 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 23/210
374/374 - 2s - loss: 0.0142 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 24/210
374/374 - 2s - loss: 0.0140 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 25/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 26/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 27/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 28/210
374/374 - 2s - loss: 0.0144 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 29/210
374/374 - 2s - loss: 0.0150 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 30/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 31/210
374/374 - 2s - loss: 0.0126 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 32/210
374/374 - 2s - loss: 0.0112 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 33/210
374/374 - 2s - loss: 0.0130 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 34/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 35/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 36/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 37/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 38/210
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 39/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 40/210
374/374 - 2s - loss: 0.0131 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 41/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 42/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 43/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 44/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 45/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 46/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 47/210
374/374 - 2s - loss: 0.0121 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 48/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 49/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 50/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 51/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 52/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 53/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 54/210
374/374 - 2s - loss: 0.0126 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 55/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 56/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 57/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 58/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 59/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 60/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 61/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 62/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 63/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 64/210
374/374 - 2s - loss: 0.0124 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 65/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 66/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0125 - 2s/epoch - 4ms/step
Epoch 67/210
374/374 - 2s - loss: 0.0151 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 68/210
374/374 - 2s - loss: 0.0122 - val_loss: 0.0128 - 2s/epoch - 4ms/step
Epoch 69/210
374/374 - 2s - loss: 0.0199 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 70/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 71/210
374/374 - 2s - loss: 0.0157 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 72/210
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 73/210
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 74/210
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 75/210
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 76/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 77/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 78/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 79/210
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 80/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 81/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 82/210
374/374 - 2s - loss: 0.0111 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 83/210
374/374 - 2s - loss: 0.0109 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 84/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 85/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 86/210
374/374 - 2s - loss: 0.0101 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 87/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 88/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 89/210
374/374 - 2s - loss: 0.0110 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 90/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 91/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 92/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 93/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 94/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 95/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 96/210
374/374 - 2s - loss: 0.0102 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 97/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 98/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 99/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 100/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 101/210
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 102/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 103/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 104/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 105/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 106/210
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 107/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 108/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 109/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 110/210
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 111/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 112/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 113/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 114/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 115/210
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 116/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 117/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 118/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 119/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 120/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 121/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 122/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 123/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 124/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 125/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 126/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 127/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 128/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 129/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 130/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 131/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 132/210
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 133/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 134/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 135/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 136/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 137/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 138/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 139/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 140/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 141/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 142/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 143/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 144/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 145/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 146/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 147/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 148/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 149/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 150/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 151/210
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 152/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 153/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 154/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 155/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 156/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 157/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 158/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 159/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 160/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 161/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 162/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 163/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 164/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 165/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 166/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 167/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 168/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 169/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 170/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 171/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 172/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 173/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 174/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 175/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 176/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 177/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 178/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 179/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 180/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 181/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 182/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 183/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 184/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 185/210
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 186/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 187/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 188/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 189/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 190/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 191/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 192/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 193/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 194/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 195/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 196/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 197/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 198/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 199/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 200/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 201/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 202/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 203/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 204/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 205/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 206/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 207/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 208/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 209/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 210/210
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009189121425151825
  1/332 [..............................] - ETA: 40s 47/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s230/332 [===================>..........] - ETA: 0s276/332 [=======================>......] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07223345315146347
cosine 0.05668928114998534
MAE: 0.035190787
RMSE: 0.07733445
r2: 0.6120229343487624
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 210, 0.001, 0.2, 252, 0.009290700778365135, 0.009189121425151825, 0.07223345315146347, 0.05668928114998534, 0.03519078716635704, 0.0773344486951828, 0.6120229343487624, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[2.0 210 0.0004000000000000001 256 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2528)         3197920     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2528)        10112       ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2528)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          637308      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3911116     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 8,393,764
Trainable params: 8,383,148
Non-trainable params: 10,616
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE2.0_cr0.2_bs256_ep210_loss_mse_lr0.0004000000000000001_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 42s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s228/332 [===================>..........] - ETA: 0s274/332 [=======================>......] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07700044139124428
cosine 0.06038844838732825
MAE: 0.03652171
RMSE: 0.079717174
r2: 0.5877469411184598
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['2.0custom_VAE', 'mse', 256, 210, 0.0004000000000000001, 0.2, 252, '--', '--', 0.07700044139124428, 0.06038844838732825, 0.03652171045541763, 0.07971717417240143, 0.5877469411184598, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_6.pkl
[1.9 195 0.0008 256 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/195
374/374 - 4s - loss: 0.0384 - val_loss: 0.0213 - 4s/epoch - 11ms/step
Epoch 2/195
374/374 - 2s - loss: 0.0158 - val_loss: 0.0331 - 2s/epoch - 5ms/step
Epoch 3/195
374/374 - 2s - loss: 0.0154 - val_loss: 0.0228 - 2s/epoch - 4ms/step
Epoch 4/195
374/374 - 2s - loss: 0.0145 - val_loss: 0.0214 - 2s/epoch - 4ms/step
Epoch 5/195
374/374 - 2s - loss: 0.0141 - val_loss: 0.0155 - 2s/epoch - 4ms/step
Epoch 6/195
374/374 - 2s - loss: 0.0137 - val_loss: 0.0177 - 2s/epoch - 4ms/step
Epoch 7/195
374/374 - 2s - loss: 0.0134 - val_loss: 0.0210 - 2s/epoch - 4ms/step
Epoch 8/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0157 - 2s/epoch - 4ms/step
Epoch 9/195
374/374 - 2s - loss: 0.0125 - val_loss: 0.0178 - 2s/epoch - 5ms/step
Epoch 10/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0312 - 2s/epoch - 5ms/step
Epoch 11/195
374/374 - 2s - loss: 0.0126 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 12/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0222 - 2s/epoch - 4ms/step
Epoch 13/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0145 - 2s/epoch - 5ms/step
Epoch 14/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 15/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 16/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 17/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 18/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 19/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0142 - 2s/epoch - 5ms/step
Epoch 20/195
374/374 - 2s - loss: 0.0148 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 21/195
374/374 - 2s - loss: 0.0140 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 22/195
374/374 - 2s - loss: 0.0266 - val_loss: 0.0166 - 2s/epoch - 4ms/step
Epoch 23/195
374/374 - 2s - loss: 0.0521 - val_loss: 0.0144 - 2s/epoch - 4ms/step
Epoch 24/195
374/374 - 2s - loss: 0.0221 - val_loss: 0.0148 - 2s/epoch - 4ms/step
Epoch 25/195
374/374 - 2s - loss: 0.0150 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 26/195
374/374 - 2s - loss: 0.0139 - val_loss: 0.0129 - 2s/epoch - 5ms/step
Epoch 27/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 28/195
374/374 - 2s - loss: 0.0127 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 29/195
374/374 - 2s - loss: 0.0125 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 30/195
374/374 - 2s - loss: 0.0129 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 31/195
374/374 - 2s - loss: 0.0138 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 32/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 33/195
374/374 - 2s - loss: 0.0122 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 34/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 35/195
374/374 - 2s - loss: 0.0119 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 36/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 37/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 38/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0143 - 2s/epoch - 4ms/step
Epoch 39/195
374/374 - 2s - loss: 0.0152 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 40/195
374/374 - 2s - loss: 0.0144 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 41/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 42/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 43/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 44/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0156 - 2s/epoch - 4ms/step
Epoch 45/195
374/374 - 2s - loss: 0.0208 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 46/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 47/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 48/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 49/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0147 - 2s/epoch - 5ms/step
Epoch 50/195
374/374 - 2s - loss: 0.0179 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 51/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 52/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0137 - 2s/epoch - 5ms/step
Epoch 53/195
374/374 - 2s - loss: 0.0227 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 54/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 55/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 56/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 57/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 58/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 59/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 60/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 61/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 62/195
374/374 - 2s - loss: 0.0122 - val_loss: 0.0216 - 2s/epoch - 5ms/step
Epoch 63/195
374/374 - 2s - loss: 0.0317 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 64/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 65/195
374/374 - 2s - loss: 0.0119 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 66/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 67/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 68/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 69/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 70/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 71/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 72/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 73/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 74/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 75/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 76/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 77/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 78/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 79/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 80/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0131 - 2s/epoch - 4ms/step
Epoch 81/195
374/374 - 2s - loss: 0.0136 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 82/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 83/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0188 - 2s/epoch - 4ms/step
Epoch 84/195
374/374 - 2s - loss: 0.0282 - val_loss: 0.0144 - 2s/epoch - 4ms/step
Epoch 85/195
374/374 - 2s - loss: 0.0190 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 86/195
374/374 - 2s - loss: 0.0126 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 87/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 88/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 89/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 90/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 91/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 92/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 93/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 94/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 95/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0144 - 2s/epoch - 5ms/step
Epoch 96/195
374/374 - 2s - loss: 0.0141 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 97/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 98/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 99/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 100/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 101/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 102/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0167 - 2s/epoch - 4ms/step
Epoch 103/195
374/374 - 2s - loss: 0.0126 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 104/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 105/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 106/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 107/195
374/374 - 2s - loss: 0.0141 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 108/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 109/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 110/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 111/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 112/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 113/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 114/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 115/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 116/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 117/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 118/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 119/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 120/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 121/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 122/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 123/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 124/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 125/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0148 - 2s/epoch - 5ms/step
Epoch 126/195
374/374 - 2s - loss: 0.0196 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 127/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 128/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 129/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 130/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 131/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 132/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 133/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 134/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 135/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 136/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 137/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 138/195
374/374 - 2s - loss: 0.0129 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 139/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 140/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 141/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 142/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 143/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 144/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 145/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 146/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 147/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 148/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 149/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 150/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 151/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 152/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0180 - 2s/epoch - 5ms/step
Epoch 153/195
374/374 - 2s - loss: 0.0125 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 154/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 155/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 156/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 157/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 158/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 159/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0159 - 2s/epoch - 4ms/step
Epoch 160/195
374/374 - 2s - loss: 0.0150 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 161/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 162/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 163/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 164/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 165/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 166/195
374/374 - 2s - loss: 0.0133 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 167/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 168/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 169/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 170/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 171/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 172/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 173/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 174/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 175/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 176/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 177/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 178/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 179/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 180/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 181/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 182/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 183/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 184/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 185/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 186/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 187/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 188/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 189/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 190/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 191/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 192/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 193/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 194/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 195/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00955071672797203
  1/332 [..............................] - ETA: 37s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s230/332 [===================>..........] - ETA: 0s276/332 [=======================>......] - ETA: 0s322/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07834635441297862
cosine 0.061467259274174305
MAE: 0.036801126
RMSE: 0.08035873
r2: 0.5810848230912231
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 256, 195, 0.0008, 0.2, 252, 0.009662223048508167, 0.00955071672797203, 0.07834635441297862, 0.061467259274174305, 0.03680112585425377, 0.08035872876644135, 0.5810848230912231, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0008 256 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
374/374 - 4s - loss: 0.0383 - val_loss: 0.0561 - 4s/epoch - 11ms/step
Epoch 2/195
374/374 - 2s - loss: 0.0164 - val_loss: 0.0353 - 2s/epoch - 5ms/step
Epoch 3/195
374/374 - 2s - loss: 0.0153 - val_loss: 0.0171 - 2s/epoch - 4ms/step
Epoch 4/195
374/374 - 2s - loss: 0.0147 - val_loss: 0.0191 - 2s/epoch - 4ms/step
Epoch 5/195
374/374 - 2s - loss: 0.0145 - val_loss: 0.0167 - 2s/epoch - 4ms/step
Epoch 6/195
374/374 - 2s - loss: 0.0136 - val_loss: 0.0157 - 2s/epoch - 5ms/step
Epoch 7/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0803 - 2s/epoch - 4ms/step
Epoch 8/195
374/374 - 2s - loss: 0.0143 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 9/195
374/374 - 2s - loss: 0.0123 - val_loss: 0.0163 - 2s/epoch - 4ms/step
Epoch 10/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 11/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0138 - 2s/epoch - 5ms/step
Epoch 12/195
374/374 - 2s - loss: 0.0119 - val_loss: 0.0598 - 2s/epoch - 4ms/step
Epoch 13/195
374/374 - 2s - loss: 0.0141 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 14/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 15/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 16/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 17/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 18/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0124 - 2s/epoch - 4ms/step
Epoch 19/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 20/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 21/195
374/374 - 2s - loss: 0.0173 - val_loss: 0.0134 - 2s/epoch - 4ms/step
Epoch 22/195
374/374 - 2s - loss: 0.0185 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 23/195
374/374 - 2s - loss: 0.0133 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 24/195
374/374 - 2s - loss: 0.0182 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 25/195
374/374 - 2s - loss: 0.0122 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 26/195
374/374 - 2s - loss: 0.0135 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 27/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 28/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 29/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 30/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 31/195
374/374 - 2s - loss: 0.0125 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 32/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 33/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 34/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 35/195
374/374 - 2s - loss: 0.0164 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 36/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 37/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 38/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 39/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 40/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 41/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 42/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 43/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 44/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 45/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 46/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 47/195
374/374 - 2s - loss: 0.0136 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 48/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 49/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 50/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 51/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 52/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 53/195
374/374 - 2s - loss: 0.0157 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 54/195
374/374 - 2s - loss: 0.0190 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 55/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 56/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 57/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 58/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 59/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 60/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 61/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0135 - 2s/epoch - 5ms/step
Epoch 62/195
374/374 - 2s - loss: 0.0194 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 63/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 64/195
374/374 - 2s - loss: 0.0126 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 65/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 66/195
374/374 - 2s - loss: 0.0150 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 67/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 68/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 69/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 70/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 71/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 72/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 73/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 74/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 75/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 76/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 77/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 78/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 79/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 80/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0144 - 2s/epoch - 4ms/step
Epoch 81/195
374/374 - 2s - loss: 0.0188 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 82/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 83/195
374/374 - 2s - loss: 0.0152 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 84/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 85/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 86/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 87/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 88/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 89/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 90/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 91/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 92/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 93/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 94/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 95/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 96/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 97/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 98/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 99/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 100/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 101/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 102/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 103/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 104/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 105/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 106/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 107/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 108/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 109/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 110/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 111/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 112/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 113/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 114/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 115/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 116/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 117/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 118/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 119/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 120/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 121/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 122/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 123/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 124/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 125/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 126/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 127/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 128/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 129/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 130/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 131/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 132/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 133/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 134/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 135/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 136/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 137/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 138/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 139/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 140/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 141/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 142/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 143/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 144/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 145/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 146/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 147/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 148/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 149/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 150/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 151/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 152/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 153/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 154/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 155/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 156/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 157/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 158/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 159/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 160/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 161/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 162/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 163/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 164/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 165/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 166/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 167/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 168/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 169/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 170/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 171/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 172/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 173/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 174/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 175/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 176/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 177/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 178/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 179/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 180/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 181/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 182/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 183/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 184/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 185/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 186/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 187/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 188/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 189/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 190/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 191/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 192/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 193/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 194/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 195/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009246490895748138
  1/332 [..............................] - ETA: 39s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s226/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07162543404475276
cosine 0.05622624872969179
MAE: 0.034992002
RMSE: 0.07693471
r2: 0.6160236369935006
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 195, 0.0008, 0.2, 252, 0.009348149411380291, 0.009246490895748138, 0.07162543404475276, 0.05622624872969179, 0.034992001950740814, 0.07693471014499664, 0.6160236369935006, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 205 0.0006000000000000001 256 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 5s - loss: 0.0368 - val_loss: 0.0195 - 5s/epoch - 12ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0160 - val_loss: 0.1284 - 2s/epoch - 5ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0159 - val_loss: 0.0198 - 2s/epoch - 4ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0146 - val_loss: 0.0178 - 2s/epoch - 4ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0156 - 2s/epoch - 4ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0139 - val_loss: 0.0172 - 2s/epoch - 4ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0134 - val_loss: 0.0144 - 2s/epoch - 4ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0153 - 2s/epoch - 5ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0124 - val_loss: 0.0128 - 2s/epoch - 4ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0143 - 2s/epoch - 4ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0125 - 2s/epoch - 4ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0133 - 2s/epoch - 4ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0526 - 2s/epoch - 4ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0141 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0316 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0190 - val_loss: 0.0126 - 2s/epoch - 5ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0131 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0141 - val_loss: 0.0127 - 2s/epoch - 5ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0193 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0178 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0193 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0140 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0132 - 2s/epoch - 5ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0158 - val_loss: 0.0176 - 2s/epoch - 4ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0239 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0125 - 2s/epoch - 5ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009182559326291084
  1/332 [..............................] - ETA: 40s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s181/332 [===============>..............] - ETA: 0s228/332 [===================>..........] - ETA: 0s275/332 [=======================>......] - ETA: 0s322/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07038981737930551
cosine 0.055258698500285634
MAE: 0.034645196
RMSE: 0.0763125
r2: 0.6222091508596486
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 256, 205, 0.0006000000000000001, 0.2, 252, 0.009299404919147491, 0.009182559326291084, 0.07038981737930551, 0.055258698500285634, 0.0346451960504055, 0.07631249725818634, 0.6222091508596486, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 205 0.0008 256 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 4s - loss: 0.0377 - val_loss: 0.0278 - 4s/epoch - 11ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0163 - val_loss: 0.0292 - 2s/epoch - 4ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0154 - val_loss: 0.0217 - 2s/epoch - 4ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0147 - val_loss: 0.0280 - 2s/epoch - 4ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0147 - val_loss: 0.0207 - 2s/epoch - 5ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0140 - val_loss: 0.0269 - 2s/epoch - 5ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0144 - val_loss: 0.0174 - 2s/epoch - 5ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0150 - 2s/epoch - 5ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0125 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.1403 - 2s/epoch - 5ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0180 - val_loss: 0.0129 - 2s/epoch - 5ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0128 - 2s/epoch - 4ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0131 - 2s/epoch - 4ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0152 - 2s/epoch - 4ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0145 - 2s/epoch - 4ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0140 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0123 - 2s/epoch - 5ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0166 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0143 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0201 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0149 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0140 - 2s/epoch - 5ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0165 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0125 - 2s/epoch - 4ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0132 - 2s/epoch - 4ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00922821182757616
  1/332 [..............................] - ETA: 40s 47/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s227/332 [===================>..........] - ETA: 0s273/332 [=======================>......] - ETA: 0s319/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07254599040402945
cosine 0.05695644588884748
MAE: 0.035239227
RMSE: 0.077423
r2: 0.6111339021396291
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 256, 205, 0.0008, 0.2, 252, 0.009335137903690338, 0.00922821182757616, 0.07254599040402945, 0.05695644588884748, 0.03523922711610794, 0.07742299884557724, 0.6111339021396291, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.001 128 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
747/747 - 5s - loss: 0.0293 - val_loss: 0.0213 - 5s/epoch - 7ms/step
Epoch 2/200
747/747 - 3s - loss: 0.0155 - val_loss: 0.0166 - 3s/epoch - 4ms/step
Epoch 3/200
747/747 - 3s - loss: 0.0144 - val_loss: 0.0149 - 3s/epoch - 4ms/step
Epoch 4/200
747/747 - 3s - loss: 0.0136 - val_loss: 0.0151 - 3s/epoch - 4ms/step
Epoch 5/200
747/747 - 3s - loss: 0.0129 - val_loss: 0.0137 - 3s/epoch - 4ms/step
Epoch 6/200
747/747 - 3s - loss: 0.0122 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 7/200
747/747 - 3s - loss: 0.0118 - val_loss: 0.0152 - 3s/epoch - 4ms/step
Epoch 8/200
747/747 - 3s - loss: 0.0117 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 9/200
747/747 - 3s - loss: 0.0113 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 10/200
747/747 - 3s - loss: 0.0110 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 11/200
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 12/200
747/747 - 3s - loss: 0.0107 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 13/200
747/747 - 3s - loss: 0.0109 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 14/200
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 15/200
747/747 - 3s - loss: 0.0138 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 16/200
747/747 - 3s - loss: 0.0123 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 17/200
747/747 - 3s - loss: 0.0124 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 18/200
747/747 - 3s - loss: 0.0108 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 19/200
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 20/200
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 21/200
747/747 - 3s - loss: 0.0111 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 22/200
747/747 - 3s - loss: 0.0135 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 23/200
747/747 - 3s - loss: 0.0108 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 24/200
747/747 - 3s - loss: 0.0108 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 25/200
747/747 - 3s - loss: 0.0105 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 26/200
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 27/200
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 28/200
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 29/200
747/747 - 3s - loss: 0.0103 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 30/200
747/747 - 3s - loss: 0.0109 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 31/200
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 32/200
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 33/200
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 34/200
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 35/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 36/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 37/200
747/747 - 3s - loss: 0.0101 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 38/200
747/747 - 3s - loss: 0.0103 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 39/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 40/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 41/200
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 42/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 43/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 44/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 45/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 46/200
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 47/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 48/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 49/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 51/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 52/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 53/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 54/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 55/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 60/200
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 61/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 63/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 64/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 65/200
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 67/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/200
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/200
747/747 - 3s - loss: 0.0095 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/200
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 187/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 189/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 192/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 194/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 195/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 196/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 197/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 198/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 199/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 200/200
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009150465950369835
  1/332 [..............................] - ETA: 45s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s218/332 [==================>...........] - ETA: 0s262/332 [======================>.......] - ETA: 0s306/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07019414596857775
cosine 0.05509602023752689
MAE: 0.034438368
RMSE: 0.0762772
r2: 0.6225586232109264
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 200, 0.001, 0.2, 252, 0.009324906393885612, 0.009150465950369835, 0.07019414596857775, 0.05509602023752689, 0.0344383679330349, 0.07627719640731812, 0.6225586232109264, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 205 0.0008 256 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE1.9_cr0.2_bs256_ep205_loss_mse_lr0.0008_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 44s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s224/332 [===================>..........] - ETA: 0s268/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07254599040402945
cosine 0.05695644588884748
MAE: 0.035239227
RMSE: 0.077423
r2: 0.6111339021396291
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['1.9custom_VAE', 'mse', 256, 205, 0.0008, 0.2, 252, '--', '--', 0.07254599040402945, 0.05695644588884748, 0.03523922711610794, 0.07742299884557724, 0.6111339021396291, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 205 0.0008 256 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 4s - loss: 0.0376 - val_loss: 0.0182 - 4s/epoch - 11ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0160 - val_loss: 0.0210 - 2s/epoch - 4ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0154 - val_loss: 0.0172 - 2s/epoch - 5ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0147 - val_loss: 0.0175 - 2s/epoch - 4ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0142 - val_loss: 0.0170 - 2s/epoch - 4ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0138 - val_loss: 0.0181 - 2s/epoch - 5ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0135 - val_loss: 0.0153 - 2s/epoch - 4ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0130 - val_loss: 0.0152 - 2s/epoch - 4ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0125 - val_loss: 0.0133 - 2s/epoch - 4ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0222 - 2s/epoch - 4ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0492 - 2s/epoch - 5ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0144 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0121 - 2s/epoch - 5ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0168 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0121 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0137 - val_loss: 0.0122 - 2s/epoch - 5ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0141 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0148 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0128 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0139 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0139 - 2s/epoch - 5ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0212 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0166 - 2s/epoch - 4ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0141 - 2s/epoch - 4ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00919590424746275
  1/332 [..............................] - ETA: 40s 46/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s229/332 [===================>..........] - ETA: 0s276/332 [=======================>......] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07086111258054022
cosine 0.05563479724848805
MAE: 0.034729633
RMSE: 0.076546974
r2: 0.619884045367153
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 256, 205, 0.0008, 0.2, 252, 0.009291203692555428, 0.00919590424746275, 0.07086111258054022, 0.05563479724848805, 0.03472963348031044, 0.07654697448015213, 0.619884045367153, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_7.pkl
[1.7999999999999998 205 0.0008 256 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 4s - loss: 0.0208 - val_loss: 0.0167 - 4s/epoch - 11ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0085 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0080 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0078 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0079 - val_loss: 0.0084 - 2s/epoch - 5ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0076 - val_loss: 0.0084 - 2s/epoch - 5ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0074 - val_loss: 0.0088 - 2s/epoch - 4ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0073 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0072 - val_loss: 0.0075 - 2s/epoch - 4ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0070 - val_loss: 0.0075 - 2s/epoch - 4ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0069 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0082 - 2s/epoch - 4ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0083 - 2s/epoch - 4ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0085 - 2s/epoch - 4ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0069 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0071 - val_loss: 0.0080 - 2s/epoch - 4ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0091 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0074 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0090 - val_loss: 0.0076 - 2s/epoch - 4ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0138 - val_loss: 0.0083 - 2s/epoch - 4ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0070 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0067 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0067 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0068 - 2s/epoch - 5ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0085 - 2s/epoch - 4ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0085 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0071 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0073 - 2s/epoch - 4ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0067 - val_loss: 0.0071 - 2s/epoch - 4ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0080 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0080 - 2s/epoch - 4ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0090 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0066 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0069 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0086 - 2s/epoch - 5ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0070 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0073 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0065 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0064 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0073 - 2s/epoch - 4ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058930604718625546
  1/332 [..............................] - ETA: 43s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s142/332 [===========>..................] - ETA: 0s189/332 [================>.............] - ETA: 0s236/332 [====================>.........] - ETA: 0s284/332 [========================>.....] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11689132254864196
cosine 0.09145933394718746
MAE: 0.045045335
RMSE: 0.09734411
r2: 0.38527691910796613
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 256, 205, 0.0008, 0.2, 252, 0.0059250881895422935, 0.0058930604718625546, 0.11689132254864196, 0.09145933394718746, 0.045045334845781326, 0.09734410792589188, 0.38527691910796613, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 205 0.001 256 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/205
374/374 - 4s - loss: 0.0382 - val_loss: 0.0245 - 4s/epoch - 11ms/step
Epoch 2/205
374/374 - 2s - loss: 0.0161 - val_loss: 0.0764 - 2s/epoch - 4ms/step
Epoch 3/205
374/374 - 2s - loss: 0.0157 - val_loss: 0.0204 - 2s/epoch - 4ms/step
Epoch 4/205
374/374 - 2s - loss: 0.0145 - val_loss: 0.0195 - 2s/epoch - 4ms/step
Epoch 5/205
374/374 - 2s - loss: 0.0143 - val_loss: 0.0151 - 2s/epoch - 4ms/step
Epoch 6/205
374/374 - 2s - loss: 0.0136 - val_loss: 0.0176 - 2s/epoch - 4ms/step
Epoch 7/205
374/374 - 2s - loss: 0.0133 - val_loss: 0.0142 - 2s/epoch - 5ms/step
Epoch 8/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0139 - 2s/epoch - 4ms/step
Epoch 9/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0333 - 2s/epoch - 4ms/step
Epoch 10/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0147 - 2s/epoch - 4ms/step
Epoch 11/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0153 - 2s/epoch - 5ms/step
Epoch 12/205
374/374 - 2s - loss: 0.0117 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 13/205
374/374 - 2s - loss: 0.0116 - val_loss: 0.0188 - 2s/epoch - 5ms/step
Epoch 14/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 15/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 16/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 17/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 18/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 19/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 20/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 21/205
374/374 - 2s - loss: 0.0115 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 22/205
374/374 - 2s - loss: 0.0114 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 23/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 24/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 25/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 26/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 27/205
374/374 - 2s - loss: 0.0124 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 28/205
374/374 - 2s - loss: 0.0129 - val_loss: 0.0117 - 2s/epoch - 4ms/step
Epoch 29/205
374/374 - 2s - loss: 0.0127 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 30/205
374/374 - 2s - loss: 0.0131 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 31/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 32/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 33/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 34/205
374/374 - 2s - loss: 0.0109 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 35/205
374/374 - 2s - loss: 0.0157 - val_loss: 0.0122 - 2s/epoch - 4ms/step
Epoch 36/205
374/374 - 2s - loss: 0.0147 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 37/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 38/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 39/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 40/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 41/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 42/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 43/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 44/205
374/374 - 2s - loss: 0.0122 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 45/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 46/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0133 - 2s/epoch - 5ms/step
Epoch 47/205
374/374 - 2s - loss: 0.0167 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 48/205
374/374 - 2s - loss: 0.0108 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 49/205
374/374 - 2s - loss: 0.0123 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 50/205
374/374 - 2s - loss: 0.0135 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 51/205
374/374 - 2s - loss: 0.0106 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 52/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 53/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 54/205
374/374 - 2s - loss: 0.0113 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 55/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 56/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 57/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 58/205
374/374 - 2s - loss: 0.0110 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 59/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 60/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 61/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 62/205
374/374 - 2s - loss: 0.0120 - val_loss: 0.0124 - 2s/epoch - 4ms/step
Epoch 63/205
374/374 - 2s - loss: 0.0131 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 64/205
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 65/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 66/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 67/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 68/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 69/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 70/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 71/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 72/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 73/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 74/205
374/374 - 2s - loss: 0.0132 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 75/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 76/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 77/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 78/205
374/374 - 2s - loss: 0.0112 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 79/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 80/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0154 - 2s/epoch - 4ms/step
Epoch 81/205
374/374 - 2s - loss: 0.0169 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 82/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 83/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 84/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 85/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 86/205
374/374 - 2s - loss: 0.0104 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 87/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 88/205
374/374 - 2s - loss: 0.0118 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 89/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 90/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 91/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 92/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 93/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 94/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 95/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 96/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 97/205
374/374 - 2s - loss: 0.0119 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 98/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 99/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 100/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 101/205
374/374 - 2s - loss: 0.0111 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 102/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 103/205
374/374 - 2s - loss: 0.0193 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 104/205
374/374 - 2s - loss: 0.0102 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 105/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 106/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 107/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 108/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 109/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 110/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 111/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 112/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 113/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0124 - 2s/epoch - 4ms/step
Epoch 114/205
374/374 - 2s - loss: 0.0126 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 115/205
374/374 - 2s - loss: 0.0099 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 116/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 117/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 118/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 119/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 120/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 121/205
374/374 - 2s - loss: 0.0101 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 122/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 123/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 124/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 125/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 126/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 127/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 128/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 129/205
374/374 - 2s - loss: 0.0105 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 130/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 131/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 132/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 133/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 134/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 135/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 136/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 137/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 138/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 139/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 140/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 141/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 142/205
374/374 - 2s - loss: 0.0100 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 143/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 144/205
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 145/205
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 146/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 147/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 148/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 149/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 150/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 151/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 152/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 153/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 154/205
374/374 - 2s - loss: 0.0098 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 155/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 156/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 157/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 158/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 159/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 160/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 161/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 162/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 163/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 164/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 165/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 166/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 167/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 168/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 169/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 170/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 171/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 172/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 173/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 174/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 175/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 176/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 177/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 178/205
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 179/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 180/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 181/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 182/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 183/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 184/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 185/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 186/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 187/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 188/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 189/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 190/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 191/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 192/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 193/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 194/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 195/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 196/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 197/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 198/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 199/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 200/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 201/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 202/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 203/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 204/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 205/205
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0092772813513875
  1/332 [..............................] - ETA: 36s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s117/332 [=========>....................] - ETA: 0s163/332 [=============>................] - ETA: 0s208/332 [=================>............] - ETA: 0s254/332 [=====================>........] - ETA: 0s301/332 [==========================>...] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.07192400952711943
cosine 0.05646185485924859
MAE: 0.035251305
RMSE: 0.07715414
r2: 0.6138302043247349
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 256, 205, 0.001, 0.2, 252, 0.009351585991680622, 0.0092772813513875, 0.07192400952711943, 0.05646185485924859, 0.035251304507255554, 0.07715413719415665, 0.6138302043247349, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 205 0.0008 256 2] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE1.7999999999999998_cr0.2_bs256_ep205_loss_logcosh_lr0.0008_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 35s 45/332 [===>..........................] - ETA: 0s  84/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s221/332 [==================>...........] - ETA: 0s267/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11689132254864196
cosine 0.09145933394718746
MAE: 0.045045335
RMSE: 0.09734411
r2: 0.38527691910796613
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['1.7999999999999998custom_VAE', 'logcosh', 256, 205, 0.0008, 0.2, 252, '--', '--', 0.11689132254864196, 0.09145933394718746, 0.045045334845781326, 0.09734410792589188, 0.38527691910796613, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_8.pkl
[1.6999999999999997 195 0.0006000000000000001 128 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 5s - loss: 0.0291 - val_loss: 0.0229 - 5s/epoch - 7ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0155 - val_loss: 0.0177 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0148 - val_loss: 0.0156 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0138 - val_loss: 0.0153 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0128 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0122 - val_loss: 0.0135 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0119 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0116 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0119 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0140 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0138 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0131 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0122 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0121 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0131 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0114 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0143 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0161 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0137 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0138 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009142471477389336
  1/332 [..............................] - ETA: 37s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s230/332 [===================>..........] - ETA: 0s277/332 [========================>.....] - ETA: 0s324/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.06903604216118196
cosine 0.05418588874859492
MAE: 0.034290943
RMSE: 0.07566037
r2: 0.6286386891625121
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 128, 195, 0.0006000000000000001, 0.2, 252, 0.009319731034338474, 0.009142471477389336, 0.06903604216118196, 0.05418588874859492, 0.034290943294763565, 0.07566037029027939, 0.6286386891625121, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 200 0.0006000000000000001 128 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/200
747/747 - 6s - loss: 0.0166 - val_loss: 0.0126 - 6s/epoch - 7ms/step
Epoch 2/200
747/747 - 3s - loss: 0.0086 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 3/200
747/747 - 3s - loss: 0.0081 - val_loss: 0.0087 - 3s/epoch - 4ms/step
Epoch 4/200
747/747 - 3s - loss: 0.0077 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 5/200
747/747 - 3s - loss: 0.0073 - val_loss: 0.0071 - 3s/epoch - 4ms/step
Epoch 6/200
747/747 - 3s - loss: 0.0070 - val_loss: 0.0075 - 3s/epoch - 4ms/step
Epoch 7/200
747/747 - 3s - loss: 0.0067 - val_loss: 0.0165 - 3s/epoch - 4ms/step
Epoch 8/200
747/747 - 3s - loss: 0.0066 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 9/200
747/747 - 3s - loss: 0.0065 - val_loss: 0.0142 - 3s/epoch - 4ms/step
Epoch 10/200
747/747 - 3s - loss: 0.0066 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0167 - 3s/epoch - 4ms/step
Epoch 12/200
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 14/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0072 - 3s/epoch - 4ms/step
Epoch 15/200
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 29/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 37/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 39/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 40/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 41/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 42/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 43/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 44/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 45/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 46/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 47/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 48/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 49/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 50/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 51/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 52/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 53/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 54/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 98/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 101/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 103/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 104/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 106/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 107/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 108/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 110/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 111/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 112/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 113/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 114/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 115/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 116/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 117/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 120/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 121/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 123/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 124/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 125/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 126/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 127/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 128/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 130/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 131/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 132/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 133/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 134/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 135/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 136/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 137/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 138/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 139/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 140/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 142/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 145/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 146/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 147/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 149/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 150/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 152/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 156/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 161/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 162/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 163/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 164/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 170/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 177/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 178/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 181/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 182/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 183/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 184/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 185/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 186/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 187/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 188/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 189/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 190/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 191/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 192/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 193/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 194/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 195/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 196/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 197/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 198/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 199/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 200/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058310870081186295
  1/332 [..............................] - ETA: 45s 45/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s184/332 [===============>..............] - ETA: 0s222/332 [===================>..........] - ETA: 0s266/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11109187355973431
cosine 0.08687438777357598
MAE: 0.04367768
RMSE: 0.09498261
r2: 0.4147406961543327
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 200, 0.0006000000000000001, 0.2, 252, 0.005878772120922804, 0.0058310870081186295, 0.11109187355973431, 0.08687438777357598, 0.0436776801943779, 0.09498260915279388, 0.4147406961543327, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0006000000000000001 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0289 - val_loss: 0.0179 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0154 - val_loss: 0.0248 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0144 - val_loss: 0.0153 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0132 - val_loss: 0.0299 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0126 - val_loss: 0.0166 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0122 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0189 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0120 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0121 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0130 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0114 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009224411100149155
  1/332 [..............................] - ETA: 45s 46/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s166/332 [==============>...............] - ETA: 0s211/332 [==================>...........] - ETA: 0s256/332 [======================>.......] - ETA: 0s302/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07191103841172854
cosine 0.05647784722579276
MAE: 0.03500738
RMSE: 0.07713655
r2: 0.6140063945412856
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 195, 0.0006000000000000001, 0.2, 252, 0.009390659630298615, 0.009224411100149155, 0.07191103841172854, 0.05647784722579276, 0.035007379949092865, 0.07713654637336731, 0.6140063945412856, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.0006000000000000001 128 2] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
747/747 - 5s - loss: 0.0154 - val_loss: 0.0193 - 5s/epoch - 7ms/step
Epoch 2/200
747/747 - 3s - loss: 0.0084 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 3/200
747/747 - 3s - loss: 0.0079 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 4/200
747/747 - 3s - loss: 0.0075 - val_loss: 0.0080 - 3s/epoch - 4ms/step
Epoch 5/200
747/747 - 3s - loss: 0.0072 - val_loss: 0.0076 - 3s/epoch - 4ms/step
Epoch 6/200
747/747 - 3s - loss: 0.0068 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 7/200
747/747 - 3s - loss: 0.0066 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 8/200
747/747 - 3s - loss: 0.0065 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 9/200
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 12/200
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 14/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 15/200
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 16/200
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 24/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 30/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 31/200
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/200
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 43/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/200
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 72/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/200
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 186/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 189/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 191/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 194/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 195/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 196/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 197/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 198/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 199/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 200/200
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005871106404811144
  1/332 [..............................] - ETA: 47s 46/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s222/332 [===================>..........] - ETA: 0s269/332 [=======================>......] - ETA: 0s316/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11461399495601654
cosine 0.08967197859147967
MAE: 0.04447872
RMSE: 0.096405596
r2: 0.3970732573814375
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 128, 200, 0.0006000000000000001, 0.2, 252, 0.005924280267208815, 0.005871106404811144, 0.11461399495601654, 0.08967197859147967, 0.04447871819138527, 0.09640559554100037, 0.3970732573814375, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_9.pkl
[1.5999999999999996 195 0.0006000000000000001 256 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
374/374 - 10s - loss: 0.0210 - val_loss: 0.0130 - 10s/epoch - 26ms/step
Epoch 2/195
374/374 - 2s - loss: 0.0083 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 3/195
374/374 - 2s - loss: 0.0080 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 4/195
374/374 - 2s - loss: 0.0078 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 5/195
374/374 - 2s - loss: 0.0076 - val_loss: 0.0086 - 2s/epoch - 4ms/step
Epoch 6/195
374/374 - 2s - loss: 0.0074 - val_loss: 0.0087 - 2s/epoch - 4ms/step
Epoch 7/195
374/374 - 2s - loss: 0.0073 - val_loss: 0.0081 - 2s/epoch - 4ms/step
Epoch 8/195
374/374 - 2s - loss: 0.0072 - val_loss: 0.0085 - 2s/epoch - 5ms/step
Epoch 9/195
374/374 - 2s - loss: 0.0071 - val_loss: 0.0328 - 2s/epoch - 4ms/step
Epoch 10/195
374/374 - 2s - loss: 0.0076 - val_loss: 0.0073 - 2s/epoch - 5ms/step
Epoch 11/195
374/374 - 2s - loss: 0.0069 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 12/195
374/374 - 2s - loss: 0.0066 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 13/195
374/374 - 2s - loss: 0.0065 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 14/195
374/374 - 2s - loss: 0.0066 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 15/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 16/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 17/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 18/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0534 - 2s/epoch - 5ms/step
Epoch 19/195
374/374 - 2s - loss: 0.0127 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 20/195
374/374 - 2s - loss: 0.0065 - val_loss: 0.0081 - 2s/epoch - 4ms/step
Epoch 21/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 22/195
374/374 - 2s - loss: 0.0071 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 23/195
374/374 - 2s - loss: 0.0065 - val_loss: 0.0073 - 2s/epoch - 4ms/step
Epoch 24/195
374/374 - 2s - loss: 0.0081 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 25/195
374/374 - 2s - loss: 0.0065 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 26/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 27/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0073 - 2s/epoch - 4ms/step
Epoch 28/195
374/374 - 2s - loss: 0.0081 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 29/195
374/374 - 2s - loss: 0.0065 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 30/195
374/374 - 2s - loss: 0.0083 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 31/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 32/195
374/374 - 2s - loss: 0.0067 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 33/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 34/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 35/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 36/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 37/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 38/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 39/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 40/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 41/195
374/374 - 2s - loss: 0.0075 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 42/195
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 43/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 44/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 45/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 46/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 47/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 48/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 49/195
374/374 - 2s - loss: 0.0064 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 50/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 51/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 52/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 53/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 54/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 55/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 56/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 57/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 58/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 59/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 60/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 61/195
374/374 - 2s - loss: 0.0063 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 62/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 63/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 64/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 65/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 66/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 67/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 68/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 69/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 70/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 71/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 72/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 73/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 74/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 75/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 76/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 77/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 78/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 79/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 80/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 81/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 82/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 83/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 84/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 85/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 86/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 87/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 88/195
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 89/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 90/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 91/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 92/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 93/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 94/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 95/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 96/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 97/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 98/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 99/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 100/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 101/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 102/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 103/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 104/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 105/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 106/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 107/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 108/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 109/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 110/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 111/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 112/195
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 113/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 114/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 115/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 116/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 117/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 118/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 119/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 120/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 121/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 122/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 123/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 124/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 125/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 126/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 127/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 128/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 129/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 130/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 131/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 132/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 133/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 134/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 135/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 136/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 137/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 138/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 139/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 140/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 141/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 142/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 143/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 144/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 145/195
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 146/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 147/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 148/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 149/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 150/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 151/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 152/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 153/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 154/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 155/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 156/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 157/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 158/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 159/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 160/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 161/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 162/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 163/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 164/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 165/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 166/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 167/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 168/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 169/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 170/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 171/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 172/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 173/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 174/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 175/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 176/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 177/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 178/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 179/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 180/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 181/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 182/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 183/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 184/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 185/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 186/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 187/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 188/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 189/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 190/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 191/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 192/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 193/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 194/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 195/195
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005867558531463146
  1/332 [..............................] - ETA: 41s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s232/332 [===================>..........] - ETA: 0s277/332 [========================>.....] - ETA: 0s324/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11638402952322904
cosine 0.09103330346916111
MAE: 0.04475104
RMSE: 0.09712174
r2: 0.3880822685182168
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 256, 195, 0.0006000000000000001, 0.2, 252, 0.0059152268804609776, 0.005867558531463146, 0.11638402952322904, 0.09103330346916111, 0.044751040637493134, 0.09712173789739609, 0.3880822685182168, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0006000000000000001 64 2] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 8s - loss: 0.0132 - val_loss: 0.0103 - 8s/epoch - 5ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0081 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 5s - loss: 0.0072 - val_loss: 0.0090 - 5s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 5s - loss: 0.0067 - val_loss: 0.0064 - 5s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 5s - loss: 0.0064 - val_loss: 0.0064 - 5s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 5s - loss: 0.0064 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005936556030064821
  1/332 [..............................] - ETA: 42s 47/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s233/332 [====================>.........] - ETA: 0s280/332 [========================>.....] - ETA: 0s327/332 [============================>.] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.11925214524544099
cosine 0.09328913619012326
MAE: 0.04549322
RMSE: 0.09830114
r2: 0.3731302045980076
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 64, 195, 0.0006000000000000001, 0.2, 252, 0.005992690566927195, 0.005936556030064821, 0.11925214524544099, 0.09328913619012326, 0.045493219047784805, 0.09830114245414734, 0.3731302045980076, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 0.0006000000000000001 128 1] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 5s - loss: 0.0285 - val_loss: 0.0250 - 5s/epoch - 7ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0154 - val_loss: 0.0172 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0143 - val_loss: 0.0142 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0135 - val_loss: 0.0137 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0128 - val_loss: 0.0222 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0125 - val_loss: 0.0128 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0119 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0117 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0115 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0119 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0118 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0114 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0111 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0118 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0111 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0113 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009184109978377819
  1/332 [..............................] - ETA: 45s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s141/332 [===========>..................] - ETA: 0s189/332 [================>.............] - ETA: 0s237/332 [====================>.........] - ETA: 0s284/332 [========================>.....] - ETA: 0s332/332 [==============================] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.06954595873457416
cosine 0.05462523408534614
MAE: 0.034448214
RMSE: 0.075889155
r2: 0.6263891739220631
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 128, 190, 0.0006000000000000001, 0.2, 252, 0.009331657551229, 0.009184109978377819, 0.06954595873457416, 0.05462523408534614, 0.03444821387529373, 0.07588915526866913, 0.6263891739220631, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0006000000000000001 256 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
374/374 - 4s - loss: 0.0383 - val_loss: 0.0217 - 4s/epoch - 10ms/step
Epoch 2/195
374/374 - 2s - loss: 0.0163 - val_loss: 0.0206 - 2s/epoch - 4ms/step
Epoch 3/195
374/374 - 2s - loss: 0.0150 - val_loss: 0.0171 - 2s/epoch - 4ms/step
Epoch 4/195
374/374 - 2s - loss: 0.0142 - val_loss: 0.0207 - 2s/epoch - 4ms/step
Epoch 5/195
374/374 - 2s - loss: 0.0141 - val_loss: 0.0156 - 2s/epoch - 4ms/step
Epoch 6/195
374/374 - 2s - loss: 0.0137 - val_loss: 0.0171 - 2s/epoch - 4ms/step
Epoch 7/195
374/374 - 2s - loss: 0.0134 - val_loss: 0.0177 - 2s/epoch - 4ms/step
Epoch 8/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0150 - 2s/epoch - 4ms/step
Epoch 9/195
374/374 - 2s - loss: 0.0128 - val_loss: 0.0135 - 2s/epoch - 4ms/step
Epoch 10/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0148 - 2s/epoch - 4ms/step
Epoch 11/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 12/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0813 - 2s/epoch - 4ms/step
Epoch 13/195
374/374 - 2s - loss: 0.0138 - val_loss: 0.0288 - 2s/epoch - 4ms/step
Epoch 14/195
374/374 - 2s - loss: 0.0133 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 15/195
374/374 - 2s - loss: 0.0114 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 16/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 17/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 18/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 19/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 20/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 21/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 22/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 23/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 24/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 25/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 26/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 27/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 28/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 29/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 30/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 31/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 32/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 33/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 34/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 35/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 36/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 37/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 38/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 39/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 40/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 41/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 42/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 43/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 44/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 45/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 46/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 47/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 48/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 49/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 50/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 51/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 52/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 53/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 54/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 55/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 56/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 57/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 58/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 59/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 60/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 61/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 62/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 63/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 64/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 65/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 66/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 67/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 68/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 69/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 70/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 71/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 72/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 73/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 74/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 75/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 76/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 77/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 78/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 79/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 80/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 81/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 82/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 83/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 84/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 85/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 86/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 87/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 88/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 89/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 90/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 91/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 92/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 93/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 94/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 95/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 96/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 97/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 98/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 99/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 100/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 101/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 102/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 103/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 104/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 105/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 106/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 107/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 108/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 109/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 110/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 111/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 112/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 113/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 114/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 115/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 116/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 117/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 118/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 119/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 120/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 121/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 122/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 123/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 124/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 125/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 126/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 127/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 128/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 129/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 130/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 131/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 132/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 133/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 134/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 135/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 136/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 137/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 138/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 139/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 140/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 141/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 142/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 143/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 144/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 145/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 146/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 147/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 148/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 149/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 150/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 151/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 152/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0093 - 2s/epoch - 4ms/step
Epoch 153/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 154/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 155/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 156/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 157/195
374/374 - 2s - loss: 0.0094 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 158/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 159/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 160/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 161/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 162/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 163/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 164/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 165/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 166/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 167/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 168/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 169/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 170/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 171/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 172/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 173/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 174/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 175/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 176/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 177/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 5ms/step
Epoch 178/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 179/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 180/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 181/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 182/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 183/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 184/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 185/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 186/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 187/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 188/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 189/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 190/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 191/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 192/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 193/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0091 - 2s/epoch - 4ms/step
Epoch 194/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
Epoch 195/195
374/374 - 2s - loss: 0.0093 - val_loss: 0.0092 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009182135574519634
  1/332 [..............................] - ETA: 40s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s226/332 [===================>..........] - ETA: 0s269/332 [=======================>......] - ETA: 0s315/332 [===========================>..] - ETA: 0s332/332 [==============================] - 0s 1ms/step
correlation 0.06921927752222513
cosine 0.05431936295401857
MAE: 0.034390107
RMSE: 0.0757443
r2: 0.6278143873754081
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 256, 195, 0.0006000000000000001, 0.2, 252, 0.00928103644400835, 0.009182135574519634, 0.06921927752222513, 0.05431936295401857, 0.03439010679721832, 0.07574430108070374, 0.6278143873754081, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 200 0.0006000000000000001 256 2] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 4s - loss: 0.0198 - val_loss: 0.0102 - 4s/epoch - 12ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0086 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0079 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0078 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0076 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0075 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0074 - val_loss: 0.0078 - 2s/epoch - 4ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0160 - 2s/epoch - 5ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0069 - val_loss: 0.0079 - 2s/epoch - 4ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0067 - val_loss: 0.0077 - 2s/epoch - 5ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0639 - 2s/epoch - 4ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0225 - 2s/epoch - 4ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0072 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0071 - 2s/epoch - 4ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0091 - 2s/epoch - 4ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0092 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0102 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0067 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0082 - val_loss: 0.0079 - 2s/epoch - 5ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0139 - val_loss: 0.0083 - 2s/epoch - 5ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0086 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0068 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0067 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0074 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0079 - 2s/epoch - 4ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0113 - 2s/epoch - 5ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0079 - val_loss: 0.0078 - 2s/epoch - 5ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0083 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0091 - 2s/epoch - 4ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005820002406835556
  1/332 [..............................] - ETA: 48s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s140/332 [===========>..................] - ETA: 0s187/332 [===============>..............] - ETA: 0s234/332 [====================>.........] - ETA: 0s279/332 [========================>.....] - ETA: 0s326/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11062785111370511
cosine 0.0865448097429139
MAE: 0.043631498
RMSE: 0.09476256
r2: 0.4174492000070168
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 256, 200, 0.0006000000000000001, 0.2, 252, 0.005867945961654186, 0.005820002406835556, 0.11062785111370511, 0.0865448097429139, 0.04363149777054787, 0.09476256370544434, 0.4174492000070168, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 195 0.0006000000000000001 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 5s - loss: 0.0293 - val_loss: 0.0195 - 5s/epoch - 7ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0155 - val_loss: 0.0171 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0146 - val_loss: 0.0652 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0142 - val_loss: 0.0543 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0138 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0121 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0117 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0116 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0189 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0119 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0125 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009152865037322044
  1/332 [..............................] - ETA: 50s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s228/332 [===================>..........] - ETA: 0s273/332 [=======================>......] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06947775289579199
cosine 0.0544841019973816
MAE: 0.03422335
RMSE: 0.075921565
r2: 0.626070255156544
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 128, 195, 0.0006000000000000001, 0.2, 252, 0.009316693060100079, 0.009152865037322044, 0.06947775289579199, 0.0544841019973816, 0.03422335162758827, 0.07592156529426575, 0.626070255156544, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 195 0.0006000000000000001 128 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0283 - val_loss: 0.0186 - 6s/epoch - 7ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0154 - val_loss: 0.0169 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0144 - val_loss: 0.0218 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0136 - val_loss: 0.0139 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0127 - val_loss: 0.0156 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0122 - val_loss: 0.0122 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0135 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0116 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0136 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009141508489847183
  1/332 [..............................] - ETA: 1:00 45/332 [===>..........................] - ETA: 0s   91/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s229/332 [===================>..........] - ETA: 0s275/332 [=======================>......] - ETA: 0s322/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06935237229566865
cosine 0.054444949182302964
MAE: 0.034308445
RMSE: 0.07579144
r2: 0.6273509110134865
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 128, 195, 0.0006000000000000001, 0.2, 252, 0.009301863610744476, 0.009141508489847183, 0.06935237229566865, 0.054444949182302964, 0.03430844470858574, 0.07579144090414047, 0.6273509110134865, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_10.pkl
[1.7999999999999998 195 0.0004000000000000001 128 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0297 - val_loss: 0.0199 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0157 - val_loss: 0.0189 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0145 - val_loss: 0.0155 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0136 - val_loss: 0.0145 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0128 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0122 - val_loss: 0.0126 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0134 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0117 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009099091403186321
  1/332 [..............................] - ETA: 54s 46/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s186/332 [===============>..............] - ETA: 0s232/332 [===================>..........] - ETA: 0s279/332 [========================>.....] - ETA: 0s326/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06783577885732892
cosine 0.05324356869014757
MAE: 0.033908796
RMSE: 0.07501949
r2: 0.6349031425866558
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 195, 0.0004000000000000001, 0.2, 252, 0.009254996664822102, 0.009099091403186321, 0.06783577885732892, 0.05324356869014757, 0.033908795565366745, 0.07501949369907379, 0.6349031425866558, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 185 0.0006000000000000001 128 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/185
747/747 - 6s - loss: 0.0286 - val_loss: 0.0197 - 6s/epoch - 8ms/step
Epoch 2/185
747/747 - 3s - loss: 0.0153 - val_loss: 0.0177 - 3s/epoch - 4ms/step
Epoch 3/185
747/747 - 3s - loss: 0.0142 - val_loss: 0.0143 - 3s/epoch - 4ms/step
Epoch 4/185
747/747 - 3s - loss: 0.0134 - val_loss: 0.0166 - 3s/epoch - 4ms/step
Epoch 5/185
747/747 - 3s - loss: 0.0126 - val_loss: 0.0134 - 3s/epoch - 4ms/step
Epoch 6/185
747/747 - 3s - loss: 0.0120 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 7/185
747/747 - 3s - loss: 0.0117 - val_loss: 0.0130 - 3s/epoch - 4ms/step
Epoch 8/185
747/747 - 3s - loss: 0.0114 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 9/185
747/747 - 3s - loss: 0.0112 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 10/185
747/747 - 3s - loss: 0.0109 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 11/185
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 12/185
747/747 - 3s - loss: 0.0107 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 13/185
747/747 - 3s - loss: 0.0108 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 14/185
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 15/185
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 16/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 17/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 18/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 19/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 20/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 21/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 22/185
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 23/185
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 24/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 25/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 26/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 27/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 28/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 29/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 30/185
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 31/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 32/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 33/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 34/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 35/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 36/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 37/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 38/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 39/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 40/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 41/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 42/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 44/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 45/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 47/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 51/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 53/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 54/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 55/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 56/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 57/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 58/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 67/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 70/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 71/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 74/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 99/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 100/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 107/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 110/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 112/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 122/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 156/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 157/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 159/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 162/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 165/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 168/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 169/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 172/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 173/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 175/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 177/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 178/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 179/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 180/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 181/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 182/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 184/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009122975170612335
  1/332 [..............................] - ETA: 1:07 46/332 [===>..........................] - ETA: 0s   92/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s229/332 [===================>..........] - ETA: 0s275/332 [=======================>......] - ETA: 0s321/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06866780180123182
cosine 0.05389785719982777
MAE: 0.034078345
RMSE: 0.07542113
r2: 0.6309832411238951
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 128, 185, 0.0006000000000000001, 0.2, 252, 0.00928744487464428, 0.009122975170612335, 0.06866780180123182, 0.05389785719982777, 0.03407834470272064, 0.07542113214731216, 0.6309832411238951, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 200 0.0006000000000000001 64 2] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/200
1493/1493 - 9s - loss: 0.0134 - val_loss: 0.0090 - 9s/epoch - 6ms/step
Epoch 2/200
1493/1493 - 6s - loss: 0.0081 - val_loss: 0.0079 - 6s/epoch - 4ms/step
Epoch 3/200
1493/1493 - 6s - loss: 0.0072 - val_loss: 0.0070 - 6s/epoch - 4ms/step
Epoch 4/200
1493/1493 - 5s - loss: 0.0068 - val_loss: 0.0066 - 5s/epoch - 4ms/step
Epoch 5/200
1493/1493 - 5s - loss: 0.0065 - val_loss: 0.0063 - 5s/epoch - 4ms/step
Epoch 6/200
1493/1493 - 5s - loss: 0.0064 - val_loss: 0.0063 - 5s/epoch - 4ms/step
Epoch 7/200
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 8/200
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 9/200
1493/1493 - 5s - loss: 0.0063 - val_loss: 0.0062 - 5s/epoch - 4ms/step
Epoch 10/200
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 11/200
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 13/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 14/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 15/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 16/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 17/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 18/200
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 19/200
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 20/200
1493/1493 - 5s - loss: 0.0062 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 21/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 22/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 23/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 24/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 25/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 26/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 27/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 28/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 29/200
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 30/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 31/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 32/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 33/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0061 - 5s/epoch - 4ms/step
Epoch 34/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 35/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 36/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 37/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 38/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 39/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 40/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 41/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 42/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 43/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 44/200
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 45/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 46/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 47/200
1493/1493 - 5s - loss: 0.0061 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 48/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 49/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 50/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 51/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 52/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 53/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 54/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 55/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 56/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 57/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 58/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 59/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 60/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 61/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 62/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 63/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 64/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 65/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 66/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 67/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 68/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 69/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 70/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 71/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 72/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 73/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 74/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 75/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 76/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 77/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 78/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 79/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 80/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 81/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 82/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 83/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 84/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 85/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 86/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 87/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 88/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 89/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 90/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0060 - 5s/epoch - 4ms/step
Epoch 91/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 92/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 93/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 94/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 95/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 96/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 97/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 98/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 99/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 100/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 101/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 102/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 103/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 104/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 105/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 106/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 107/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 108/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 109/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 110/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 111/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 112/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 114/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 115/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 116/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 117/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 118/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 119/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 120/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 121/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 122/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 123/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 124/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 125/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 126/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 127/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 128/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 129/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 130/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 131/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 132/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 133/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 134/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 135/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 136/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 138/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 139/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 140/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 141/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 142/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 143/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 144/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 145/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 146/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 147/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 148/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 149/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 151/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 152/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 153/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 154/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 155/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 156/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 157/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 158/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 159/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 160/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 161/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 162/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 163/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 164/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 165/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 166/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 167/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 168/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 169/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 170/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 171/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 172/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 173/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 174/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 175/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 176/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 177/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 178/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 179/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 180/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 181/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 182/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 183/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 184/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 185/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 186/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 187/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 188/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 189/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 190/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 191/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 192/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
Epoch 193/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 194/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 195/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 196/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 197/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 198/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 199/200
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 200/200
1493/1493 - 5s - loss: 0.0060 - val_loss: 0.0059 - 5s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005909879691898823
  1/332 [..............................] - ETA: 51s 45/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s170/332 [==============>...............] - ETA: 0s216/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s306/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11536356388871012
cosine 0.09029103665027446
MAE: 0.044682987
RMSE: 0.096808806
r2: 0.392019251281704
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 64, 200, 0.0006000000000000001, 0.2, 252, 0.005958906374871731, 0.005909879691898823, 0.11536356388871012, 0.09029103665027446, 0.04468298703432083, 0.09680880606174469, 0.392019251281704, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 195 0.0006000000000000001 64 1] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 8s - loss: 0.0250 - val_loss: 0.0177 - 8s/epoch - 6ms/step
Epoch 2/195
1493/1493 - 5s - loss: 0.0146 - val_loss: 0.0139 - 5s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 5s - loss: 0.0128 - val_loss: 0.0123 - 5s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 5s - loss: 0.0120 - val_loss: 0.0115 - 5s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 5s - loss: 0.0117 - val_loss: 0.0113 - 5s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 5s - loss: 0.0097 - val_loss: 0.0094 - 5s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009239373728632927
  1/332 [..............................] - ETA: 52s 45/332 [===>..........................] - ETA: 0s  89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s169/332 [==============>...............] - ETA: 0s215/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0704107218549425
cosine 0.05526103614030853
MAE: 0.03487935
RMSE: 0.07644319
r2: 0.6209145811679938
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 64, 195, 0.0006000000000000001, 0.2, 252, 0.009458854794502258, 0.009239373728632927, 0.0704107218549425, 0.05526103614030853, 0.034879349172115326, 0.07644318789243698, 0.6209145811679938, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 195 0.0004000000000000001 64 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 9s - loss: 0.0241 - val_loss: 0.0163 - 9s/epoch - 6ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0146 - val_loss: 0.0142 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 6s - loss: 0.0133 - val_loss: 0.0126 - 6s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 6s - loss: 0.0126 - val_loss: 0.0120 - 6s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 6s - loss: 0.0119 - val_loss: 0.0113 - 6s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009275199845433235
  1/332 [..............................] - ETA: 1:07 46/332 [===>..........................] - ETA: 0s   92/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s225/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07257357474502149
cosine 0.05699021398706612
MAE: 0.03522872
RMSE: 0.07751661
r2: 0.6101932802445256
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 195, 0.0004000000000000001, 0.2, 252, 0.009504564106464386, 0.009275199845433235, 0.07257357474502149, 0.05699021398706612, 0.03522872179746628, 0.07751660794019699, 0.6101932802445256, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 0.0006000000000000001 256 2] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
374/374 - 5s - loss: 0.0211 - val_loss: 0.0257 - 5s/epoch - 12ms/step
Epoch 2/190
374/374 - 2s - loss: 0.0087 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 3/190
374/374 - 2s - loss: 0.0082 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 4/190
374/374 - 2s - loss: 0.0080 - val_loss: 0.0131 - 2s/epoch - 4ms/step
Epoch 5/190
374/374 - 2s - loss: 0.0078 - val_loss: 0.0086 - 2s/epoch - 4ms/step
Epoch 6/190
374/374 - 2s - loss: 0.0077 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 7/190
374/374 - 2s - loss: 0.0075 - val_loss: 0.0090 - 2s/epoch - 4ms/step
Epoch 8/190
374/374 - 2s - loss: 0.0072 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 9/190
374/374 - 2s - loss: 0.0072 - val_loss: 0.0072 - 2s/epoch - 5ms/step
Epoch 10/190
374/374 - 2s - loss: 0.0070 - val_loss: 0.0071 - 2s/epoch - 4ms/step
Epoch 11/190
374/374 - 2s - loss: 0.0070 - val_loss: 0.0168 - 2s/epoch - 4ms/step
Epoch 12/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 13/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 14/190
374/374 - 2s - loss: 0.0065 - val_loss: 0.0534 - 2s/epoch - 4ms/step
Epoch 15/190
374/374 - 2s - loss: 0.0072 - val_loss: 0.0146 - 2s/epoch - 4ms/step
Epoch 16/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 17/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 18/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 19/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 20/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0140 - 2s/epoch - 4ms/step
Epoch 21/190
374/374 - 2s - loss: 0.0069 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 22/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 23/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 24/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 25/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 26/190
374/374 - 2s - loss: 0.0099 - val_loss: 0.0076 - 2s/epoch - 4ms/step
Epoch 27/190
374/374 - 2s - loss: 0.0127 - val_loss: 0.0078 - 2s/epoch - 4ms/step
Epoch 28/190
374/374 - 2s - loss: 0.0119 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 29/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 30/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 31/190
374/374 - 2s - loss: 0.0097 - val_loss: 0.0074 - 2s/epoch - 4ms/step
Epoch 32/190
374/374 - 2s - loss: 0.0069 - val_loss: 0.0089 - 2s/epoch - 4ms/step
Epoch 33/190
374/374 - 2s - loss: 0.0112 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 34/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 35/190
374/374 - 2s - loss: 0.0069 - val_loss: 0.0091 - 2s/epoch - 4ms/step
Epoch 36/190
374/374 - 2s - loss: 0.0104 - val_loss: 0.0071 - 2s/epoch - 4ms/step
Epoch 37/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 38/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 39/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0085 - 2s/epoch - 4ms/step
Epoch 40/190
374/374 - 2s - loss: 0.0103 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 41/190
374/374 - 2s - loss: 0.0069 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 42/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 43/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 44/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 45/190
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 46/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 47/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 48/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 49/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 50/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 51/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 52/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0073 - 2s/epoch - 4ms/step
Epoch 53/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 54/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0088 - 2s/epoch - 4ms/step
Epoch 55/190
374/374 - 2s - loss: 0.0085 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 56/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 57/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 58/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 59/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 60/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 61/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 62/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 63/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 64/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 65/190
374/374 - 2s - loss: 0.0100 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 66/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 67/190
374/374 - 2s - loss: 0.0107 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 68/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0071 - 2s/epoch - 4ms/step
Epoch 69/190
374/374 - 2s - loss: 0.0082 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 70/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 71/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 72/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 73/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 74/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 75/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 76/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 77/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 78/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 79/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 80/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 81/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 82/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 83/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 84/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 85/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 86/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 87/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 88/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 89/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 90/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 91/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 92/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 93/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 94/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 95/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 96/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 97/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 98/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 99/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 100/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 101/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 102/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 103/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 104/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 105/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 106/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 107/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 108/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 109/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 110/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 111/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 112/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 113/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 114/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 115/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 116/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 117/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 118/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 119/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 120/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 121/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 122/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 123/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 124/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 125/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 126/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 127/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 128/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 129/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 130/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 131/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 132/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 133/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 134/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 135/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 136/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 137/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 138/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 139/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 140/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 141/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 142/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 143/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 144/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 145/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 146/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 147/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 148/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 149/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 150/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 151/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 152/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 153/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 154/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 155/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 156/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 157/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 158/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 159/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 160/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 161/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 162/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 163/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 164/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 165/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 166/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 167/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 168/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 169/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 170/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 171/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 172/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 173/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 174/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 175/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 176/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 177/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 178/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 179/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 180/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 181/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 182/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 183/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 184/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 185/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 186/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 187/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 188/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 189/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 190/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005832965485751629
  1/332 [..............................] - ETA: 1:06 47/332 [===>..........................] - ETA: 0s   93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s231/332 [===================>..........] - ETA: 0s278/332 [========================>.....] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11074864436916886
cosine 0.08661709960074053
MAE: 0.04333997
RMSE: 0.09489666
r2: 0.41579939651830794
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 256, 190, 0.0006000000000000001, 0.2, 252, 0.0058783432468771935, 0.005832965485751629, 0.11074864436916886, 0.08661709960074053, 0.04333997145295143, 0.09489665925502777, 0.41579939651830794, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 200 0.0004000000000000001 256 2] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/200
374/374 - 4s - loss: 0.0195 - val_loss: 0.0134 - 4s/epoch - 12ms/step
Epoch 2/200
374/374 - 2s - loss: 0.0085 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 3/200
374/374 - 2s - loss: 0.0079 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 4/200
374/374 - 2s - loss: 0.0076 - val_loss: 0.0087 - 2s/epoch - 4ms/step
Epoch 5/200
374/374 - 2s - loss: 0.0075 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 6/200
374/374 - 2s - loss: 0.0074 - val_loss: 0.0135 - 2s/epoch - 4ms/step
Epoch 7/200
374/374 - 2s - loss: 0.0073 - val_loss: 0.0088 - 2s/epoch - 5ms/step
Epoch 8/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0083 - 2s/epoch - 4ms/step
Epoch 9/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0080 - 2s/epoch - 4ms/step
Epoch 10/200
374/374 - 2s - loss: 0.0070 - val_loss: 0.0211 - 2s/epoch - 4ms/step
Epoch 11/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 12/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 13/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0565 - 2s/epoch - 4ms/step
Epoch 14/200
374/374 - 2s - loss: 0.0080 - val_loss: 0.0075 - 2s/epoch - 4ms/step
Epoch 15/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 16/200
374/374 - 2s - loss: 0.0072 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 17/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 18/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 19/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 20/200
374/374 - 2s - loss: 0.0068 - val_loss: 0.0073 - 2s/epoch - 5ms/step
Epoch 21/200
374/374 - 2s - loss: 0.0090 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 22/200
374/374 - 2s - loss: 0.0073 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 23/200
374/374 - 2s - loss: 0.0072 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 24/200
374/374 - 2s - loss: 0.0110 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 25/200
374/374 - 2s - loss: 0.0068 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 26/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 27/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 28/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 29/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 30/200
374/374 - 2s - loss: 0.0099 - val_loss: 0.0077 - 2s/epoch - 4ms/step
Epoch 31/200
374/374 - 2s - loss: 0.0123 - val_loss: 0.0070 - 2s/epoch - 4ms/step
Epoch 32/200
374/374 - 2s - loss: 0.0073 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 33/200
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 34/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 35/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0072 - 2s/epoch - 4ms/step
Epoch 36/200
374/374 - 2s - loss: 0.0091 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 37/200
374/374 - 2s - loss: 0.0069 - val_loss: 0.0066 - 2s/epoch - 4ms/step
Epoch 38/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 4ms/step
Epoch 39/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 40/200
374/374 - 2s - loss: 0.0070 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 41/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 42/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 43/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 44/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 45/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 46/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 47/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 48/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0067 - 2s/epoch - 4ms/step
Epoch 49/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 50/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0068 - 2s/epoch - 4ms/step
Epoch 51/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 52/200
374/374 - 2s - loss: 0.0068 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 53/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 54/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 55/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0069 - 2s/epoch - 4ms/step
Epoch 56/200
374/374 - 2s - loss: 0.0071 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 57/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 58/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 59/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 60/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 61/200
374/374 - 2s - loss: 0.0066 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 62/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 63/200
374/374 - 2s - loss: 0.0064 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 64/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 65/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 66/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 67/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 68/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 69/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0063 - 2s/epoch - 4ms/step
Epoch 70/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 4ms/step
Epoch 71/200
374/374 - 2s - loss: 0.0065 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 72/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 73/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 74/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 75/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 4ms/step
Epoch 76/200
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 77/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 78/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 4ms/step
Epoch 79/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 80/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 81/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 82/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 83/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 84/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 85/200
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 86/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 87/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 88/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 89/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 90/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 91/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 92/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 93/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 94/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 95/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 96/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 97/200
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 98/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 99/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 100/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 101/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 102/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 103/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 104/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 105/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 106/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 107/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 108/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 109/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 110/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 111/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 112/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 113/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 4ms/step
Epoch 114/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 115/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 116/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 117/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 118/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 119/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 120/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 121/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 122/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 123/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 124/200
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 125/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 126/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 127/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 128/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 129/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 130/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 131/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 132/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 133/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 134/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 135/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 136/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 137/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 138/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 139/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 140/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 141/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 142/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 143/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 144/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 145/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 146/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 147/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 148/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 149/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 150/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 151/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 152/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 153/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 154/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 155/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 156/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 157/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 158/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 159/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 160/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 161/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 162/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 163/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 164/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 165/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 166/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 167/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 168/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 169/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 170/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 171/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 172/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 173/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 174/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 175/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 176/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 177/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 178/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 179/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 180/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 181/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 182/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 183/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 184/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 185/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 186/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 187/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 188/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 189/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 190/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 191/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 4ms/step
Epoch 192/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 193/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 194/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 195/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 196/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 197/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 198/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 199/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 4ms/step
Epoch 200/200
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005838765762746334
  1/332 [..............................] - ETA: 1:01 44/332 [==>...........................] - ETA: 0s   90/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s181/332 [===============>..............] - ETA: 0s227/332 [===================>..........] - ETA: 0s273/332 [=======================>......] - ETA: 0s317/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11310390283870014
cosine 0.08846270540413927
MAE: 0.043988306
RMSE: 0.09582594
r2: 0.40430160365694573
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 256, 200, 0.0004000000000000001, 0.2, 252, 0.005879654549062252, 0.005838765762746334, 0.11310390283870014, 0.08846270540413927, 0.04398830607533455, 0.09582594037055969, 0.40430160365694573, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_11.pkl
[1.6999999999999997 195 0.0004000000000000001 64 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 9s - loss: 0.0248 - val_loss: 0.0182 - 9s/epoch - 6ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0145 - val_loss: 0.0138 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0125 - 6s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 6s - loss: 0.0122 - val_loss: 0.0121 - 6s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 6s - loss: 0.0120 - val_loss: 0.0115 - 6s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0116 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009245704859495163
  1/332 [..............................] - ETA: 1:00 46/332 [===>..........................] - ETA: 0s   93/332 [=======>......................] - ETA: 0s139/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s231/332 [===================>..........] - ETA: 0s277/332 [========================>.....] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07131722805367925
cosine 0.055978593789672924
MAE: 0.034963463
RMSE: 0.07686949
r2: 0.6166745982969014
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 64, 195, 0.0004000000000000001, 0.2, 252, 0.009484113194048405, 0.009245704859495163, 0.07131722805367925, 0.055978593789672924, 0.0349634625017643, 0.07686948776245117, 0.6166745982969014, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 0.0004000000000000001 128 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 6s - loss: 0.0288 - val_loss: 0.0211 - 6s/epoch - 8ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0153 - val_loss: 0.0228 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0143 - val_loss: 0.0145 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0135 - val_loss: 0.0244 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0127 - val_loss: 0.0126 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0120 - val_loss: 0.0232 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0121 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0114 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0112 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0113 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0114 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0118 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0115 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0112 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009185143746435642
  1/332 [..............................] - ETA: 58s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s229/332 [===================>..........] - ETA: 0s274/332 [=======================>......] - ETA: 0s319/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0707922350942437
cosine 0.055550884732065944
MAE: 0.034710955
RMSE: 0.0765941
r2: 0.6194158816043971
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 128, 190, 0.0004000000000000001, 0.2, 252, 0.009343083016574383, 0.009185143746435642, 0.0707922350942437, 0.055550884732065944, 0.03471095487475395, 0.07659409940242767, 0.6194158816043971, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 190 0.0006000000000000001 128 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 6s - loss: 0.0154 - val_loss: 0.0147 - 6s/epoch - 8ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0083 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0079 - val_loss: 0.0089 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0076 - val_loss: 0.0088 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0072 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0067 - val_loss: 0.0082 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0066 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0065 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0067 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0068 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005876393988728523
  1/332 [..............................] - ETA: 58s 45/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s226/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s317/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11600767408244528
cosine 0.0907091987984521
MAE: 0.044718813
RMSE: 0.09699288
r2: 0.3897049525650845
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 128, 190, 0.0006000000000000001, 0.2, 252, 0.005933725740760565, 0.005876393988728523, 0.11600767408244528, 0.0907091987984521, 0.04471881315112114, 0.09699288010597229, 0.3897049525650845, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 195 0.0004000000000000001 256 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
374/374 - 5s - loss: 0.0367 - val_loss: 0.0238 - 5s/epoch - 13ms/step
Epoch 2/195
374/374 - 2s - loss: 0.0155 - val_loss: 0.0187 - 2s/epoch - 4ms/step
Epoch 3/195
374/374 - 2s - loss: 0.0151 - val_loss: 0.1167 - 2s/epoch - 4ms/step
Epoch 4/195
374/374 - 2s - loss: 0.0158 - val_loss: 0.1089 - 2s/epoch - 5ms/step
Epoch 5/195
374/374 - 2s - loss: 0.0148 - val_loss: 0.0153 - 2s/epoch - 4ms/step
Epoch 6/195
374/374 - 2s - loss: 0.0135 - val_loss: 0.0162 - 2s/epoch - 5ms/step
Epoch 7/195
374/374 - 2s - loss: 0.0133 - val_loss: 0.0138 - 2s/epoch - 4ms/step
Epoch 8/195
374/374 - 2s - loss: 0.0130 - val_loss: 0.0212 - 2s/epoch - 4ms/step
Epoch 9/195
374/374 - 2s - loss: 0.0130 - val_loss: 0.0136 - 2s/epoch - 5ms/step
Epoch 10/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0136 - 2s/epoch - 4ms/step
Epoch 11/195
374/374 - 2s - loss: 0.0121 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 12/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0137 - 2s/epoch - 4ms/step
Epoch 13/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0153 - 2s/epoch - 5ms/step
Epoch 14/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0129 - 2s/epoch - 4ms/step
Epoch 15/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0176 - 2s/epoch - 4ms/step
Epoch 16/195
374/374 - 2s - loss: 0.0122 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 17/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0120 - 2s/epoch - 4ms/step
Epoch 18/195
374/374 - 2s - loss: 0.0116 - val_loss: 0.0131 - 2s/epoch - 4ms/step
Epoch 19/195
374/374 - 2s - loss: 0.0142 - val_loss: 0.0133 - 2s/epoch - 5ms/step
Epoch 20/195
374/374 - 2s - loss: 0.0294 - val_loss: 0.0139 - 2s/epoch - 4ms/step
Epoch 21/195
374/374 - 2s - loss: 0.0289 - val_loss: 0.0184 - 2s/epoch - 4ms/step
Epoch 22/195
374/374 - 2s - loss: 0.0132 - val_loss: 0.0123 - 2s/epoch - 4ms/step
Epoch 23/195
374/374 - 2s - loss: 0.0126 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 24/195
374/374 - 2s - loss: 0.0137 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 25/195
374/374 - 2s - loss: 0.0137 - val_loss: 0.0136 - 2s/epoch - 4ms/step
Epoch 26/195
374/374 - 2s - loss: 0.0223 - val_loss: 0.0126 - 2s/epoch - 4ms/step
Epoch 27/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0119 - 2s/epoch - 4ms/step
Epoch 28/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 29/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 30/195
374/374 - 2s - loss: 0.0125 - val_loss: 0.0114 - 2s/epoch - 4ms/step
Epoch 31/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0112 - 2s/epoch - 5ms/step
Epoch 32/195
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 33/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 34/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0109 - 2s/epoch - 5ms/step
Epoch 35/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 36/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 37/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 38/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 39/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 40/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 41/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0134 - 2s/epoch - 4ms/step
Epoch 42/195
374/374 - 2s - loss: 0.0154 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 43/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0118 - 2s/epoch - 5ms/step
Epoch 44/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0160 - 2s/epoch - 4ms/step
Epoch 45/195
374/374 - 2s - loss: 0.0254 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 46/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0125 - 2s/epoch - 4ms/step
Epoch 47/195
374/374 - 2s - loss: 0.0152 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 48/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 49/195
374/374 - 2s - loss: 0.0114 - val_loss: 0.0159 - 2s/epoch - 4ms/step
Epoch 50/195
374/374 - 2s - loss: 0.0333 - val_loss: 0.0128 - 2s/epoch - 5ms/step
Epoch 51/195
374/374 - 2s - loss: 0.0144 - val_loss: 0.0163 - 2s/epoch - 5ms/step
Epoch 52/195
374/374 - 2s - loss: 0.0352 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 53/195
374/374 - 2s - loss: 0.0124 - val_loss: 0.0120 - 2s/epoch - 5ms/step
Epoch 54/195
374/374 - 2s - loss: 0.0119 - val_loss: 0.0115 - 2s/epoch - 4ms/step
Epoch 55/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0166 - 2s/epoch - 4ms/step
Epoch 56/195
374/374 - 2s - loss: 0.0281 - val_loss: 0.0121 - 2s/epoch - 4ms/step
Epoch 57/195
374/374 - 2s - loss: 0.0120 - val_loss: 0.0116 - 2s/epoch - 5ms/step
Epoch 58/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 59/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 60/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 61/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 62/195
374/374 - 2s - loss: 0.0113 - val_loss: 0.0194 - 2s/epoch - 4ms/step
Epoch 63/195
374/374 - 2s - loss: 0.0443 - val_loss: 0.0127 - 2s/epoch - 4ms/step
Epoch 64/195
374/374 - 2s - loss: 0.0123 - val_loss: 0.0115 - 2s/epoch - 5ms/step
Epoch 65/195
374/374 - 2s - loss: 0.0117 - val_loss: 0.0113 - 2s/epoch - 4ms/step
Epoch 66/195
374/374 - 2s - loss: 0.0114 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 67/195
374/374 - 2s - loss: 0.0112 - val_loss: 0.0110 - 2s/epoch - 4ms/step
Epoch 68/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 69/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 70/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 71/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 72/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 4ms/step
Epoch 73/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 74/195
374/374 - 2s - loss: 0.0110 - val_loss: 0.0208 - 2s/epoch - 5ms/step
Epoch 75/195
374/374 - 2s - loss: 0.0253 - val_loss: 0.0118 - 2s/epoch - 4ms/step
Epoch 76/195
374/374 - 2s - loss: 0.0115 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 77/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0111 - 2s/epoch - 4ms/step
Epoch 78/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0108 - 2s/epoch - 4ms/step
Epoch 79/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 80/195
374/374 - 2s - loss: 0.0107 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 81/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 82/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 83/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 84/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 85/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0140 - 2s/epoch - 4ms/step
Epoch 86/195
374/374 - 2s - loss: 0.0159 - val_loss: 0.0108 - 2s/epoch - 5ms/step
Epoch 87/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0106 - 2s/epoch - 5ms/step
Epoch 88/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0127 - 2s/epoch - 5ms/step
Epoch 89/195
374/374 - 2s - loss: 0.0118 - val_loss: 0.0104 - 2s/epoch - 5ms/step
Epoch 90/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 91/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 92/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 93/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0110 - 2s/epoch - 5ms/step
Epoch 94/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 95/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 96/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0104 - 2s/epoch - 4ms/step
Epoch 97/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 98/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 99/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 100/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 101/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0216 - 2s/epoch - 4ms/step
Epoch 102/195
374/374 - 2s - loss: 0.0144 - val_loss: 0.0103 - 2s/epoch - 4ms/step
Epoch 103/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0161 - 2s/epoch - 4ms/step
Epoch 104/195
374/374 - 2s - loss: 0.0166 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 105/195
374/374 - 2s - loss: 0.0104 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 106/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 107/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 108/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 4ms/step
Epoch 109/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0161 - 2s/epoch - 5ms/step
Epoch 110/195
374/374 - 2s - loss: 0.0187 - val_loss: 0.0105 - 2s/epoch - 5ms/step
Epoch 111/195
374/374 - 2s - loss: 0.0105 - val_loss: 0.0102 - 2s/epoch - 4ms/step
Epoch 112/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 113/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 114/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0105 - 2s/epoch - 4ms/step
Epoch 115/195
374/374 - 2s - loss: 0.0108 - val_loss: 0.0116 - 2s/epoch - 4ms/step
Epoch 116/195
374/374 - 2s - loss: 0.0109 - val_loss: 0.0103 - 2s/epoch - 5ms/step
Epoch 117/195
374/374 - 2s - loss: 0.0102 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 118/195
374/374 - 2s - loss: 0.0101 - val_loss: 0.0100 - 2s/epoch - 5ms/step
Epoch 119/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 120/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 121/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 122/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 123/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 5ms/step
Epoch 124/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 125/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 126/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 127/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 128/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0099 - 2s/epoch - 4ms/step
Epoch 129/195
374/374 - 2s - loss: 0.0099 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 130/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0130 - 2s/epoch - 4ms/step
Epoch 131/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0114 - 2s/epoch - 5ms/step
Epoch 132/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 133/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 134/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 135/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0143 - 2s/epoch - 4ms/step
Epoch 136/195
374/374 - 2s - loss: 0.0106 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 137/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 138/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0097 - 2s/epoch - 5ms/step
Epoch 139/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 140/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 141/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0098 - 2s/epoch - 5ms/step
Epoch 142/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 143/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 144/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 145/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 146/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 147/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0107 - 2s/epoch - 4ms/step
Epoch 148/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 149/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 150/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 151/195
374/374 - 2s - loss: 0.0100 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 152/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0112 - 2s/epoch - 4ms/step
Epoch 153/195
374/374 - 2s - loss: 0.0111 - val_loss: 0.0098 - 2s/epoch - 4ms/step
Epoch 154/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0109 - 2s/epoch - 4ms/step
Epoch 155/195
374/374 - 2s - loss: 0.0103 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 156/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0096 - 2s/epoch - 4ms/step
Epoch 157/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 158/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 159/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 160/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 161/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 162/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 163/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 164/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 165/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 166/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 167/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0101 - 2s/epoch - 4ms/step
Epoch 168/195
374/374 - 2s - loss: 0.0097 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 169/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 170/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 171/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 172/195
374/374 - 2s - loss: 0.0098 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 173/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 174/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 175/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 176/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 5ms/step
Epoch 177/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 178/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 179/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 180/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 181/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 182/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 183/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 184/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 185/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0097 - 2s/epoch - 4ms/step
Epoch 186/195
374/374 - 2s - loss: 0.0096 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 187/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 188/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 189/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 190/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 191/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0095 - 2s/epoch - 4ms/step
Epoch 192/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 193/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 194/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 4ms/step
Epoch 195/195
374/374 - 2s - loss: 0.0095 - val_loss: 0.0094 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009364129975438118
  1/332 [..............................] - ETA: 1:06 42/332 [==>...........................] - ETA: 0s   85/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s174/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s265/332 [======================>.......] - ETA: 0s310/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07452634557143635
cosine 0.05845826191359361
MAE: 0.035782054
RMSE: 0.07849966
r2: 0.600243494804184
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 256, 195, 0.0004000000000000001, 0.2, 252, 0.00948405358940363, 0.009364129975438118, 0.07452634557143635, 0.05845826191359361, 0.03578205406665802, 0.07849965989589691, 0.600243494804184, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0004000000000000001 64 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 9s - loss: 0.0249 - val_loss: 0.0192 - 9s/epoch - 6ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0146 - val_loss: 0.0198 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0133 - 6s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 6s - loss: 0.0122 - val_loss: 0.0120 - 6s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0113 - 6s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0115 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009311274625360966
  1/332 [..............................] - ETA: 1:00 44/332 [==>...........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s130/332 [==========>...................] - ETA: 0s174/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s262/332 [======================>.......] - ETA: 0s308/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07299171264581396
cosine 0.05734236629401069
MAE: 0.035515603
RMSE: 0.07779246
r2: 0.6074140289482884
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 64, 195, 0.0004000000000000001, 0.2, 252, 0.009513075463473797, 0.009311274625360966, 0.07299171264581396, 0.05734236629401069, 0.03551560267806053, 0.0777924582362175, 0.6074140289482884, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 195 0.0006000000000000001 128 2] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0154 - val_loss: 0.0126 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0083 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0079 - val_loss: 0.0086 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0075 - val_loss: 0.0220 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0073 - val_loss: 0.0071 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0068 - val_loss: 0.0081 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0083 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058497353456914425
  1/332 [..............................] - ETA: 54s 45/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s183/332 [===============>..............] - ETA: 0s228/332 [===================>..........] - ETA: 0s274/332 [=======================>......] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11248360346206575
cosine 0.08798810489169616
MAE: 0.043953843
RMSE: 0.09559252
r2: 0.40720044509463865
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 195, 0.0006000000000000001, 0.2, 252, 0.005898169241845608, 0.0058497353456914425, 0.11248360346206575, 0.08798810489169616, 0.04395384341478348, 0.09559252113103867, 0.40720044509463865, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.4999999999999996 195 0.0004000000000000001 64 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 1895)         2397175     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 1895)        7580        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 1895)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         2948323     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,308,662
Trainable params: 6,300,578
Non-trainable params: 8,084
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 12s - loss: 0.0239 - val_loss: 0.0172 - 12s/epoch - 8ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0144 - val_loss: 0.0142 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 6s - loss: 0.0131 - val_loss: 0.0126 - 6s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 6s - loss: 0.0116 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009228946641087532
  1/332 [..............................] - ETA: 57s 46/332 [===>..........................] - ETA: 0s  92/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s184/332 [===============>..............] - ETA: 0s230/332 [===================>..........] - ETA: 0s276/332 [=======================>......] - ETA: 0s322/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07095253244575984
cosine 0.055699172842920475
MAE: 0.03481257
RMSE: 0.07667021
r2: 0.618659506306636
RMSE zero-vector: 0.23411466903540806
['1.4999999999999996custom_VAE', 'mse', 64, 195, 0.0004000000000000001, 0.2, 252, 0.009484682232141495, 0.009228946641087532, 0.07095253244575984, 0.055699172842920475, 0.0348125696182251, 0.07667020708322525, 0.618659506306636, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_12.pkl
[1.5999999999999996 185 0.0004000000000000001 64 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/185
1493/1493 - 9s - loss: 0.0239 - val_loss: 0.0162 - 9s/epoch - 6ms/step
Epoch 2/185
1493/1493 - 6s - loss: 0.0143 - val_loss: 0.0164 - 6s/epoch - 4ms/step
Epoch 3/185
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0125 - 6s/epoch - 4ms/step
Epoch 4/185
1493/1493 - 6s - loss: 0.0122 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/185
1493/1493 - 6s - loss: 0.0118 - val_loss: 0.0114 - 6s/epoch - 4ms/step
Epoch 6/185
1493/1493 - 6s - loss: 0.0115 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 7/185
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/185
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 9/185
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 10/185
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 11/185
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/185
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/185
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/185
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/185
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/185
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 77/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 108/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 113/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 180/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 181/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009284915402531624
  1/332 [..............................] - ETA: 1:01 46/332 [===>..........................] - ETA: 0s   91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s227/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s311/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07274300267212894
cosine 0.057155290713321025
MAE: 0.035418797
RMSE: 0.077633165
r2: 0.6090199534493013
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 185, 0.0004000000000000001, 0.2, 252, 0.009491048753261566, 0.009284915402531624, 0.07274300267212894, 0.057155290713321025, 0.0354187972843647, 0.07763316482305527, 0.6090199534493013, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 0.0004000000000000001 128 2] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 6s - loss: 0.0157 - val_loss: 0.0118 - 6s/epoch - 8ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0082 - val_loss: 0.0086 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0077 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0074 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0071 - val_loss: 0.0071 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0068 - val_loss: 0.0068 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0066 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0065 - val_loss: 0.0146 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0067 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005843395832926035
  1/332 [..............................] - ETA: 56s 46/332 [===>..........................] - ETA: 0s  93/332 [=======>......................] - ETA: 0s138/332 [===========>..................] - ETA: 0s185/332 [===============>..............] - ETA: 0s231/332 [===================>..........] - ETA: 0s278/332 [========================>.....] - ETA: 0s324/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1140969409679315
cosine 0.08920190108415543
MAE: 0.044154793
RMSE: 0.09622326
r2: 0.3993517761630687
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 190, 0.0004000000000000001, 0.2, 252, 0.00590833555907011, 0.005843395832926035, 0.1140969409679315, 0.08920190108415543, 0.04415479302406311, 0.09622325748205185, 0.3993517761630687, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 190 0.0004000000000000001 128 1] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 6s - loss: 0.0291 - val_loss: 0.0210 - 6s/epoch - 8ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0157 - val_loss: 0.0344 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0154 - val_loss: 0.0146 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0137 - val_loss: 0.0144 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0130 - val_loss: 0.0323 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0136 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0119 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0114 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0112 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00912405177950859
  1/332 [..............................] - ETA: 1:14 46/332 [===>..........................] - ETA: 0s   91/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s181/332 [===============>..............] - ETA: 0s227/332 [===================>..........] - ETA: 0s261/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06872925803744923
cosine 0.053926454550178374
MAE: 0.034059547
RMSE: 0.0755125
r2: 0.6300886531843836
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 190, 0.0004000000000000001, 0.2, 252, 0.009287793189287186, 0.00912405177950859, 0.06872925803744923, 0.053926454550178374, 0.0340595468878746, 0.07551249861717224, 0.6300886531843836, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.0004000000000000001 128 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0152 - val_loss: 0.0141 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0085 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0080 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0076 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0073 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0069 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005821776110678911
  1/332 [..............................] - ETA: 1:07 45/332 [===>..........................] - ETA: 0s   90/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s177/332 [==============>...............] - ETA: 0s219/332 [==================>...........] - ETA: 0s263/332 [======================>.......] - ETA: 0s308/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11139146957224916
cosine 0.08712441581197833
MAE: 0.043662284
RMSE: 0.09515881
r2: 0.41256736705188063
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'logcosh', 128, 195, 0.0004000000000000001, 0.2, 252, 0.005883592646569014, 0.005821776110678911, 0.11139146957224916, 0.08712441581197833, 0.043662283569574356, 0.09515880793333054, 0.41256736705188063, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.4999999999999996 185 0.0006000000000000001 128 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 1895)         2397175     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 1895)        7580        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 1895)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         2948323     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,308,662
Trainable params: 6,300,578
Non-trainable params: 8,084
__________________________________________________________________________________________________
Epoch 1/185
747/747 - 6s - loss: 0.0279 - val_loss: 0.0194 - 6s/epoch - 8ms/step
Epoch 2/185
747/747 - 3s - loss: 0.0155 - val_loss: 0.0240 - 3s/epoch - 4ms/step
Epoch 3/185
747/747 - 3s - loss: 0.0146 - val_loss: 0.0166 - 3s/epoch - 4ms/step
Epoch 4/185
747/747 - 3s - loss: 0.0138 - val_loss: 0.0162 - 3s/epoch - 4ms/step
Epoch 5/185
747/747 - 3s - loss: 0.0132 - val_loss: 0.0131 - 3s/epoch - 4ms/step
Epoch 6/185
747/747 - 3s - loss: 0.0125 - val_loss: 0.0121 - 3s/epoch - 4ms/step
Epoch 7/185
747/747 - 3s - loss: 0.0120 - val_loss: 0.0131 - 3s/epoch - 4ms/step
Epoch 8/185
747/747 - 3s - loss: 0.0116 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 9/185
747/747 - 3s - loss: 0.0113 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 10/185
747/747 - 3s - loss: 0.0112 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 11/185
747/747 - 3s - loss: 0.0112 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 12/185
747/747 - 3s - loss: 0.0108 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 13/185
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 14/185
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 15/185
747/747 - 3s - loss: 0.0105 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 16/185
747/747 - 3s - loss: 0.0110 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 17/185
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 18/185
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 19/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 20/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 21/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 22/185
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 23/185
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 24/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 25/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 26/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 27/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 28/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 29/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 30/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 31/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 32/185
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 33/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 34/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 35/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 36/185
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 37/185
747/747 - 3s - loss: 0.0103 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 38/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 39/185
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 40/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 41/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 42/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 43/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 44/185
747/747 - 3s - loss: 0.0100 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 45/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 46/185
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 47/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 49/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 50/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 51/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 52/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 53/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 54/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 55/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 56/185
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 57/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 58/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 60/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 61/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 63/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 64/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 65/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 66/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 67/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 68/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 69/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 70/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 71/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 72/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 73/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 74/185
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 78/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 80/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 81/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 84/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 85/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 87/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 88/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 89/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 90/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 91/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 92/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 93/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 94/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 95/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 96/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 97/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 98/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 99/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 100/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 101/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 102/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 103/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 104/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 105/185
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 107/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 110/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 112/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 118/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 119/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 120/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 122/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 124/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 125/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 126/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 128/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 129/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 130/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 131/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 132/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 133/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 134/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 135/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 136/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 137/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 138/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 141/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 142/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 143/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 144/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 145/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 146/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 147/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 148/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 149/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 150/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 151/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 152/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 153/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 154/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 155/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 156/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 157/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 158/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 159/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 160/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 161/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 162/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 163/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 164/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 165/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 166/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 167/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 168/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 169/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 170/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 171/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 172/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 173/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 174/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 175/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 176/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 177/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 178/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 179/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 180/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 181/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 182/185
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 183/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 184/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 185/185
747/747 - 3s - loss: 0.0092 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009083514101803303
  1/332 [..............................] - ETA: 1:07 47/332 [===>..........................] - ETA: 0s   94/332 [=======>......................] - ETA: 0s141/332 [===========>..................] - ETA: 0s187/332 [===============>..............] - ETA: 0s232/332 [===================>..........] - ETA: 0s277/332 [========================>.....] - ETA: 0s322/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06706433964256427
cosine 0.05261214688010275
MAE: 0.03355333
RMSE: 0.07461584
r2: 0.6388213212254187
RMSE zero-vector: 0.23411466903540806
['1.4999999999999996custom_VAE', 'mse', 128, 185, 0.0006000000000000001, 0.2, 252, 0.009229911491274834, 0.009083514101803303, 0.06706433964256427, 0.05261214688010275, 0.03355332836508751, 0.07461584359407425, 0.6388213212254187, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 195 0.0006000000000000001 128 2] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0155 - val_loss: 0.0116 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0082 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0079 - val_loss: 0.0080 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0076 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0072 - val_loss: 0.0074 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0070 - val_loss: 0.0076 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0068 - val_loss: 0.0074 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0067 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058560981415212154
  1/332 [..............................] - ETA: 56s 46/332 [===>..........................] - ETA: 0s  91/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s179/332 [===============>..............] - ETA: 0s224/332 [===================>..........] - ETA: 0s269/332 [=======================>......] - ETA: 0s314/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11274078947236033
cosine 0.08812584451379032
MAE: 0.04391717
RMSE: 0.09573494
r2: 0.4054326953646702
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 195, 0.0006000000000000001, 0.2, 252, 0.005887570790946484, 0.0058560981415212154, 0.11274078947236033, 0.08812584451379032, 0.04391717165708542, 0.09573493897914886, 0.4054326953646702, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 195 0.0004000000000000001 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0288 - val_loss: 0.0173 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0152 - val_loss: 0.0179 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0142 - val_loss: 0.0141 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0133 - val_loss: 0.0285 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0127 - val_loss: 0.0122 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0121 - val_loss: 0.0134 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0118 - val_loss: 0.0141 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0120 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0119 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0128 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0126 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0112 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009206647984683514
  1/332 [..............................] - ETA: 1:02 46/332 [===>..........................] - ETA: 0s   92/332 [=======>......................] - ETA: 0s137/332 [===========>..................] - ETA: 0s182/332 [===============>..............] - ETA: 0s228/332 [===================>..........] - ETA: 0s272/332 [=======================>......] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0705358051620157
cosine 0.05540578407676005
MAE: 0.034793258
RMSE: 0.07647192
r2: 0.6206295296380436
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 128, 195, 0.0004000000000000001, 0.2, 252, 0.009351714514195919, 0.009206647984683514, 0.0705358051620157, 0.05540578407676005, 0.03479325771331787, 0.07647191733121872, 0.6206295296380436, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.7999999999999998 195 0.00020000000000000006 128 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2275)         2877875     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2275)        9100        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2275)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          573552      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3526303     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,560,382
Trainable params: 7,550,778
Non-trainable params: 9,604
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0294 - val_loss: 0.0196 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0160 - val_loss: 0.0162 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0144 - val_loss: 0.0154 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0137 - val_loss: 0.0145 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0131 - val_loss: 0.0131 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0127 - val_loss: 0.0130 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0122 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0116 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0113 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0128 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0128 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0108 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0152 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0162 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0110 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0138 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0153 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0126 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0181 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0134 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009213807992637157
  1/332 [..............................] - ETA: 1:13 43/332 [==>...........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s218/332 [==================>...........] - ETA: 0s262/332 [======================>.......] - ETA: 0s307/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07105393553854068
cosine 0.055776680454954396
MAE: 0.034862448
RMSE: 0.07668478
r2: 0.6185144139734904
RMSE zero-vector: 0.23411466903540806
['1.7999999999999998custom_VAE', 'mse', 128, 195, 0.00020000000000000006, 0.2, 252, 0.009371932595968246, 0.009213807992637157, 0.07105393553854068, 0.055776680454954396, 0.034862447530031204, 0.07668478041887283, 0.6185144139734904, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_13.pkl
[1.6999999999999997 190 0.0004000000000000001 64 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
1493/1493 - 9s - loss: 0.0130 - val_loss: 0.0135 - 9s/epoch - 6ms/step
Epoch 2/190
1493/1493 - 6s - loss: 0.0080 - val_loss: 0.0076 - 6s/epoch - 4ms/step
Epoch 3/190
1493/1493 - 6s - loss: 0.0070 - val_loss: 0.0068 - 6s/epoch - 4ms/step
Epoch 4/190
1493/1493 - 6s - loss: 0.0066 - val_loss: 0.0064 - 6s/epoch - 4ms/step
Epoch 5/190
1493/1493 - 6s - loss: 0.0064 - val_loss: 0.0063 - 6s/epoch - 4ms/step
Epoch 6/190
1493/1493 - 6s - loss: 0.0064 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 7/190
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0063 - 6s/epoch - 4ms/step
Epoch 8/190
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 9/190
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 10/190
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 11/190
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 13/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 14/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 15/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 16/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 17/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 18/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 19/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 20/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 21/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 22/190
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 23/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 24/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 25/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 26/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 27/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 28/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 29/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 30/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 31/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 32/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 33/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 34/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 35/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 36/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 37/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 38/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 39/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 40/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 41/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 42/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 43/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 44/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 45/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 46/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 47/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 48/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 49/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 50/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 51/190
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 52/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 53/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 54/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 55/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 56/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 57/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 58/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 59/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 60/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 61/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 62/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 63/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 64/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 65/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 66/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 67/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 68/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 69/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 70/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 71/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 72/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 73/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 74/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 75/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 76/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 77/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 78/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 79/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 80/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 81/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 82/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 83/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 84/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 85/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 86/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 87/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 88/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 89/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 90/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 91/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 92/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 93/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 94/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 95/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 96/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 97/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 98/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 99/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 100/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 101/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 102/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 103/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 104/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 105/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 106/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 107/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 108/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 109/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 110/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 111/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 112/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 114/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 115/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 116/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 117/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 118/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 119/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 120/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 121/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 122/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 123/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 124/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 125/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 126/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 127/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 128/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 129/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 130/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 131/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 132/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 133/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 134/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 135/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 136/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 138/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 139/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 140/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 141/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 142/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 143/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 144/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 145/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 146/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 147/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 148/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 149/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 151/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 152/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 153/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 154/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 155/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 156/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 157/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 158/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 159/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 160/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 161/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 162/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 163/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 164/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 165/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 166/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 167/190
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 168/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 169/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 170/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 171/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 172/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 173/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 174/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 175/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 176/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 177/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 178/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 179/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 180/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 181/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 182/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 183/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 184/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 185/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 186/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 187/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 188/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 189/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 190/190
1493/1493 - 6s - loss: 0.0059 - val_loss: 0.0059 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005890426691621542
  1/332 [..............................] - ETA: 59s 44/332 [==>...........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s136/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s225/332 [===================>..........] - ETA: 0s270/332 [=======================>......] - ETA: 0s314/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11206063697844058
cosine 0.08766478232413115
MAE: 0.043826174
RMSE: 0.09549809
r2: 0.40837089262004894
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 64, 190, 0.0004000000000000001, 0.2, 252, 0.005940382834523916, 0.005890426691621542, 0.11206063697844058, 0.08766478232413115, 0.04382617399096489, 0.09549809247255325, 0.40837089262004894, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 195 0.00020000000000000006 128 2] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 7s - loss: 0.0156 - val_loss: 0.0098 - 7s/epoch - 9ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0083 - val_loss: 0.0086 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0077 - val_loss: 0.0085 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0074 - val_loss: 0.0078 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0071 - val_loss: 0.0074 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0069 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0067 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0079 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0065 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005886687431484461
  1/332 [..............................] - ETA: 58s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s268/332 [=======================>......] - ETA: 0s314/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11445699215407107
cosine 0.08953669698135924
MAE: 0.044194825
RMSE: 0.096355855
r2: 0.39769508560204747
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 195, 0.00020000000000000006, 0.2, 252, 0.005919414572417736, 0.005886687431484461, 0.11445699215407107, 0.08953669698135924, 0.04419482499361038, 0.0963558554649353, 0.39769508560204747, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 195 0.0004000000000000001 64 1] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/195
1493/1493 - 9s - loss: 0.0251 - val_loss: 0.0164 - 9s/epoch - 6ms/step
Epoch 2/195
1493/1493 - 6s - loss: 0.0146 - val_loss: 0.0139 - 6s/epoch - 4ms/step
Epoch 3/195
1493/1493 - 6s - loss: 0.0129 - val_loss: 0.0121 - 6s/epoch - 4ms/step
Epoch 4/195
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0126 - 6s/epoch - 4ms/step
Epoch 5/195
1493/1493 - 6s - loss: 0.0119 - val_loss: 0.0114 - 6s/epoch - 4ms/step
Epoch 6/195
1493/1493 - 6s - loss: 0.0115 - val_loss: 0.0112 - 6s/epoch - 4ms/step
Epoch 7/195
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 8/195
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 9/195
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 10/195
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 11/195
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 12/195
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 13/195
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 14/195
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 15/195
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 16/195
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 17/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 18/195
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 19/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 20/195
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 21/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 22/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 23/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 24/195
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 25/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/195
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 29/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/195
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 34/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 37/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/195
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 49/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 51/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 53/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/195
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 66/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 68/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 69/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 70/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 71/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 72/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 73/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 74/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 75/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/195
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 105/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 106/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 110/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 111/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 112/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 114/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 115/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 117/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 121/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 122/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 124/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 127/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 132/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 138/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 142/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 155/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/195
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 170/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/195
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/195
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 177/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/195
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 184/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 191/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 192/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 193/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 194/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 195/195
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009295615367591381
  1/332 [..............................] - ETA: 1:04 43/332 [==>...........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s130/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s216/332 [==================>...........] - ETA: 0s257/332 [======================>.......] - ETA: 0s301/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07285057448055715
cosine 0.05720953592771501
MAE: 0.0352325
RMSE: 0.07767422
r2: 0.6086066808492867
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 64, 195, 0.0004000000000000001, 0.2, 252, 0.009515452198684216, 0.009295615367591381, 0.07285057448055715, 0.05720953592771501, 0.03523249924182892, 0.07767421752214432, 0.6086066808492867, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 0.0004000000000000001 256 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
374/374 - 6s - loss: 0.0198 - val_loss: 0.0099 - 6s/epoch - 15ms/step
Epoch 2/190
374/374 - 2s - loss: 0.0083 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 3/190
374/374 - 2s - loss: 0.0080 - val_loss: 0.0096 - 2s/epoch - 6ms/step
Epoch 4/190
374/374 - 2s - loss: 0.0077 - val_loss: 0.0099 - 2s/epoch - 6ms/step
Epoch 5/190
374/374 - 2s - loss: 0.0075 - val_loss: 0.0086 - 2s/epoch - 5ms/step
Epoch 6/190
374/374 - 2s - loss: 0.0074 - val_loss: 0.0093 - 2s/epoch - 5ms/step
Epoch 7/190
374/374 - 2s - loss: 0.0073 - val_loss: 0.0076 - 2s/epoch - 6ms/step
Epoch 8/190
374/374 - 2s - loss: 0.0070 - val_loss: 0.0156 - 2s/epoch - 5ms/step
Epoch 9/190
374/374 - 2s - loss: 0.0069 - val_loss: 0.0071 - 2s/epoch - 5ms/step
Epoch 10/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0193 - 2s/epoch - 5ms/step
Epoch 11/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 12/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0072 - 2s/epoch - 5ms/step
Epoch 13/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 14/190
374/374 - 2s - loss: 0.0065 - val_loss: 0.0211 - 2s/epoch - 5ms/step
Epoch 15/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 16/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 6ms/step
Epoch 17/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0076 - 2s/epoch - 5ms/step
Epoch 18/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0144 - 2s/epoch - 6ms/step
Epoch 19/190
374/374 - 2s - loss: 0.0110 - val_loss: 0.0075 - 2s/epoch - 6ms/step
Epoch 20/190
374/374 - 2s - loss: 0.0089 - val_loss: 0.0067 - 2s/epoch - 6ms/step
Epoch 21/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 22/190
374/374 - 2s - loss: 0.0065 - val_loss: 0.0063 - 2s/epoch - 6ms/step
Epoch 23/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 24/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 25/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 6ms/step
Epoch 26/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 27/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 28/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 29/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 30/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 31/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 32/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 33/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 34/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 35/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 36/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 37/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 38/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0070 - 2s/epoch - 6ms/step
Epoch 39/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0063 - 2s/epoch - 6ms/step
Epoch 40/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 41/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 42/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0066 - 2s/epoch - 6ms/step
Epoch 43/190
374/374 - 2s - loss: 0.0068 - val_loss: 0.0067 - 2s/epoch - 6ms/step
Epoch 44/190
374/374 - 2s - loss: 0.0071 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 45/190
374/374 - 2s - loss: 0.0066 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 46/190
374/374 - 2s - loss: 0.0065 - val_loss: 0.0068 - 2s/epoch - 5ms/step
Epoch 47/190
374/374 - 2s - loss: 0.0079 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 48/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 49/190
374/374 - 2s - loss: 0.0064 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 50/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 51/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 52/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 53/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 54/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 55/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 56/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 57/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 58/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 59/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 60/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 61/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 62/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 63/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 64/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 65/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 66/190
374/374 - 2s - loss: 0.0075 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 67/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0065 - 2s/epoch - 6ms/step
Epoch 68/190
374/374 - 2s - loss: 0.0073 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 69/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 70/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 71/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 72/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 73/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 74/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 75/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 76/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 77/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 78/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 79/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 80/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 81/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 82/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 83/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 84/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 85/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 86/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 87/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 88/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 89/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 90/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 91/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 92/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0072 - 2s/epoch - 6ms/step
Epoch 93/190
374/374 - 2s - loss: 0.0067 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 94/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 95/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 96/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 97/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0065 - 2s/epoch - 6ms/step
Epoch 98/190
374/374 - 2s - loss: 0.0063 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 99/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 100/190
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 101/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 102/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 103/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 104/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 105/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 106/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 107/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 108/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 109/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 110/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 111/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 112/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 113/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 114/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 115/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 116/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 117/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 118/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 119/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 120/190
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 121/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 122/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 123/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 124/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 125/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 126/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 127/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 128/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 129/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 130/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 131/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 132/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 133/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 134/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 135/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 136/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 137/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 138/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 139/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 140/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 141/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 142/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 143/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 144/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 145/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 146/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 147/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 148/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 149/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 150/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 151/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 152/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 153/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 154/190
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 155/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 156/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 157/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 158/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 159/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 160/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 161/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 162/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 163/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 164/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 165/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 166/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 167/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 168/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 169/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 170/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 171/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 172/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 173/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 174/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 175/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 176/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 177/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 178/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 179/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 180/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 181/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 182/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 183/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 184/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 185/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 186/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 187/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 188/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 189/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 190/190
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005843838211148977
  1/332 [..............................] - ETA: 1:01 45/332 [===>..........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s131/332 [==========>...................] - ETA: 0s176/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11322616444548884
cosine 0.08855863932704099
MAE: 0.044100016
RMSE: 0.09587684
r2: 0.4036687946251387
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 256, 190, 0.0004000000000000001, 0.2, 252, 0.005899722687900066, 0.005843838211148977, 0.11322616444548884, 0.08855863932704099, 0.044100016355514526, 0.09587684273719788, 0.4036687946251387, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 195 0.0004000000000000001 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 7s - loss: 0.0284 - val_loss: 0.0193 - 7s/epoch - 9ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0154 - val_loss: 0.0523 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0146 - val_loss: 0.0141 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0135 - val_loss: 0.0140 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0131 - val_loss: 0.0144 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0125 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0119 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0167 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0117 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0111 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0106 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0115 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0109 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0105 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0135 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0127 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0104 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0116 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 5ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0119 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0107 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0100 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 4s - loss: 0.0096 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 71/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 96/195
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 107/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 108/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 109/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 110/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 120/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 122/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 132/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 133/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 144/195
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 146/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 155/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 156/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 157/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 167/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 168/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 169/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 179/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 181/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 191/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 192/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 193/195
747/747 - 4s - loss: 0.0093 - val_loss: 0.0091 - 4s/epoch - 5ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009145992808043957
  1/332 [..............................] - ETA: 1:02 44/332 [==>...........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s177/332 [==============>...............] - ETA: 0s221/332 [==================>...........] - ETA: 0s264/332 [======================>.......] - ETA: 0s309/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06876176432802954
cosine 0.053990435013895076
MAE: 0.03416966
RMSE: 0.075508386
r2: 0.6301290093748554
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 128, 195, 0.0004000000000000001, 0.2, 252, 0.009272671304643154, 0.009145992808043957, 0.06876176432802954, 0.053990435013895076, 0.03416965901851654, 0.07550838589668274, 0.6301290093748554, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.9 190 0.0004000000000000001 128 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2401)         3037265     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2401)        9604        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2401)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          605304      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3717949     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,975,426
Trainable params: 7,965,318
Non-trainable params: 10,108
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 7s - loss: 0.0294 - val_loss: 0.0176 - 7s/epoch - 9ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0156 - val_loss: 0.0218 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0144 - val_loss: 0.0167 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0136 - val_loss: 0.0141 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0130 - val_loss: 0.0137 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0125 - val_loss: 0.0157 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 4s - loss: 0.0121 - val_loss: 0.0132 - 4s/epoch - 5ms/step
Epoch 8/190
747/747 - 4s - loss: 0.0117 - val_loss: 0.0118 - 4s/epoch - 6ms/step
Epoch 9/190
747/747 - 4s - loss: 0.0115 - val_loss: 0.0110 - 4s/epoch - 5ms/step
Epoch 10/190
747/747 - 4s - loss: 0.0111 - val_loss: 0.0111 - 4s/epoch - 5ms/step
Epoch 11/190
747/747 - 4s - loss: 0.0112 - val_loss: 0.0116 - 4s/epoch - 5ms/step
Epoch 12/190
747/747 - 4s - loss: 0.0115 - val_loss: 0.0107 - 4s/epoch - 5ms/step
Epoch 13/190
747/747 - 4s - loss: 0.0108 - val_loss: 0.0106 - 4s/epoch - 5ms/step
Epoch 14/190
747/747 - 4s - loss: 0.0107 - val_loss: 0.0105 - 4s/epoch - 5ms/step
Epoch 15/190
747/747 - 4s - loss: 0.0108 - val_loss: 0.0109 - 4s/epoch - 5ms/step
Epoch 16/190
747/747 - 4s - loss: 0.0120 - val_loss: 0.0117 - 4s/epoch - 5ms/step
Epoch 17/190
747/747 - 4s - loss: 0.0124 - val_loss: 0.0114 - 4s/epoch - 5ms/step
Epoch 18/190
747/747 - 4s - loss: 0.0117 - val_loss: 0.0107 - 4s/epoch - 5ms/step
Epoch 19/190
747/747 - 4s - loss: 0.0108 - val_loss: 0.0105 - 4s/epoch - 5ms/step
Epoch 20/190
747/747 - 4s - loss: 0.0107 - val_loss: 0.0104 - 4s/epoch - 5ms/step
Epoch 21/190
747/747 - 4s - loss: 0.0164 - val_loss: 0.0121 - 4s/epoch - 5ms/step
Epoch 22/190
747/747 - 4s - loss: 0.0151 - val_loss: 0.0110 - 4s/epoch - 5ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0111 - val_loss: 0.0109 - 3s/epoch - 5ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0113 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0138 - val_loss: 0.0146 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0233 - val_loss: 0.0113 - 3s/epoch - 5ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0114 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 4s - loss: 0.0113 - val_loss: 0.0107 - 4s/epoch - 5ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0107 - 3s/epoch - 5ms/step
Epoch 30/190
747/747 - 4s - loss: 0.0108 - val_loss: 0.0105 - 4s/epoch - 5ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0117 - 3s/epoch - 5ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0121 - val_loss: 0.0105 - 3s/epoch - 5ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0108 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0120 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0135 - 3s/epoch - 5ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0135 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 4s - loss: 0.0104 - val_loss: 0.0102 - 4s/epoch - 5ms/step
Epoch 43/190
747/747 - 4s - loss: 0.0103 - val_loss: 0.0102 - 4s/epoch - 5ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 5ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0108 - 3s/epoch - 5ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0151 - val_loss: 0.0107 - 3s/epoch - 5ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0109 - 3s/epoch - 5ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 4s - loss: 0.0101 - val_loss: 0.0099 - 4s/epoch - 5ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 60/190
747/747 - 4s - loss: 0.0100 - val_loss: 0.0101 - 4s/epoch - 5ms/step
Epoch 61/190
747/747 - 4s - loss: 0.0101 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 62/190
747/747 - 4s - loss: 0.0100 - val_loss: 0.0099 - 4s/epoch - 5ms/step
Epoch 63/190
747/747 - 4s - loss: 0.0100 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 64/190
747/747 - 4s - loss: 0.0099 - val_loss: 0.0098 - 4s/epoch - 5ms/step
Epoch 65/190
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 66/190
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 67/190
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 68/190
747/747 - 4s - loss: 0.0099 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 69/190
747/747 - 4s - loss: 0.0098 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 70/190
747/747 - 4s - loss: 0.0098 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 71/190
747/747 - 4s - loss: 0.0098 - val_loss: 0.0096 - 4s/epoch - 5ms/step
Epoch 72/190
747/747 - 4s - loss: 0.0098 - val_loss: 0.0097 - 4s/epoch - 5ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 5ms/step
Epoch 79/190
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 80/190
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 81/190
747/747 - 4s - loss: 0.0097 - val_loss: 0.0095 - 4s/epoch - 5ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 4s - loss: 0.0097 - val_loss: 0.0094 - 4s/epoch - 5ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 172/190
747/747 - 4s - loss: 0.0095 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 180/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 181/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 182/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 183/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 184/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 185/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 186/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 187/190
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009264973923563957
  1/332 [..............................] - ETA: 1:18 43/332 [==>...........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s178/332 [===============>..............] - ETA: 0s221/332 [==================>...........] - ETA: 0s264/332 [======================>.......] - ETA: 0s305/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0725063809382884
cosine 0.056941773081068445
MAE: 0.035306882
RMSE: 0.07737284
r2: 0.6116376695148993
RMSE zero-vector: 0.23411466903540806
['1.9custom_VAE', 'mse', 128, 190, 0.0004000000000000001, 0.2, 252, 0.009441914968192577, 0.009264973923563957, 0.0725063809382884, 0.056941773081068445, 0.03530688211321831, 0.07737284153699875, 0.6116376695148993, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_14.pkl
[1.5999999999999996 185 0.0006000000000000001 128 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/185
747/747 - 8s - loss: 0.0151 - val_loss: 0.0090 - 8s/epoch - 11ms/step
Epoch 2/185
747/747 - 4s - loss: 0.0082 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 3/185
747/747 - 4s - loss: 0.0078 - val_loss: 0.0135 - 4s/epoch - 6ms/step
Epoch 4/185
747/747 - 4s - loss: 0.0075 - val_loss: 0.0079 - 4s/epoch - 5ms/step
Epoch 5/185
747/747 - 4s - loss: 0.0071 - val_loss: 0.0070 - 4s/epoch - 5ms/step
Epoch 6/185
747/747 - 4s - loss: 0.0067 - val_loss: 0.0066 - 4s/epoch - 5ms/step
Epoch 7/185
747/747 - 4s - loss: 0.0065 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 8/185
747/747 - 4s - loss: 0.0064 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 9/185
747/747 - 4s - loss: 0.0064 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 10/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0065 - 4s/epoch - 5ms/step
Epoch 11/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 12/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 13/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 14/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 15/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 16/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 17/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 18/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 19/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 20/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 21/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 22/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0063 - 4s/epoch - 5ms/step
Epoch 23/185
747/747 - 4s - loss: 0.0064 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 24/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 25/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 26/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 27/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 28/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 29/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 30/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 31/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 32/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 33/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 34/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 35/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 36/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 37/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 38/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 39/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 40/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 41/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 42/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 43/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 44/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 45/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 46/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 47/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 48/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 49/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 50/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 51/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 52/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 53/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 54/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 55/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 56/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 57/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 58/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 59/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 60/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 61/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 62/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 63/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 64/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 65/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 66/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 67/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 68/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 69/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 70/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 71/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 72/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 73/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 74/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 75/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 76/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 77/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 78/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 79/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 80/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 81/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 82/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 83/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 84/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 85/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 86/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 87/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 88/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 89/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 90/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 91/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 92/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 93/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 94/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 95/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 96/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 97/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 98/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 99/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 100/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 101/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 102/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 103/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 104/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 105/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 106/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 107/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 108/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 109/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 110/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 111/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 112/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 113/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 114/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 115/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 116/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 117/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 118/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 119/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 120/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 121/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 122/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 123/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 124/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 125/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 126/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 127/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 128/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 129/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 130/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 131/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 132/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 133/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 134/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 135/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 136/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 137/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 138/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 139/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 140/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 141/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 142/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 143/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 144/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 145/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 146/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 147/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 148/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 149/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 150/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 151/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 152/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 153/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 154/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 155/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 156/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 157/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 158/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 159/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 160/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 161/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 162/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 163/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 164/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 165/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 166/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 167/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 168/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 169/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 170/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 171/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 172/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 173/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 174/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 175/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 176/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 177/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 178/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 179/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 180/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 181/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 182/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 183/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 184/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 185/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005849592853337526
  1/332 [..............................] - ETA: 1:12 43/332 [==>...........................] - ETA: 0s   74/332 [=====>........................] - ETA: 0s117/332 [=========>....................] - ETA: 0s158/332 [=============>................] - ETA: 0s199/332 [================>.............] - ETA: 0s234/332 [====================>.........] - ETA: 0s276/332 [=======================>......] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11292259227744238
cosine 0.08832971784828565
MAE: 0.04389956
RMSE: 0.09574949
r2: 0.4052518230518516
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 185, 0.0006000000000000001, 0.2, 252, 0.005908892024308443, 0.005849592853337526, 0.11292259227744238, 0.08832971784828565, 0.04389955848455429, 0.09574948996305466, 0.4052518230518516, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 180 0.0006000000000000001 128 2] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/180
747/747 - 8s - loss: 0.0158 - val_loss: 0.0100 - 8s/epoch - 11ms/step
Epoch 2/180
747/747 - 4s - loss: 0.0082 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 3/180
747/747 - 4s - loss: 0.0079 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 4/180
747/747 - 4s - loss: 0.0075 - val_loss: 0.0080 - 4s/epoch - 5ms/step
Epoch 5/180
747/747 - 4s - loss: 0.0072 - val_loss: 0.0078 - 4s/epoch - 5ms/step
Epoch 6/180
747/747 - 4s - loss: 0.0070 - val_loss: 0.0074 - 4s/epoch - 5ms/step
Epoch 7/180
747/747 - 4s - loss: 0.0068 - val_loss: 0.0066 - 4s/epoch - 5ms/step
Epoch 8/180
747/747 - 3s - loss: 0.0065 - val_loss: 0.0079 - 3s/epoch - 4ms/step
Epoch 9/180
747/747 - 3s - loss: 0.0066 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 11/180
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 18/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/180
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 20/180
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 21/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 23/180
747/747 - 3s - loss: 0.0069 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 24/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 25/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 26/180
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 27/180
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 28/180
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 29/180
747/747 - 4s - loss: 0.0063 - val_loss: 0.0069 - 4s/epoch - 5ms/step
Epoch 30/180
747/747 - 4s - loss: 0.0076 - val_loss: 0.0066 - 4s/epoch - 5ms/step
Epoch 31/180
747/747 - 4s - loss: 0.0070 - val_loss: 0.0063 - 4s/epoch - 5ms/step
Epoch 32/180
747/747 - 4s - loss: 0.0063 - val_loss: 0.0063 - 4s/epoch - 5ms/step
Epoch 33/180
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 34/180
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 35/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 36/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 37/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 38/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 39/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 40/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 41/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 42/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 43/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 44/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/180
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 47/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 51/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 60/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 65/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 68/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 69/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 73/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 153/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 155/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 156/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 157/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 158/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 161/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 162/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 174/180
747/747 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 6ms/step
Epoch 175/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 176/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 177/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 178/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 179/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 180/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005896249320358038
  1/332 [..............................] - ETA: 1:22 43/332 [==>...........................] - ETA: 0s   84/332 [======>.......................] - ETA: 0s127/332 [==========>...................] - ETA: 0s170/332 [==============>...............] - ETA: 0s212/332 [==================>...........] - ETA: 0s243/332 [====================>.........] - ETA: 0s286/332 [========================>.....] - ETA: 0s328/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11649014133801336
cosine 0.09110692108054903
MAE: 0.045155983
RMSE: 0.097173706
r2: 0.387427373490515
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 180, 0.0006000000000000001, 0.2, 252, 0.005941065959632397, 0.005896249320358038, 0.11649014133801336, 0.09110692108054903, 0.04515598341822624, 0.09717370569705963, 0.387427373490515, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 185 0.0006000000000000001 128 2] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
File geneticVAE_MMmp_gap_custom_VAE1.5999999999999996_cr0.2_bs128_ep185_loss_logcosh_lr0.0006000000000000001_AutoEncoder.h5 exists in folder already, skiping this calculation.
  1/332 [..............................] - ETA: 1:11 42/332 [==>...........................] - ETA: 0s   83/332 [======>.......................] - ETA: 0s125/332 [==========>...................] - ETA: 0s167/332 [==============>...............] - ETA: 0s209/332 [=================>............] - ETA: 0s251/332 [=====================>........] - ETA: 0s293/332 [=========================>....] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11292259227744238
cosine 0.08832971784828565
MAE: 0.04389956
RMSE: 0.09574949
r2: 0.4052518230518516
RMSE zero-vector: 0.23411466903540806
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
['1.5999999999999996custom_VAE', 'logcosh', 128, 185, 0.0006000000000000001, 0.2, 252, '--', '--', 0.11292259227744238, 0.08832971784828565, 0.04389955848455429, 0.09574948996305466, 0.4052518230518516, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 185 0.00020000000000000006 128 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/185
747/747 - 9s - loss: 0.0154 - val_loss: 0.0147 - 9s/epoch - 12ms/step
Epoch 2/185
747/747 - 4s - loss: 0.0081 - val_loss: 0.0141 - 4s/epoch - 5ms/step
Epoch 3/185
747/747 - 4s - loss: 0.0077 - val_loss: 0.0082 - 4s/epoch - 5ms/step
Epoch 4/185
747/747 - 4s - loss: 0.0074 - val_loss: 0.0076 - 4s/epoch - 5ms/step
Epoch 5/185
747/747 - 4s - loss: 0.0071 - val_loss: 0.0073 - 4s/epoch - 5ms/step
Epoch 6/185
747/747 - 4s - loss: 0.0070 - val_loss: 0.0074 - 4s/epoch - 5ms/step
Epoch 7/185
747/747 - 4s - loss: 0.0069 - val_loss: 0.0068 - 4s/epoch - 5ms/step
Epoch 8/185
747/747 - 4s - loss: 0.0068 - val_loss: 0.0146 - 4s/epoch - 5ms/step
Epoch 9/185
747/747 - 4s - loss: 0.0069 - val_loss: 0.0064 - 4s/epoch - 5ms/step
Epoch 10/185
747/747 - 4s - loss: 0.0064 - val_loss: 0.0063 - 4s/epoch - 5ms/step
Epoch 11/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0063 - 4s/epoch - 5ms/step
Epoch 12/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 6ms/step
Epoch 13/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 6ms/step
Epoch 14/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 15/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 16/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 17/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 18/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 19/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 20/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 21/185
747/747 - 4s - loss: 0.0063 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 22/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 6ms/step
Epoch 23/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 6ms/step
Epoch 24/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 6ms/step
Epoch 25/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 26/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 27/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 28/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 29/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 30/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 31/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 32/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 33/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 6ms/step
Epoch 34/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 6ms/step
Epoch 35/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 6ms/step
Epoch 36/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 37/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 38/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 6ms/step
Epoch 39/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 40/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 41/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 42/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 43/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 44/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 6ms/step
Epoch 45/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 46/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 47/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 48/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 49/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 50/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 51/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 52/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 53/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 54/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 55/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 56/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 57/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 58/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 59/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 60/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 61/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 62/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 63/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 64/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 65/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 66/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 67/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 68/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 69/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 70/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 71/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 72/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 73/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 74/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 75/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 76/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 77/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 78/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 79/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 80/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 81/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 82/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 83/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 84/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 85/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 86/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 87/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 88/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 89/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 90/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 91/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 92/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 93/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 94/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 95/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 96/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 97/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 98/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 99/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 100/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 101/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 102/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 103/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 104/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 105/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 106/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 107/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 108/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 109/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 110/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 111/185
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 112/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 113/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 114/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 115/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 116/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 117/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 118/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 119/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 120/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 121/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 122/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 123/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 124/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 125/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 126/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 127/185
747/747 - 5s - loss: 0.0059 - val_loss: 0.0059 - 5s/epoch - 6ms/step
Epoch 128/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 129/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 130/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 131/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 132/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 133/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 134/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 135/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 136/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 137/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 138/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 6ms/step
Epoch 139/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 140/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 141/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 142/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 143/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 151/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 162/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 176/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 177/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 178/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 181/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 183/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 184/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005832237657159567
  1/332 [..............................] - ETA: 1:00 45/332 [===>..........................] - ETA: 0s   90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s180/332 [===============>..............] - ETA: 0s216/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s307/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11200297221434687
cosine 0.08760274351317164
MAE: 0.043768737
RMSE: 0.0954039
r2: 0.4095373931270432
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 185, 0.00020000000000000006, 0.2, 252, 0.005892026703804731, 0.005832237657159567, 0.11200297221434687, 0.08760274351317164, 0.043768737465143204, 0.09540390223264694, 0.4095373931270432, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 180 0.0008 128 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/180
747/747 - 6s - loss: 0.0294 - val_loss: 0.0181 - 6s/epoch - 8ms/step
Epoch 2/180
747/747 - 3s - loss: 0.0153 - val_loss: 0.0172 - 3s/epoch - 4ms/step
Epoch 3/180
747/747 - 3s - loss: 0.0142 - val_loss: 0.0143 - 3s/epoch - 4ms/step
Epoch 4/180
747/747 - 3s - loss: 0.0135 - val_loss: 0.0154 - 3s/epoch - 4ms/step
Epoch 5/180
747/747 - 3s - loss: 0.0128 - val_loss: 0.0132 - 3s/epoch - 4ms/step
Epoch 6/180
747/747 - 3s - loss: 0.0122 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 7/180
747/747 - 3s - loss: 0.0118 - val_loss: 0.0122 - 3s/epoch - 4ms/step
Epoch 8/180
747/747 - 4s - loss: 0.0115 - val_loss: 0.0114 - 4s/epoch - 5ms/step
Epoch 9/180
747/747 - 3s - loss: 0.0112 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 10/180
747/747 - 3s - loss: 0.0115 - val_loss: 0.0123 - 3s/epoch - 4ms/step
Epoch 11/180
747/747 - 3s - loss: 0.0119 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 12/180
747/747 - 3s - loss: 0.0110 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 13/180
747/747 - 3s - loss: 0.0111 - val_loss: 0.0118 - 3s/epoch - 4ms/step
Epoch 14/180
747/747 - 3s - loss: 0.0118 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 15/180
747/747 - 3s - loss: 0.0108 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 16/180
747/747 - 3s - loss: 0.0112 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 17/180
747/747 - 3s - loss: 0.0107 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 18/180
747/747 - 3s - loss: 0.0114 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 19/180
747/747 - 3s - loss: 0.0109 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 20/180
747/747 - 3s - loss: 0.0106 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 21/180
747/747 - 3s - loss: 0.0107 - val_loss: 0.0114 - 3s/epoch - 4ms/step
Epoch 22/180
747/747 - 3s - loss: 0.0120 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 23/180
747/747 - 3s - loss: 0.0113 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 24/180
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 25/180
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 26/180
747/747 - 3s - loss: 0.0104 - val_loss: 0.0116 - 3s/epoch - 4ms/step
Epoch 27/180
747/747 - 3s - loss: 0.0117 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 28/180
747/747 - 3s - loss: 0.0104 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 29/180
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 30/180
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 31/180
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 32/180
747/747 - 3s - loss: 0.0103 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 33/180
747/747 - 3s - loss: 0.0110 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 34/180
747/747 - 3s - loss: 0.0103 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 35/180
747/747 - 3s - loss: 0.0106 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 36/180
747/747 - 3s - loss: 0.0102 - val_loss: 0.0110 - 3s/epoch - 5ms/step
Epoch 37/180
747/747 - 3s - loss: 0.0108 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 38/180
747/747 - 3s - loss: 0.0101 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 39/180
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 40/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 41/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 42/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 43/180
747/747 - 3s - loss: 0.0107 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 44/180
747/747 - 3s - loss: 0.0101 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 45/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 46/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 47/180
747/747 - 3s - loss: 0.0106 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 48/180
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 49/180
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 50/180
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 51/180
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 52/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 53/180
747/747 - 3s - loss: 0.0100 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 54/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 55/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 56/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 57/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 58/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 59/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 60/180
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 61/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 62/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 63/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 64/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 65/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 67/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 68/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 69/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 70/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 71/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/180
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 73/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 75/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 80/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 81/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 82/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 83/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 84/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 85/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 87/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 88/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 89/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 90/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 91/180
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 92/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 93/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 94/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 95/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 96/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 97/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 99/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 102/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 103/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 104/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 107/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 111/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 117/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 120/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 123/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 124/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 125/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 127/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 128/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 129/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 130/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 131/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 132/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 133/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 134/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 135/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 136/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 137/180
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 138/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 139/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 140/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 141/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 142/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 143/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 144/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 145/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 146/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 147/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 148/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 149/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 150/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 151/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 154/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 155/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 157/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 158/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 159/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 160/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 161/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 162/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 163/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 164/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 165/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 166/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 168/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 170/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 171/180
747/747 - 4s - loss: 0.0094 - val_loss: 0.0093 - 4s/epoch - 5ms/step
Epoch 172/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 173/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 174/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 175/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 176/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/180
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009221786633133888
  1/332 [..............................] - ETA: 54s 47/332 [===>..........................] - ETA: 0s  94/332 [=======>......................] - ETA: 0s140/332 [===========>..................] - ETA: 0s175/332 [==============>...............] - ETA: 0s221/332 [==================>...........] - ETA: 0s267/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0719313328215818
cosine 0.056471679813224686
MAE: 0.035082653
RMSE: 0.07714561
r2: 0.6139153728173141
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 128, 180, 0.0008, 0.2, 252, 0.009394575841724873, 0.009221786633133888, 0.0719313328215818, 0.056471679813224686, 0.035082653164863586, 0.07714560627937317, 0.6139153728173141, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.4999999999999996 190 0.0004000000000000001 128 1] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 1895)         2397175     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 1895)        7580        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 1895)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         2948323     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,308,662
Trainable params: 6,300,578
Non-trainable params: 8,084
__________________________________________________________________________________________________
Epoch 1/190
747/747 - 7s - loss: 0.0281 - val_loss: 0.0204 - 7s/epoch - 9ms/step
Epoch 2/190
747/747 - 3s - loss: 0.0153 - val_loss: 0.0274 - 3s/epoch - 4ms/step
Epoch 3/190
747/747 - 3s - loss: 0.0142 - val_loss: 0.0145 - 3s/epoch - 4ms/step
Epoch 4/190
747/747 - 3s - loss: 0.0135 - val_loss: 0.0142 - 3s/epoch - 4ms/step
Epoch 5/190
747/747 - 3s - loss: 0.0127 - val_loss: 0.0125 - 3s/epoch - 4ms/step
Epoch 6/190
747/747 - 3s - loss: 0.0122 - val_loss: 0.0165 - 3s/epoch - 4ms/step
Epoch 7/190
747/747 - 3s - loss: 0.0120 - val_loss: 0.0127 - 3s/epoch - 4ms/step
Epoch 8/190
747/747 - 3s - loss: 0.0117 - val_loss: 0.0115 - 3s/epoch - 4ms/step
Epoch 9/190
747/747 - 3s - loss: 0.0115 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 10/190
747/747 - 3s - loss: 0.0113 - val_loss: 0.0111 - 3s/epoch - 4ms/step
Epoch 11/190
747/747 - 3s - loss: 0.0111 - val_loss: 0.0108 - 3s/epoch - 4ms/step
Epoch 12/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 13/190
747/747 - 3s - loss: 0.0109 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 14/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 15/190
747/747 - 3s - loss: 0.0107 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 16/190
747/747 - 3s - loss: 0.0110 - val_loss: 0.0104 - 3s/epoch - 5ms/step
Epoch 17/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 18/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 19/190
747/747 - 3s - loss: 0.0106 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 20/190
747/747 - 3s - loss: 0.0112 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 21/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 22/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0107 - 3s/epoch - 4ms/step
Epoch 23/190
747/747 - 3s - loss: 0.0111 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 24/190
747/747 - 3s - loss: 0.0104 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 25/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 26/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 27/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 28/190
747/747 - 3s - loss: 0.0101 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 29/190
747/747 - 3s - loss: 0.0105 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 30/190
747/747 - 3s - loss: 0.0103 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 31/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 32/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 33/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 5ms/step
Epoch 34/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 35/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 36/190
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 37/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 38/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 39/190
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 40/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 42/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 44/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 5ms/step
Epoch 45/190
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 46/190
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 47/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 48/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 50/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 51/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 53/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 54/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 55/190
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 56/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 57/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 58/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 60/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 66/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 67/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 68/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 70/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 71/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 72/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/190
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 74/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 5ms/step
Epoch 75/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 76/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 77/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 78/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 79/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 81/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 86/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 92/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 95/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 96/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 97/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 98/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 101/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 102/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 103/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 104/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 105/190
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 106/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 107/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 108/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 109/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 110/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 111/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 112/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 113/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 114/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 115/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 116/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 118/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 119/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 120/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 121/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 122/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 126/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 127/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 135/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 144/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 151/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 152/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 154/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 155/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 156/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 157/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 158/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 159/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 160/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 162/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/190
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 166/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 167/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 168/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 169/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 170/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 171/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 172/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 173/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 174/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 175/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 176/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 177/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 178/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 179/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 180/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 181/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 182/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 183/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 184/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 185/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 186/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 187/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 188/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 189/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 190/190
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009177636355161667
  1/332 [..............................] - ETA: 1:03 44/332 [==>...........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s176/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s265/332 [======================>.......] - ETA: 0s309/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06814038905722665
cosine 0.053480494676155725
MAE: 0.033957332
RMSE: 0.07516819
r2: 0.6334542424081554
RMSE zero-vector: 0.23411466903540806
['1.4999999999999996custom_VAE', 'mse', 128, 190, 0.0004000000000000001, 0.2, 252, 0.009323053061962128, 0.009177636355161667, 0.06814038905722665, 0.053480494676155725, 0.033957332372665405, 0.0751681923866272, 0.6334542424081554, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 190 0.00020000000000000006 64 1] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/190
1493/1493 - 10s - loss: 0.0242 - val_loss: 0.0164 - 10s/epoch - 7ms/step
Epoch 2/190
1493/1493 - 6s - loss: 0.0145 - val_loss: 0.0216 - 6s/epoch - 4ms/step
Epoch 3/190
1493/1493 - 6s - loss: 0.0131 - val_loss: 0.0126 - 6s/epoch - 4ms/step
Epoch 4/190
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0128 - 6s/epoch - 4ms/step
Epoch 5/190
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0112 - 6s/epoch - 4ms/step
Epoch 6/190
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 7/190
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/190
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 9/190
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 10/190
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/190
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 17/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 20/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 31/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 67/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 5ms/step
Epoch 87/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 101/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 109/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 118/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 123/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 151/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 180/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 187/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 189/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 190/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009280243888497353
  1/332 [..............................] - ETA: 1:10 43/332 [==>...........................] - ETA: 0s   86/332 [======>.......................] - ETA: 0s130/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s212/332 [==================>...........] - ETA: 0s256/332 [======================>.......] - ETA: 0s299/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07212904530945607
cosine 0.056634109648407246
MAE: 0.035343938
RMSE: 0.07733809
r2: 0.6119864152407388
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 190, 0.00020000000000000006, 0.2, 252, 0.009507919661700726, 0.009280243888497353, 0.07212904530945607, 0.056634109648407246, 0.03534393757581711, 0.0773380920290947, 0.6119864152407388, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_15.pkl
[1.5999999999999996 185 0.0006000000000000001 64 1] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/185
1493/1493 - 9s - loss: 0.0242 - val_loss: 0.0159 - 9s/epoch - 6ms/step
Epoch 2/185
1493/1493 - 6s - loss: 0.0144 - val_loss: 0.0135 - 6s/epoch - 4ms/step
Epoch 3/185
1493/1493 - 6s - loss: 0.0130 - val_loss: 0.0124 - 6s/epoch - 4ms/step
Epoch 4/185
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/185
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0114 - 6s/epoch - 4ms/step
Epoch 6/185
1493/1493 - 6s - loss: 0.0118 - val_loss: 0.0112 - 6s/epoch - 4ms/step
Epoch 7/185
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0110 - 6s/epoch - 4ms/step
Epoch 8/185
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 9/185
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 10/185
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/185
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/185
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/185
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/185
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/185
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/185
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/185
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/185
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 25/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/185
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/185
1493/1493 - 7s - loss: 0.0099 - val_loss: 0.0096 - 7s/epoch - 4ms/step
Epoch 29/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 30/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 31/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/185
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 38/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 39/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 42/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 43/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 45/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/185
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/185
1493/1493 - 7s - loss: 0.0097 - val_loss: 0.0095 - 7s/epoch - 4ms/step
Epoch 51/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 53/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 55/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 61/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/185
1493/1493 - 7s - loss: 0.0097 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 73/185
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 87/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 97/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 98/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 101/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/185
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 104/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 109/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/185
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 111/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 119/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/185
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 140/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 147/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 152/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 153/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 154/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 161/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 164/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 165/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 167/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 168/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 174/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 175/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 176/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 179/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 181/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/185
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 183/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 185/185
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00929125864058733
  1/332 [..............................] - ETA: 1:00 45/332 [===>..........................] - ETA: 0s   89/332 [=======>......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s214/332 [==================>...........] - ETA: 0s258/332 [======================>.......] - ETA: 0s302/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07131342420791888
cosine 0.056021123562854866
MAE: 0.03497773
RMSE: 0.076906875
r2: 0.6163012709117494
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 185, 0.0006000000000000001, 0.2, 252, 0.009480605833232403, 0.00929125864058733, 0.07131342420791888, 0.056021123562854866, 0.03497773036360741, 0.07690687477588654, 0.6163012709117494, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 190 5.421010862427522e-20 64 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/190
1493/1493 - 9s - loss: 0.0240 - val_loss: 0.0230 - 9s/epoch - 6ms/step
Epoch 2/190
1493/1493 - 6s - loss: 0.0149 - val_loss: 0.0175 - 6s/epoch - 4ms/step
Epoch 3/190
1493/1493 - 6s - loss: 0.0131 - val_loss: 0.0124 - 6s/epoch - 4ms/step
Epoch 4/190
1493/1493 - 6s - loss: 0.0121 - val_loss: 0.0123 - 6s/epoch - 4ms/step
Epoch 5/190
1493/1493 - 6s - loss: 0.0118 - val_loss: 0.0111 - 6s/epoch - 4ms/step
Epoch 6/190
1493/1493 - 6s - loss: 0.0112 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 7/190
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 8/190
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 9/190
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 10/190
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/190
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 12/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 13/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 15/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 16/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 17/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 18/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 20/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 22/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 24/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 25/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 26/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 27/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 28/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 31/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 33/190
1493/1493 - 7s - loss: 0.0100 - val_loss: 0.0097 - 7s/epoch - 4ms/step
Epoch 34/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 35/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 36/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 38/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 41/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 43/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 44/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 45/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 46/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 47/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 48/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/190
1493/1493 - 7s - loss: 0.0098 - val_loss: 0.0095 - 7s/epoch - 4ms/step
Epoch 55/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 61/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 62/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 63/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 64/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 65/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/190
1493/1493 - 7s - loss: 0.0097 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 68/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 85/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 90/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 92/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 94/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 95/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 96/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 97/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 100/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 101/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 102/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 103/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 104/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 107/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 111/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 118/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 125/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 135/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 137/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 139/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 146/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 153/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 156/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 160/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 161/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 167/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 168/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 169/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 170/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 5ms/step
Epoch 174/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 5ms/step
Epoch 175/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 176/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 177/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 180/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 181/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 182/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 183/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 185/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 187/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 188/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 189/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 5ms/step
Epoch 190/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009265986271202564
  1/332 [..............................] - ETA: 1:06 42/332 [==>...........................] - ETA: 0s   84/332 [======>.......................] - ETA: 0s126/332 [==========>...................] - ETA: 0s169/332 [==============>...............] - ETA: 0s211/332 [==================>...........] - ETA: 0s253/332 [=====================>........] - ETA: 0s295/332 [=========================>....] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07176440697524218
cosine 0.05634740713943053
MAE: 0.034983467
RMSE: 0.07713225
r2: 0.614049070879176
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 190, 5.421010862427522e-20, 0.2, 252, 0.009491958655416965, 0.009265986271202564, 0.07176440697524218, 0.05634740713943053, 0.03498346731066704, 0.07713224738836288, 0.614049070879176, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 180 0.0006000000000000001 128 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/180
747/747 - 8s - loss: 0.0147 - val_loss: 0.0123 - 8s/epoch - 10ms/step
Epoch 2/180
747/747 - 4s - loss: 0.0083 - val_loss: 0.0090 - 4s/epoch - 5ms/step
Epoch 3/180
747/747 - 3s - loss: 0.0079 - val_loss: 0.0081 - 3s/epoch - 4ms/step
Epoch 4/180
747/747 - 3s - loss: 0.0075 - val_loss: 0.0079 - 3s/epoch - 5ms/step
Epoch 5/180
747/747 - 3s - loss: 0.0072 - val_loss: 0.0072 - 3s/epoch - 4ms/step
Epoch 6/180
747/747 - 3s - loss: 0.0070 - val_loss: 0.0069 - 3s/epoch - 5ms/step
Epoch 7/180
747/747 - 3s - loss: 0.0069 - val_loss: 0.0078 - 3s/epoch - 4ms/step
Epoch 8/180
747/747 - 3s - loss: 0.0068 - val_loss: 0.0067 - 3s/epoch - 5ms/step
Epoch 9/180
747/747 - 3s - loss: 0.0066 - val_loss: 0.0065 - 3s/epoch - 5ms/step
Epoch 10/180
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 11/180
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 12/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 21/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 23/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 24/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 26/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 34/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/180
747/747 - 4s - loss: 0.0061 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 38/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 39/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 40/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 46/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 48/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 49/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 50/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 51/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 52/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 53/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 54/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 60/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 64/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 65/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 66/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 79/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 80/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 82/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 83/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 95/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 96/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 97/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 98/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 99/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 103/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 105/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 110/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 111/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 112/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 113/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 114/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 118/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 123/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 124/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 125/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 126/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 127/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 128/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 129/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 130/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 131/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 132/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 136/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 137/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 138/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 139/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 140/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 141/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 142/180
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 143/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 145/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 146/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 147/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 150/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 152/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 155/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 156/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 159/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 160/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 161/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 162/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 163/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 170/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 173/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 174/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 175/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 176/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 177/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 178/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005837930366396904
  1/332 [..............................] - ETA: 1:05 42/332 [==>...........................] - ETA: 0s   83/332 [======>.......................] - ETA: 0s124/332 [==========>...................] - ETA: 0s166/332 [==============>...............] - ETA: 0s206/332 [=================>............] - ETA: 0s247/332 [=====================>........] - ETA: 0s289/332 [=========================>....] - ETA: 0s330/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11143813084261937
cosine 0.08717863544782423
MAE: 0.043809675
RMSE: 0.0951278
r2: 0.41295000763595757
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 180, 0.0006000000000000001, 0.2, 252, 0.005888369400054216, 0.005837930366396904, 0.11143813084261937, 0.08717863544782423, 0.043809674680233, 0.09512779861688614, 0.41295000763595757, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 190 5.421010862427522e-20 64 1] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/190
1493/1493 - 11s - loss: 0.0246 - val_loss: 0.0161 - 11s/epoch - 7ms/step
Epoch 2/190
1493/1493 - 6s - loss: 0.0146 - val_loss: 0.0141 - 6s/epoch - 4ms/step
Epoch 3/190
1493/1493 - 6s - loss: 0.0131 - val_loss: 0.0126 - 6s/epoch - 4ms/step
Epoch 4/190
1493/1493 - 6s - loss: 0.0122 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/190
1493/1493 - 6s - loss: 0.0117 - val_loss: 0.0112 - 6s/epoch - 4ms/step
Epoch 6/190
1493/1493 - 6s - loss: 0.0113 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 7/190
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0107 - 6s/epoch - 4ms/step
Epoch 8/190
1493/1493 - 6s - loss: 0.0109 - val_loss: 0.0106 - 6s/epoch - 4ms/step
Epoch 9/190
1493/1493 - 6s - loss: 0.0108 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 10/190
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 11/190
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 12/190
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 13/190
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 14/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 15/190
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 16/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 17/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 18/190
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 19/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 21/190
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 23/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 24/190
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 25/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 26/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/190
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 30/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 31/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 32/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/190
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 39/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 40/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 41/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 42/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 43/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 45/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/190
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/190
1493/1493 - 7s - loss: 0.0097 - val_loss: 0.0095 - 7s/epoch - 4ms/step
Epoch 52/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 53/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 54/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 55/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 56/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 57/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 58/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 59/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 60/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 61/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 62/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/190
1493/1493 - 7s - loss: 0.0097 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 68/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/190
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 81/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 82/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 83/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 85/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 87/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 88/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 89/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 90/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 92/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 93/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 94/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 97/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 98/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 99/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 100/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 101/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 109/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/190
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 116/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 120/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 129/190
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 132/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 141/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 145/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 148/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 152/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 154/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 155/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 156/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 158/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 159/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 160/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 161/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 162/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 163/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 164/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 165/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 166/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 167/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 168/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 169/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 170/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 171/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 172/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 173/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 174/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 175/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 176/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 177/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 178/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 179/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 180/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 181/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0093 - 7s/epoch - 4ms/step
Epoch 182/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 183/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 184/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 185/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 186/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 187/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 188/190
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 189/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 190/190
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009245555847883224
  1/332 [..............................] - ETA: 1:07 42/332 [==>...........................] - ETA: 0s   84/332 [======>.......................] - ETA: 0s125/332 [==========>...................] - ETA: 0s167/332 [==============>...............] - ETA: 0s207/332 [=================>............] - ETA: 0s248/332 [=====================>........] - ETA: 0s290/332 [=========================>....] - ETA: 0s329/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.0703560605538462
cosine 0.0552199226402131
MAE: 0.0347776
RMSE: 0.0763865
r2: 0.6214762038115488
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'mse', 64, 190, 5.421010862427522e-20, 0.2, 252, 0.00948338396847248, 0.009245555847883224, 0.0703560605538462, 0.0552199226402131, 0.034777600318193436, 0.07638649642467499, 0.6214762038115488, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 180 0.0008 128 2] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/180
747/747 - 8s - loss: 0.0150 - val_loss: 0.0101 - 8s/epoch - 11ms/step
Epoch 2/180
747/747 - 3s - loss: 0.0084 - val_loss: 0.0102 - 3s/epoch - 5ms/step
Epoch 3/180
747/747 - 3s - loss: 0.0078 - val_loss: 0.0081 - 3s/epoch - 5ms/step
Epoch 4/180
747/747 - 4s - loss: 0.0075 - val_loss: 0.0082 - 4s/epoch - 5ms/step
Epoch 5/180
747/747 - 3s - loss: 0.0071 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 6/180
747/747 - 3s - loss: 0.0067 - val_loss: 0.0085 - 3s/epoch - 4ms/step
Epoch 7/180
747/747 - 3s - loss: 0.0066 - val_loss: 0.0068 - 3s/epoch - 4ms/step
Epoch 8/180
747/747 - 3s - loss: 0.0065 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 9/180
747/747 - 4s - loss: 0.0064 - val_loss: 0.0246 - 4s/epoch - 5ms/step
Epoch 10/180
747/747 - 3s - loss: 0.0070 - val_loss: 0.0069 - 3s/epoch - 5ms/step
Epoch 11/180
747/747 - 3s - loss: 0.0069 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 12/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 14/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 15/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 16/180
747/747 - 4s - loss: 0.0062 - val_loss: 0.0062 - 4s/epoch - 5ms/step
Epoch 17/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 18/180
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 19/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 21/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 22/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 23/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 26/180
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 27/180
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 28/180
747/747 - 4s - loss: 0.0061 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 29/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 30/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 35/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/180
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 38/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 40/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 41/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 42/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 47/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 48/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 50/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 52/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 53/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 54/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 59/180
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 60/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 61/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 64/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 65/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 66/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 71/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 72/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 73/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 76/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/180
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 127/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 137/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 138/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 141/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 146/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 147/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 152/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 161/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 163/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 164/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 170/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 172/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 179/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 180/180
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058263749815523624
  1/332 [..............................] - ETA: 1:00 45/332 [===>..........................] - ETA: 0s   90/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s268/332 [=======================>......] - ETA: 0s312/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.111787547665949
cosine 0.08743927308491298
MAE: 0.04394143
RMSE: 0.09530778
r2: 0.4107265063986336
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 180, 0.0008, 0.2, 252, 0.0059005203656852245, 0.0058263749815523624, 0.111787547665949, 0.08743927308491298, 0.043941430747509, 0.09530778229236603, 0.4107265063986336, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 175 0.0006000000000000001 128 2] 8
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/175
747/747 - 6s - loss: 0.0152 - val_loss: 0.0095 - 6s/epoch - 8ms/step
Epoch 2/175
747/747 - 3s - loss: 0.0084 - val_loss: 0.0191 - 3s/epoch - 4ms/step
Epoch 3/175
747/747 - 3s - loss: 0.0079 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 4/175
747/747 - 3s - loss: 0.0075 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 5/175
747/747 - 3s - loss: 0.0072 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 6/175
747/747 - 3s - loss: 0.0068 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 7/175
747/747 - 3s - loss: 0.0066 - val_loss: 0.0240 - 3s/epoch - 4ms/step
Epoch 8/175
747/747 - 3s - loss: 0.0069 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 9/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 10/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0113 - 3s/epoch - 4ms/step
Epoch 11/175
747/747 - 3s - loss: 0.0068 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 12/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 14/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 16/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 18/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 23/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 24/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 36/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 39/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 40/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 48/175
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 49/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 52/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 61/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 62/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 64/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 68/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 73/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 74/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 76/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 77/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 86/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 87/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 89/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 98/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 99/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 111/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 112/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 114/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 124/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 127/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 137/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 138/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 139/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 140/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 149/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 150/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 152/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 158/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 161/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 162/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 163/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 164/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 165/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 173/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 175/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.0058413282968103886
  1/332 [..............................] - ETA: 1:01 45/332 [===>..........................] - ETA: 0s   90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s179/332 [===============>..............] - ETA: 0s224/332 [===================>..........] - ETA: 0s268/332 [=======================>......] - ETA: 0s313/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1132342166864463
cosine 0.0885800271271491
MAE: 0.044015165
RMSE: 0.0958808
r2: 0.4036194697385509
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 175, 0.0006000000000000001, 0.2, 252, 0.005898362025618553, 0.0058413282968103886, 0.1132342166864463, 0.0885800271271491, 0.04401516541838646, 0.09588079899549484, 0.4036194697385509, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 185 0.0006000000000000001 128 2] 9
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/185
747/747 - 6s - loss: 0.0152 - val_loss: 0.0093 - 6s/epoch - 8ms/step
Epoch 2/185
747/747 - 3s - loss: 0.0084 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 3/185
747/747 - 3s - loss: 0.0079 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 4/185
747/747 - 3s - loss: 0.0075 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 5/185
747/747 - 3s - loss: 0.0071 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 6/185
747/747 - 3s - loss: 0.0067 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 7/185
747/747 - 3s - loss: 0.0066 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 8/185
747/747 - 3s - loss: 0.0065 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 9/185
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/185
747/747 - 3s - loss: 0.0063 - val_loss: 0.0086 - 3s/epoch - 4ms/step
Epoch 11/185
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 12/185
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/185
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 15/185
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 16/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 17/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 22/185
747/747 - 3s - loss: 0.0064 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 27/185
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/185
747/747 - 4s - loss: 0.0062 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 30/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/185
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 39/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 40/185
747/747 - 4s - loss: 0.0061 - val_loss: 0.0061 - 4s/epoch - 5ms/step
Epoch 41/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 42/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 43/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 44/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 45/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 46/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 51/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 52/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/185
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 55/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 64/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 65/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 67/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 68/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 69/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 70/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 71/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 72/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 73/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 77/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 78/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 79/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 81/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 91/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 93/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 94/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/185
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 103/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 104/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 106/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 116/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 117/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 119/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 124/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 129/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 130/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 132/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 141/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 142/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 144/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 147/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 148/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 151/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 153/185
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 154/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 156/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 157/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 164/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 165/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 166/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 167/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 169/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 174/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 176/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 179/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 180/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 181/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 182/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 184/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 185/185
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005843593273311853
  1/332 [..............................] - ETA: 1:00 44/332 [==>...........................] - ETA: 0s   86/332 [======>.......................] - ETA: 0s130/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s219/332 [==================>...........] - ETA: 0s263/332 [======================>.......] - ETA: 0s308/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11108160228705433
cosine 0.086884213131956
MAE: 0.0435658
RMSE: 0.09506705
r2: 0.413699594314116
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 185, 0.0006000000000000001, 0.2, 252, 0.0058950032107532024, 0.005843593273311853, 0.11108160228705433, 0.086884213131956, 0.04356579855084419, 0.09506704658269882, 0.413699594314116, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_16.pkl
[1.6999999999999997 195 0.0004000000000000001 128 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/195
747/747 - 6s - loss: 0.0150 - val_loss: 0.0113 - 6s/epoch - 8ms/step
Epoch 2/195
747/747 - 3s - loss: 0.0083 - val_loss: 0.0088 - 3s/epoch - 4ms/step
Epoch 3/195
747/747 - 3s - loss: 0.0079 - val_loss: 0.0104 - 3s/epoch - 4ms/step
Epoch 4/195
747/747 - 3s - loss: 0.0075 - val_loss: 0.0083 - 3s/epoch - 4ms/step
Epoch 5/195
747/747 - 3s - loss: 0.0071 - val_loss: 0.0173 - 3s/epoch - 4ms/step
Epoch 6/195
747/747 - 3s - loss: 0.0068 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 7/195
747/747 - 3s - loss: 0.0066 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 8/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 11/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 15/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 16/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 18/195
747/747 - 3s - loss: 0.0074 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 19/195
747/747 - 3s - loss: 0.0069 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 20/195
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 21/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 23/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 29/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 31/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 32/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 33/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 34/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 39/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 43/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 44/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 45/195
747/747 - 3s - loss: 0.0063 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 46/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 47/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/195
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 55/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 56/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 57/195
747/747 - 3s - loss: 0.0062 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 59/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 65/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 69/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/195
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 72/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 82/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 85/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 95/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 96/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 98/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 108/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 109/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 111/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 112/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 121/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 122/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 125/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 135/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 136/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 138/195
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 147/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 150/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 151/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 160/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 161/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 163/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 164/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 172/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 173/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 174/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 176/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 177/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 178/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 179/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 180/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 181/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 182/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 183/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 184/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 185/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 186/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 187/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 188/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 189/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 190/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 191/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 192/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 193/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 194/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 195/195
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005874591413885355
  1/332 [..............................] - ETA: 1:01 45/332 [===>..........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s132/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s218/332 [==================>...........] - ETA: 0s262/332 [======================>.......] - ETA: 0s306/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1148723313494354
cosine 0.08980955587909935
MAE: 0.044525087
RMSE: 0.096609704
r2: 0.39451731462858336
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 195, 0.0004000000000000001, 0.2, 252, 0.005915472749620676, 0.005874591413885355, 0.1148723313494354, 0.08980955587909935, 0.044525086879730225, 0.0966097041964531, 0.39451731462858336, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 170 0.0004000000000000001 128 2] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/170
747/747 - 6s - loss: 0.0152 - val_loss: 0.0102 - 6s/epoch - 9ms/step
Epoch 2/170
747/747 - 3s - loss: 0.0084 - val_loss: 0.0086 - 3s/epoch - 4ms/step
Epoch 3/170
747/747 - 3s - loss: 0.0078 - val_loss: 0.0085 - 3s/epoch - 4ms/step
Epoch 4/170
747/747 - 3s - loss: 0.0075 - val_loss: 0.0079 - 3s/epoch - 4ms/step
Epoch 5/170
747/747 - 3s - loss: 0.0072 - val_loss: 0.0075 - 3s/epoch - 4ms/step
Epoch 6/170
747/747 - 3s - loss: 0.0070 - val_loss: 0.0074 - 3s/epoch - 4ms/step
Epoch 7/170
747/747 - 3s - loss: 0.0069 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 8/170
747/747 - 3s - loss: 0.0067 - val_loss: 0.0069 - 3s/epoch - 4ms/step
Epoch 9/170
747/747 - 3s - loss: 0.0065 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 10/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0065 - 3s/epoch - 4ms/step
Epoch 14/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 16/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 21/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 24/170
747/747 - 3s - loss: 0.0065 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 26/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 28/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 32/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 33/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 42/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 53/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 54/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 55/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 56/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 68/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 152/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 154/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 155/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 156/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 161/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 164/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 166/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 168/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 169/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 170/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005855630151927471
  1/332 [..............................] - ETA: 1:06 44/332 [==>...........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s131/332 [==========>...................] - ETA: 0s175/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s302/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11330582507592168
cosine 0.08860724971759917
MAE: 0.04411922
RMSE: 0.09591391
r2: 0.40320745548890535
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 128, 170, 0.0004000000000000001, 0.2, 252, 0.005900248885154724, 0.005855630151927471, 0.11330582507592168, 0.08860724971759917, 0.0441192202270031, 0.09591390937566757, 0.40320745548890535, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 170 0.0004000000000000001 128 1] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/170
747/747 - 6s - loss: 0.0330 - val_loss: 0.0188 - 6s/epoch - 8ms/step
Epoch 2/170
747/747 - 3s - loss: 0.0160 - val_loss: 0.0238 - 3s/epoch - 4ms/step
Epoch 3/170
747/747 - 3s - loss: 0.0147 - val_loss: 0.0146 - 3s/epoch - 4ms/step
Epoch 4/170
747/747 - 3s - loss: 0.0139 - val_loss: 0.0234 - 3s/epoch - 4ms/step
Epoch 5/170
747/747 - 3s - loss: 0.0132 - val_loss: 0.0150 - 3s/epoch - 4ms/step
Epoch 6/170
747/747 - 3s - loss: 0.0124 - val_loss: 0.0123 - 3s/epoch - 4ms/step
Epoch 7/170
747/747 - 3s - loss: 0.0120 - val_loss: 0.0213 - 3s/epoch - 4ms/step
Epoch 8/170
747/747 - 3s - loss: 0.0120 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 9/170
747/747 - 3s - loss: 0.0114 - val_loss: 0.0463 - 3s/epoch - 4ms/step
Epoch 10/170
747/747 - 3s - loss: 0.0122 - val_loss: 0.0172 - 3s/epoch - 4ms/step
Epoch 11/170
747/747 - 3s - loss: 0.0114 - val_loss: 0.0109 - 3s/epoch - 4ms/step
Epoch 12/170
747/747 - 3s - loss: 0.0109 - val_loss: 0.0120 - 3s/epoch - 4ms/step
Epoch 13/170
747/747 - 3s - loss: 0.0109 - val_loss: 0.0138 - 3s/epoch - 4ms/step
Epoch 14/170
747/747 - 3s - loss: 0.0107 - val_loss: 0.0106 - 3s/epoch - 4ms/step
Epoch 15/170
747/747 - 3s - loss: 0.0105 - val_loss: 0.0197 - 3s/epoch - 4ms/step
Epoch 16/170
747/747 - 3s - loss: 0.0116 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 17/170
747/747 - 3s - loss: 0.0104 - val_loss: 0.0163 - 3s/epoch - 4ms/step
Epoch 18/170
747/747 - 3s - loss: 0.0114 - val_loss: 0.0211 - 3s/epoch - 4ms/step
Epoch 19/170
747/747 - 3s - loss: 0.0145 - val_loss: 0.0161 - 3s/epoch - 4ms/step
Epoch 20/170
747/747 - 3s - loss: 0.0151 - val_loss: 0.0105 - 3s/epoch - 4ms/step
Epoch 21/170
747/747 - 3s - loss: 0.0106 - val_loss: 0.0112 - 3s/epoch - 4ms/step
Epoch 22/170
747/747 - 3s - loss: 0.0108 - val_loss: 0.0117 - 3s/epoch - 4ms/step
Epoch 23/170
747/747 - 3s - loss: 0.0109 - val_loss: 0.0126 - 3s/epoch - 4ms/step
Epoch 24/170
747/747 - 3s - loss: 0.0117 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 25/170
747/747 - 3s - loss: 0.0103 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 26/170
747/747 - 3s - loss: 0.0102 - val_loss: 0.0100 - 3s/epoch - 4ms/step
Epoch 27/170
747/747 - 3s - loss: 0.0102 - val_loss: 0.0101 - 3s/epoch - 4ms/step
Epoch 28/170
747/747 - 3s - loss: 0.0102 - val_loss: 0.0143 - 3s/epoch - 4ms/step
Epoch 29/170
747/747 - 3s - loss: 0.0115 - val_loss: 0.0103 - 3s/epoch - 4ms/step
Epoch 30/170
747/747 - 3s - loss: 0.0102 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 31/170
747/747 - 3s - loss: 0.0101 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 32/170
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 33/170
747/747 - 3s - loss: 0.0100 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 34/170
747/747 - 3s - loss: 0.0099 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 35/170
747/747 - 3s - loss: 0.0099 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 36/170
747/747 - 3s - loss: 0.0102 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 37/170
747/747 - 3s - loss: 0.0099 - val_loss: 0.0098 - 3s/epoch - 4ms/step
Epoch 38/170
747/747 - 3s - loss: 0.0099 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 39/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 40/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 41/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 42/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 43/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0102 - 3s/epoch - 4ms/step
Epoch 44/170
747/747 - 3s - loss: 0.0100 - val_loss: 0.0097 - 3s/epoch - 4ms/step
Epoch 45/170
747/747 - 3s - loss: 0.0098 - val_loss: 0.0095 - 3s/epoch - 5ms/step
Epoch 46/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 47/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 48/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 49/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 50/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 51/170
747/747 - 3s - loss: 0.0097 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 52/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 53/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 54/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 55/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 56/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 57/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 58/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 59/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 60/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 61/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 62/170
747/747 - 3s - loss: 0.0096 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 63/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 64/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 65/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 66/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 67/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 68/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 69/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 70/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 71/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 72/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0094 - 3s/epoch - 4ms/step
Epoch 73/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 74/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 75/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 76/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 77/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 78/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 79/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 80/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 81/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 82/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 83/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 84/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 85/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 86/170
747/747 - 3s - loss: 0.0095 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 87/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 88/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 89/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 90/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 91/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 5ms/step
Epoch 92/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 93/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 94/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 95/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 96/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 97/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 98/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 99/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0093 - 3s/epoch - 4ms/step
Epoch 100/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 101/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 102/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 103/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 104/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 105/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 106/170
747/747 - 4s - loss: 0.0094 - val_loss: 0.0092 - 4s/epoch - 5ms/step
Epoch 107/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 108/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 109/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 110/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 111/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 112/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 113/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 114/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 115/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 116/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 117/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 118/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 119/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 120/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 121/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 122/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 123/170
747/747 - 3s - loss: 0.0094 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 124/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 125/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 126/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 127/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 128/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 129/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 130/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 131/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 132/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 133/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 134/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 135/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 136/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 137/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 138/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 139/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 140/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 141/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 142/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 143/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 144/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 145/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 146/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 147/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 148/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 149/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 150/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 151/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 152/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 153/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 154/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 5ms/step
Epoch 155/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 156/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 157/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 158/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 159/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 160/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 161/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 162/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 163/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 164/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0092 - 3s/epoch - 4ms/step
Epoch 165/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 166/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 5ms/step
Epoch 167/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 168/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 169/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
Epoch 170/170
747/747 - 3s - loss: 0.0093 - val_loss: 0.0091 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.009142948314547539
  1/332 [..............................] - ETA: 1:03 44/332 [==>...........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s124/332 [==========>...................] - ETA: 0s167/332 [==============>...............] - ETA: 0s210/332 [=================>............] - ETA: 0s253/332 [=====================>........] - ETA: 0s296/332 [=========================>....] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.06789578626594407
cosine 0.053307434595219826
MAE: 0.03412486
RMSE: 0.07501866
r2: 0.6349111641462454
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 128, 170, 0.0004000000000000001, 0.2, 252, 0.009285397827625275, 0.009142948314547539, 0.06789578626594407, 0.053307434595219826, 0.03412485867738724, 0.07501865923404694, 0.6349111641462454, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 175 0.0004000000000000001 128 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/175
747/747 - 6s - loss: 0.0151 - val_loss: 0.0096 - 6s/epoch - 8ms/step
Epoch 2/175
747/747 - 3s - loss: 0.0082 - val_loss: 0.0110 - 3s/epoch - 4ms/step
Epoch 3/175
747/747 - 3s - loss: 0.0079 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 4/175
747/747 - 3s - loss: 0.0075 - val_loss: 0.0089 - 3s/epoch - 4ms/step
Epoch 5/175
747/747 - 3s - loss: 0.0070 - val_loss: 0.0071 - 3s/epoch - 4ms/step
Epoch 6/175
747/747 - 3s - loss: 0.0067 - val_loss: 0.0519 - 3s/epoch - 4ms/step
Epoch 7/175
747/747 - 3s - loss: 0.0072 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 8/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 9/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0067 - 3s/epoch - 4ms/step
Epoch 14/175
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 15/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 16/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 19/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 20/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 21/175
747/747 - 3s - loss: 0.0065 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 23/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 25/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 26/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 27/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 28/175
747/747 - 3s - loss: 0.0066 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 29/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 30/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 31/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 32/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 34/175
747/747 - 3s - loss: 0.0066 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 35/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 38/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 39/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 40/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 41/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 42/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 43/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 44/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 45/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 46/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 52/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 56/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 58/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 64/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 66/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 67/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 68/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 69/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 70/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 71/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 72/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 75/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 81/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 82/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 94/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 108/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 120/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 134/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 157/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 159/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 160/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 161/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 171/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 174/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 175/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005876322276890278
  1/332 [..............................] - ETA: 1:01 44/332 [==>...........................] - ETA: 0s   89/332 [=======>......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s174/332 [==============>...............] - ETA: 0s214/332 [==================>...........] - ETA: 0s257/332 [======================>.......] - ETA: 0s300/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1153699051163307
cosine 0.09020904014908589
MAE: 0.04450877
RMSE: 0.096742004
r2: 0.3928580012022282
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 175, 0.0004000000000000001, 0.2, 252, 0.005925178527832031, 0.005876322276890278, 0.1153699051163307, 0.09020904014908589, 0.04450877010822296, 0.09674200415611267, 0.3928580012022282, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 180 0.0006000000000000001 256 2] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/180
374/374 - 5s - loss: 0.0204 - val_loss: 0.0104 - 5s/epoch - 13ms/step
Epoch 2/180
374/374 - 2s - loss: 0.0085 - val_loss: 0.0784 - 2s/epoch - 5ms/step
Epoch 3/180
374/374 - 2s - loss: 0.0088 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 4/180
374/374 - 2s - loss: 0.0080 - val_loss: 0.0124 - 2s/epoch - 5ms/step
Epoch 5/180
374/374 - 2s - loss: 0.0078 - val_loss: 0.0084 - 2s/epoch - 5ms/step
Epoch 6/180
374/374 - 2s - loss: 0.0077 - val_loss: 0.0094 - 2s/epoch - 5ms/step
Epoch 7/180
374/374 - 2s - loss: 0.0075 - val_loss: 0.0084 - 2s/epoch - 5ms/step
Epoch 8/180
374/374 - 2s - loss: 0.0073 - val_loss: 0.0083 - 2s/epoch - 5ms/step
Epoch 9/180
374/374 - 2s - loss: 0.0072 - val_loss: 0.0077 - 2s/epoch - 5ms/step
Epoch 10/180
374/374 - 2s - loss: 0.0071 - val_loss: 0.0102 - 2s/epoch - 5ms/step
Epoch 11/180
374/374 - 2s - loss: 0.0071 - val_loss: 0.0074 - 2s/epoch - 5ms/step
Epoch 12/180
374/374 - 2s - loss: 0.0069 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 13/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0090 - 2s/epoch - 5ms/step
Epoch 14/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 15/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0279 - 2s/epoch - 5ms/step
Epoch 16/180
374/374 - 2s - loss: 0.0070 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 17/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0111 - 2s/epoch - 5ms/step
Epoch 18/180
374/374 - 2s - loss: 0.0068 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 19/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0089 - 2s/epoch - 5ms/step
Epoch 20/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0077 - 2s/epoch - 5ms/step
Epoch 21/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0273 - 2s/epoch - 5ms/step
Epoch 22/180
374/374 - 2s - loss: 0.0094 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 23/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0215 - 2s/epoch - 5ms/step
Epoch 24/180
374/374 - 2s - loss: 0.0179 - val_loss: 0.0091 - 2s/epoch - 5ms/step
Epoch 25/180
374/374 - 2s - loss: 0.0086 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 26/180
374/374 - 2s - loss: 0.0071 - val_loss: 0.0143 - 2s/epoch - 5ms/step
Epoch 27/180
374/374 - 2s - loss: 0.0158 - val_loss: 0.0071 - 2s/epoch - 5ms/step
Epoch 28/180
374/374 - 2s - loss: 0.0068 - val_loss: 0.0076 - 2s/epoch - 5ms/step
Epoch 29/180
374/374 - 2s - loss: 0.0078 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 30/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 31/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 32/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 33/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 34/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 35/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0190 - 2s/epoch - 5ms/step
Epoch 36/180
374/374 - 2s - loss: 0.0210 - val_loss: 0.0130 - 2s/epoch - 5ms/step
Epoch 37/180
374/374 - 2s - loss: 0.0230 - val_loss: 0.0119 - 2s/epoch - 5ms/step
Epoch 38/180
374/374 - 2s - loss: 0.0296 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 39/180
374/374 - 2s - loss: 0.0084 - val_loss: 0.0079 - 2s/epoch - 5ms/step
Epoch 40/180
374/374 - 2s - loss: 0.0079 - val_loss: 0.0082 - 2s/epoch - 5ms/step
Epoch 41/180
374/374 - 2s - loss: 0.0084 - val_loss: 0.0074 - 2s/epoch - 5ms/step
Epoch 42/180
374/374 - 2s - loss: 0.0073 - val_loss: 0.0071 - 2s/epoch - 5ms/step
Epoch 43/180
374/374 - 2s - loss: 0.0072 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 44/180
374/374 - 2s - loss: 0.0070 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 45/180
374/374 - 2s - loss: 0.0070 - val_loss: 0.0068 - 2s/epoch - 5ms/step
Epoch 46/180
374/374 - 2s - loss: 0.0071 - val_loss: 0.0152 - 2s/epoch - 5ms/step
Epoch 47/180
374/374 - 2s - loss: 0.0292 - val_loss: 0.0091 - 2s/epoch - 5ms/step
Epoch 48/180
374/374 - 2s - loss: 0.0076 - val_loss: 0.0079 - 2s/epoch - 5ms/step
Epoch 49/180
374/374 - 2s - loss: 0.0088 - val_loss: 0.0073 - 2s/epoch - 5ms/step
Epoch 50/180
374/374 - 2s - loss: 0.0072 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 51/180
374/374 - 2s - loss: 0.0070 - val_loss: 0.0068 - 2s/epoch - 5ms/step
Epoch 52/180
374/374 - 2s - loss: 0.0069 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 53/180
374/374 - 2s - loss: 0.0068 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 54/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 55/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 56/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 57/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 58/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0075 - 2s/epoch - 5ms/step
Epoch 59/180
374/374 - 2s - loss: 0.0068 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 60/180
374/374 - 2s - loss: 0.0065 - val_loss: 0.0085 - 2s/epoch - 5ms/step
Epoch 61/180
374/374 - 2s - loss: 0.0072 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 62/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 63/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 64/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0117 - 2s/epoch - 5ms/step
Epoch 65/180
374/374 - 2s - loss: 0.0079 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 66/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 67/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 68/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 69/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0071 - 2s/epoch - 5ms/step
Epoch 70/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 71/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0075 - 2s/epoch - 5ms/step
Epoch 72/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0096 - 2s/epoch - 5ms/step
Epoch 73/180
374/374 - 2s - loss: 0.0066 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 74/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 75/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 76/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0101 - 2s/epoch - 5ms/step
Epoch 77/180
374/374 - 2s - loss: 0.0078 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 78/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 79/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 80/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 81/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 82/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 83/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 84/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 85/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 86/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 87/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 88/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0079 - 2s/epoch - 5ms/step
Epoch 89/180
374/374 - 2s - loss: 0.0067 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 90/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0073 - 2s/epoch - 5ms/step
Epoch 91/180
374/374 - 2s - loss: 0.0073 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 92/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 93/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 94/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 95/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 96/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 97/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 98/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 99/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 100/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 101/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0070 - 2s/epoch - 5ms/step
Epoch 102/180
374/374 - 2s - loss: 0.0073 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 103/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 104/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 105/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 106/180
374/374 - 2s - loss: 0.0063 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 107/180
374/374 - 2s - loss: 0.0072 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 108/180
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 109/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 110/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 111/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 112/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 113/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0068 - 2s/epoch - 5ms/step
Epoch 114/180
374/374 - 2s - loss: 0.0068 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 115/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 116/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 117/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 118/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 119/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 120/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 121/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 122/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 123/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 124/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 125/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 126/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 127/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 128/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 129/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 130/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0069 - 2s/epoch - 5ms/step
Epoch 131/180
374/374 - 2s - loss: 0.0064 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 132/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 133/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 134/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 135/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 136/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 137/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 138/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 139/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 140/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 141/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 142/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 143/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 144/180
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 145/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 146/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 147/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 148/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 149/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 150/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 151/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 152/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 153/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 154/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 155/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 156/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 157/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 158/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 159/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 160/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 161/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 162/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 163/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 164/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 165/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 166/180
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 167/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 168/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 169/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 170/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 171/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 172/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 173/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 174/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 175/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 176/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 177/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 178/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 179/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 180/180
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005902578588575125
  1/332 [..............................] - ETA: 49s 43/332 [==>...........................] - ETA: 0s  88/332 [======>.......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s224/332 [===================>..........] - ETA: 0s269/332 [=======================>......] - ETA: 0s314/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.1150971338141652
cosine 0.09004382640291869
MAE: 0.04518844
RMSE: 0.09659521
r2: 0.3947003842136298
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 256, 180, 0.0006000000000000001, 0.2, 252, 0.005920494440943003, 0.005902578588575125, 0.1150971338141652, 0.09004382640291869, 0.04518843814730644, 0.09659521281719208, 0.3947003842136298, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Saved GA instance to file: ./tmp//ga_instance_generation_17.pkl
[1.5999999999999996 170 0.0006000000000000001 64 2] 2
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/170
1493/1493 - 9s - loss: 0.0128 - val_loss: 0.0091 - 9s/epoch - 6ms/step
Epoch 2/170
1493/1493 - 6s - loss: 0.0079 - val_loss: 0.0077 - 6s/epoch - 4ms/step
Epoch 3/170
1493/1493 - 6s - loss: 0.0072 - val_loss: 0.0070 - 6s/epoch - 4ms/step
Epoch 4/170
1493/1493 - 6s - loss: 0.0069 - val_loss: 0.0067 - 6s/epoch - 4ms/step
Epoch 5/170
1493/1493 - 6s - loss: 0.0065 - val_loss: 0.0064 - 6s/epoch - 4ms/step
Epoch 6/170
1493/1493 - 6s - loss: 0.0064 - val_loss: 0.0063 - 6s/epoch - 4ms/step
Epoch 7/170
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 8/170
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 9/170
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 10/170
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 11/170
1493/1493 - 6s - loss: 0.0063 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 12/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 13/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 14/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 15/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0062 - 6s/epoch - 4ms/step
Epoch 16/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 17/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 18/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 19/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 20/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 21/170
1493/1493 - 6s - loss: 0.0062 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 22/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0061 - 6s/epoch - 4ms/step
Epoch 23/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 24/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 25/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 26/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 27/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 28/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 29/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 30/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 31/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 32/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 33/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 34/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 35/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 36/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 37/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 38/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 39/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 40/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 41/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 42/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 43/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 44/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 45/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 46/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 47/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 48/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 49/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 50/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 51/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 52/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 53/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 54/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 55/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 56/170
1493/1493 - 6s - loss: 0.0061 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 57/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 58/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 59/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 60/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 61/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 62/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 63/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 64/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 65/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 66/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 67/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 68/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 69/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 70/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 71/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 72/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 73/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 74/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 75/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 76/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 77/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 78/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 79/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 80/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 81/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 82/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 83/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 84/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 85/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 86/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 87/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 88/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 89/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 90/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 91/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 92/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 93/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 94/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 95/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 96/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 97/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 98/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 99/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 100/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 101/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 102/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 103/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 104/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 105/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 106/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 107/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 108/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 109/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 110/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 111/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 112/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 113/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 114/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 115/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 116/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 117/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 118/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 119/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 120/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 121/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 122/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 123/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 124/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 125/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 126/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 127/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 128/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 129/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 130/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 131/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 132/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 133/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 134/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 135/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 136/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 137/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 138/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 139/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 140/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 141/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 142/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 143/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 144/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 145/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 146/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 147/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 148/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0060 - 6s/epoch - 4ms/step
Epoch 149/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 150/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 151/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 152/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 153/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 154/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 155/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 156/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 157/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 158/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 159/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 160/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 161/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 162/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 163/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 164/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 165/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 166/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 167/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 168/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 169/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
Epoch 170/170
1493/1493 - 6s - loss: 0.0060 - val_loss: 0.0059 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005934292916208506
  1/332 [..............................] - ETA: 1:07 44/332 [==>...........................] - ETA: 0s   84/332 [======>.......................] - ETA: 0s128/332 [==========>...................] - ETA: 0s173/332 [==============>...............] - ETA: 0s217/332 [==================>...........] - ETA: 0s261/332 [======================>.......] - ETA: 0s304/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11880419255033152
cosine 0.09295448111535197
MAE: 0.045539986
RMSE: 0.09809972
r2: 0.37569673166426176
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'logcosh', 64, 170, 0.0006000000000000001, 0.2, 252, 0.006002448964864016, 0.005934292916208506, 0.11880419255033152, 0.09295448111535197, 0.045539986342191696, 0.0980997234582901, 0.37569673166426176, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 170 0.0006000000000000001 64 1] 3
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
Epoch 1/170
1493/1493 - 9s - loss: 0.0245 - val_loss: 0.0213 - 9s/epoch - 6ms/step
Epoch 2/170
1493/1493 - 6s - loss: 0.0149 - val_loss: 0.0161 - 6s/epoch - 4ms/step
Epoch 3/170
1493/1493 - 6s - loss: 0.0132 - val_loss: 0.0122 - 6s/epoch - 4ms/step
Epoch 4/170
1493/1493 - 6s - loss: 0.0122 - val_loss: 0.0116 - 6s/epoch - 4ms/step
Epoch 5/170
1493/1493 - 6s - loss: 0.0118 - val_loss: 0.0113 - 6s/epoch - 4ms/step
Epoch 6/170
1493/1493 - 6s - loss: 0.0114 - val_loss: 0.0109 - 6s/epoch - 4ms/step
Epoch 7/170
1493/1493 - 6s - loss: 0.0111 - val_loss: 0.0108 - 6s/epoch - 4ms/step
Epoch 8/170
1493/1493 - 6s - loss: 0.0110 - val_loss: 0.0105 - 6s/epoch - 4ms/step
Epoch 9/170
1493/1493 - 6s - loss: 0.0107 - val_loss: 0.0104 - 6s/epoch - 4ms/step
Epoch 10/170
1493/1493 - 6s - loss: 0.0106 - val_loss: 0.0103 - 6s/epoch - 4ms/step
Epoch 11/170
1493/1493 - 6s - loss: 0.0105 - val_loss: 0.0102 - 6s/epoch - 4ms/step
Epoch 12/170
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 13/170
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0101 - 6s/epoch - 4ms/step
Epoch 14/170
1493/1493 - 6s - loss: 0.0104 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 15/170
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 16/170
1493/1493 - 6s - loss: 0.0103 - val_loss: 0.0100 - 6s/epoch - 4ms/step
Epoch 17/170
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 18/170
1493/1493 - 6s - loss: 0.0102 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 19/170
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0099 - 6s/epoch - 4ms/step
Epoch 20/170
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 21/170
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 22/170
1493/1493 - 6s - loss: 0.0101 - val_loss: 0.0098 - 6s/epoch - 4ms/step
Epoch 23/170
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 24/170
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 25/170
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 26/170
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 27/170
1493/1493 - 6s - loss: 0.0100 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 28/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0097 - 6s/epoch - 4ms/step
Epoch 29/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 30/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 31/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 32/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 33/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 34/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 35/170
1493/1493 - 6s - loss: 0.0099 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 36/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 37/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 38/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0096 - 6s/epoch - 4ms/step
Epoch 39/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 40/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 41/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 42/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 43/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 44/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 45/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 46/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 47/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 48/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 49/170
1493/1493 - 6s - loss: 0.0098 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 50/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 51/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 52/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 53/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 54/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 55/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 56/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 57/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0095 - 6s/epoch - 4ms/step
Epoch 58/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 59/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 60/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 61/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 62/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 63/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 64/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 65/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 66/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 67/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 68/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 69/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 70/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 71/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 72/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 73/170
1493/1493 - 6s - loss: 0.0097 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 74/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 75/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 76/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 77/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 78/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 79/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 80/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 81/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 82/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 83/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 84/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 85/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 86/170
1493/1493 - 7s - loss: 0.0096 - val_loss: 0.0094 - 7s/epoch - 4ms/step
Epoch 87/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 88/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 89/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 90/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 91/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 92/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 93/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 94/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 95/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 96/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 97/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 98/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 99/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 100/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 101/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 102/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 103/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 104/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 105/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 106/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 107/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 108/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0094 - 6s/epoch - 4ms/step
Epoch 109/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 110/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 111/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 112/170
1493/1493 - 6s - loss: 0.0096 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 113/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 114/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 115/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 116/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 117/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 118/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 119/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 120/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 121/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 122/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 123/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 124/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 125/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 126/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 127/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 128/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 129/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 130/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 131/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 132/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 133/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 134/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 135/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 136/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 137/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 138/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 139/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 140/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 141/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 142/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 143/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 144/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 145/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 146/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 147/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 148/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 149/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 150/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 151/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 152/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 153/170
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 154/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 155/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 156/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 157/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 158/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 159/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 160/170
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 161/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0093 - 6s/epoch - 4ms/step
Epoch 162/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 163/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 164/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 165/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 166/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 167/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 168/170
1493/1493 - 7s - loss: 0.0095 - val_loss: 0.0092 - 7s/epoch - 4ms/step
Epoch 169/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
Epoch 170/170
1493/1493 - 6s - loss: 0.0095 - val_loss: 0.0092 - 6s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00922928936779499
  1/332 [..............................] - ETA: 1:08 43/332 [==>...........................] - ETA: 0s   87/332 [======>.......................] - ETA: 0s129/332 [==========>...................] - ETA: 0s172/332 [==============>...............] - ETA: 0s214/332 [==================>...........] - ETA: 0s257/332 [======================>.......] - ETA: 0s299/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.07148369938932722
cosine 0.05611968183692698
MAE: 0.035228737
RMSE: 0.07703612
r2: 0.6150106339576512
RMSE zero-vector: 0.23411466903540806
['1.5999999999999996custom_VAE', 'mse', 64, 170, 0.0006000000000000001, 0.2, 252, 0.009467029944062233, 0.00922928936779499, 0.07148369938932722, 0.05611968183692698, 0.03522873669862747, 0.07703611999750137, 0.6150106339576512, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.3999999999999995 185 0.0006000000000000001 256 2] 4
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 1769)         2237785     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 1769)        7076        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 1769)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          446040      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          446040      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         2756677     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 5,893,618
Trainable params: 5,886,038
Non-trainable params: 7,580
__________________________________________________________________________________________________
Epoch 1/185
374/374 - 12s - loss: 0.0194 - val_loss: 0.0131 - 12s/epoch - 33ms/step
Epoch 2/185
374/374 - 2s - loss: 0.0081 - val_loss: 0.0210 - 2s/epoch - 5ms/step
Epoch 3/185
374/374 - 2s - loss: 0.0080 - val_loss: 0.0089 - 2s/epoch - 5ms/step
Epoch 4/185
374/374 - 2s - loss: 0.0076 - val_loss: 0.0107 - 2s/epoch - 5ms/step
Epoch 5/185
374/374 - 2s - loss: 0.0076 - val_loss: 0.0106 - 2s/epoch - 6ms/step
Epoch 6/185
374/374 - 2s - loss: 0.0075 - val_loss: 0.0088 - 2s/epoch - 6ms/step
Epoch 7/185
374/374 - 2s - loss: 0.0073 - val_loss: 0.0079 - 2s/epoch - 5ms/step
Epoch 8/185
374/374 - 2s - loss: 0.0072 - val_loss: 0.0088 - 2s/epoch - 5ms/step
Epoch 9/185
374/374 - 2s - loss: 0.0071 - val_loss: 0.0076 - 2s/epoch - 6ms/step
Epoch 10/185
374/374 - 2s - loss: 0.0070 - val_loss: 0.0080 - 2s/epoch - 6ms/step
Epoch 11/185
374/374 - 2s - loss: 0.0070 - val_loss: 0.0098 - 2s/epoch - 6ms/step
Epoch 12/185
374/374 - 2s - loss: 0.0069 - val_loss: 0.0067 - 2s/epoch - 6ms/step
Epoch 13/185
374/374 - 2s - loss: 0.0066 - val_loss: 0.0085 - 2s/epoch - 6ms/step
Epoch 14/185
374/374 - 2s - loss: 0.0066 - val_loss: 0.0248 - 2s/epoch - 5ms/step
Epoch 15/185
374/374 - 2s - loss: 0.0071 - val_loss: 0.0066 - 2s/epoch - 6ms/step
Epoch 16/185
374/374 - 2s - loss: 0.0064 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 17/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0064 - 2s/epoch - 5ms/step
Epoch 18/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0315 - 2s/epoch - 5ms/step
Epoch 19/185
374/374 - 2s - loss: 0.0081 - val_loss: 0.0072 - 2s/epoch - 5ms/step
Epoch 20/185
374/374 - 2s - loss: 0.0070 - val_loss: 0.0067 - 2s/epoch - 6ms/step
Epoch 21/185
374/374 - 2s - loss: 0.0065 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 22/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 23/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 24/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 25/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 26/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0071 - 2s/epoch - 6ms/step
Epoch 27/185
374/374 - 2s - loss: 0.0070 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 28/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 29/185
374/374 - 2s - loss: 0.0065 - val_loss: 0.0067 - 2s/epoch - 5ms/step
Epoch 30/185
374/374 - 2s - loss: 0.0079 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 31/185
374/374 - 2s - loss: 0.0071 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 32/185
374/374 - 2s - loss: 0.0064 - val_loss: 0.0064 - 2s/epoch - 6ms/step
Epoch 33/185
374/374 - 2s - loss: 0.0066 - val_loss: 0.0065 - 2s/epoch - 6ms/step
Epoch 34/185
374/374 - 2s - loss: 0.0069 - val_loss: 0.0063 - 2s/epoch - 6ms/step
Epoch 35/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 36/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 37/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 38/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 39/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 40/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 41/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 42/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 43/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 44/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 45/185
374/374 - 2s - loss: 0.0063 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 46/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0067 - 2s/epoch - 6ms/step
Epoch 47/185
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 48/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0065 - 2s/epoch - 5ms/step
Epoch 49/185
374/374 - 2s - loss: 0.0067 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 50/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 51/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 52/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 53/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 54/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 55/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 56/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 57/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 58/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 59/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 60/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0061 - 2s/epoch - 5ms/step
Epoch 61/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 62/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0063 - 2s/epoch - 5ms/step
Epoch 63/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 64/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 65/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0066 - 2s/epoch - 5ms/step
Epoch 66/185
374/374 - 2s - loss: 0.0065 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 67/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 68/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 69/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 70/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 71/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 72/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 73/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 74/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 75/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 76/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 77/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 78/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 79/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 80/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 6ms/step
Epoch 81/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 82/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 83/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 84/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 85/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 86/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 87/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 88/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 89/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 90/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 6ms/step
Epoch 91/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 92/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 93/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 94/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 95/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0061 - 2s/epoch - 6ms/step
Epoch 96/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 97/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0062 - 2s/epoch - 5ms/step
Epoch 98/185
374/374 - 2s - loss: 0.0062 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 99/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 100/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 101/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 102/185
374/374 - 2s - loss: 0.0061 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 103/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 104/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 105/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 106/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 107/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 108/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 109/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 110/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 111/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 112/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 113/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 114/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 115/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 116/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 117/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0060 - 2s/epoch - 5ms/step
Epoch 118/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 119/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 120/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 121/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 122/185
374/374 - 2s - loss: 0.0060 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 123/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 124/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 125/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 126/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 127/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 128/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 129/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 130/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 131/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 132/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 133/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 134/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 135/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 136/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 137/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 138/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 139/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 140/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 141/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 142/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 143/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 144/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 145/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 146/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 147/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 148/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 149/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 150/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 151/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 152/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 153/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 154/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 155/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 156/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 157/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 158/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 159/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 160/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 161/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 162/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 163/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 164/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 165/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 166/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 167/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 168/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 169/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 170/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 171/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 6ms/step
Epoch 172/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 173/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 174/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 175/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 176/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 6ms/step
Epoch 177/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0059 - 2s/epoch - 5ms/step
Epoch 178/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 179/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 180/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 181/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 182/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 183/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 184/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
Epoch 185/185
374/374 - 2s - loss: 0.0059 - val_loss: 0.0058 - 2s/epoch - 5ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005837646778672934
  1/332 [..............................] - ETA: 54s 45/332 [===>..........................] - ETA: 0s  90/332 [=======>......................] - ETA: 0s135/332 [===========>..................] - ETA: 0s179/332 [===============>..............] - ETA: 0s224/332 [===================>..........] - ETA: 0s266/332 [=======================>......] - ETA: 0s310/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11129630218013206
cosine 0.08708364902646237
MAE: 0.043583862
RMSE: 0.095045894
r2: 0.4139605191541509
RMSE zero-vector: 0.23411466903540806
['1.3999999999999995custom_VAE', 'logcosh', 256, 185, 0.0006000000000000001, 0.2, 252, 0.005886570084840059, 0.005837646778672934, 0.11129630218013206, 0.08708364902646237, 0.043583862483501434, 0.09504589438438416, 0.4139605191541509, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.4999999999999996 175 0.0006000000000000001 128 2] 5
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 1895)         2397175     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 1895)        7580        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 1895)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          477792      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         2948323     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,308,662
Trainable params: 6,300,578
Non-trainable params: 8,084
__________________________________________________________________________________________________
Epoch 1/175
747/747 - 6s - loss: 0.0156 - val_loss: 0.0191 - 6s/epoch - 9ms/step
Epoch 2/175
747/747 - 3s - loss: 0.0080 - val_loss: 0.0095 - 3s/epoch - 4ms/step
Epoch 3/175
747/747 - 3s - loss: 0.0077 - val_loss: 0.0079 - 3s/epoch - 4ms/step
Epoch 4/175
747/747 - 3s - loss: 0.0073 - val_loss: 0.0083 - 3s/epoch - 4ms/step
Epoch 5/175
747/747 - 3s - loss: 0.0071 - val_loss: 0.0073 - 3s/epoch - 4ms/step
Epoch 6/175
747/747 - 3s - loss: 0.0070 - val_loss: 0.0408 - 3s/epoch - 4ms/step
Epoch 7/175
747/747 - 3s - loss: 0.0073 - val_loss: 0.0068 - 3s/epoch - 4ms/step
Epoch 8/175
747/747 - 3s - loss: 0.0067 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 9/175
747/747 - 3s - loss: 0.0064 - val_loss: 0.0080 - 3s/epoch - 4ms/step
Epoch 10/175
747/747 - 3s - loss: 0.0066 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 11/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 12/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 13/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 14/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 15/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 16/175
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 17/175
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 18/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 19/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 20/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 21/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 22/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 23/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 24/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 26/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 27/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 28/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 29/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 30/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 31/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 32/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 33/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 34/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 35/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 36/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 37/175
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 39/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/175
747/747 - 4s - loss: 0.0060 - val_loss: 0.0060 - 4s/epoch - 5ms/step
Epoch 42/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 43/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 46/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 47/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 48/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 49/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 50/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 51/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 52/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 53/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 54/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 55/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 56/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 57/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 59/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 60/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 61/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 62/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 63/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 64/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 65/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 67/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 68/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 69/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 71/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 72/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 78/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 80/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 81/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 82/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/175
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 84/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 85/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 91/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 93/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 94/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/175
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 97/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 98/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/175
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 104/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 106/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 108/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 110/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 117/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 119/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 120/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 121/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 123/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 125/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 130/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 132/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 133/175
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 134/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 138/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 143/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 144/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 146/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 147/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 148/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 150/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 156/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 157/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 159/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 160/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 161/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 5ms/step
Epoch 164/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 165/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 167/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 170/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 171/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 172/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 173/175
747/747 - 4s - loss: 0.0059 - val_loss: 0.0058 - 4s/epoch - 5ms/step
Epoch 174/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
Epoch 175/175
747/747 - 3s - loss: 0.0059 - val_loss: 0.0058 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005845795851200819
  1/332 [..............................] - ETA: 1:01 45/332 [===>..........................] - ETA: 0s   89/332 [=======>......................] - ETA: 0s134/332 [===========>..................] - ETA: 0s177/332 [==============>...............] - ETA: 0s220/332 [==================>...........] - ETA: 0s263/332 [======================>.......] - ETA: 0s306/332 [==========================>...] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11247994894807041
cosine 0.08792274713493768
MAE: 0.044093132
RMSE: 0.09566152
r2: 0.40634418671876915
RMSE zero-vector: 0.23411466903540806
['1.4999999999999996custom_VAE', 'logcosh', 128, 175, 0.0006000000000000001, 0.2, 252, 0.005900931544601917, 0.005845795851200819, 0.11247994894807041, 0.08792274713493768, 0.04409313201904297, 0.09566152095794678, 0.40634418671876915, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.6999999999999997 170 0.0004000000000000001 128 2] 6
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2148)         2717220     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2148)        8592        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2148)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          541548      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3333136     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 7,142,044
Trainable params: 7,132,948
Non-trainable params: 9,096
__________________________________________________________________________________________________
Epoch 1/170
747/747 - 6s - loss: 0.0155 - val_loss: 0.0118 - 6s/epoch - 8ms/step
Epoch 2/170
747/747 - 3s - loss: 0.0084 - val_loss: 0.0096 - 3s/epoch - 4ms/step
Epoch 3/170
747/747 - 3s - loss: 0.0078 - val_loss: 0.0099 - 3s/epoch - 4ms/step
Epoch 4/170
747/747 - 3s - loss: 0.0074 - val_loss: 0.0077 - 3s/epoch - 4ms/step
Epoch 5/170
747/747 - 3s - loss: 0.0072 - val_loss: 0.0082 - 3s/epoch - 4ms/step
Epoch 6/170
747/747 - 3s - loss: 0.0070 - val_loss: 0.0070 - 3s/epoch - 4ms/step
Epoch 7/170
747/747 - 3s - loss: 0.0067 - val_loss: 0.0124 - 3s/epoch - 4ms/step
Epoch 8/170
747/747 - 3s - loss: 0.0066 - val_loss: 0.0066 - 3s/epoch - 4ms/step
Epoch 9/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 10/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 11/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 12/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 5ms/step
Epoch 13/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 14/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 15/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 16/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 17/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 18/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0064 - 3s/epoch - 4ms/step
Epoch 19/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 20/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0063 - 3s/epoch - 4ms/step
Epoch 21/170
747/747 - 3s - loss: 0.0064 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 22/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 23/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 24/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 25/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 26/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0063 - 3s/epoch - 5ms/step
Epoch 27/170
747/747 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 28/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 29/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 5ms/step
Epoch 30/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 31/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0062 - 3s/epoch - 4ms/step
Epoch 32/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 33/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 34/170
747/747 - 3s - loss: 0.0062 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 35/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 36/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0061 - 3s/epoch - 4ms/step
Epoch 37/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 38/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 39/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 40/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 41/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 42/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 43/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 44/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 45/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 46/170
747/747 - 3s - loss: 0.0061 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 47/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 48/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 49/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 50/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 51/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 52/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 53/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 54/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 55/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 56/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 57/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 58/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 59/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 60/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 61/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 62/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 4ms/step
Epoch 63/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 64/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0060 - 3s/epoch - 5ms/step
Epoch 65/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 66/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 67/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 68/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 69/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 70/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 71/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 72/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 73/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 74/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 75/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 76/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 77/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 78/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 79/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 80/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 81/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 82/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 83/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 84/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 85/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 86/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 87/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 88/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 89/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 90/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 91/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 92/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 93/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 94/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 95/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 96/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 97/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 98/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 99/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 100/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 101/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 102/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 103/170
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 104/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 105/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 106/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 107/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 108/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 109/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 110/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 111/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 112/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 113/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 114/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 115/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 116/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 117/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 118/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 119/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 120/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 121/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 122/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 123/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 124/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 125/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 126/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 127/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 128/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 129/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 130/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 131/170
747/747 - 4s - loss: 0.0060 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 132/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 133/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 134/170
747/747 - 3s - loss: 0.0060 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 135/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 136/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 137/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 138/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 139/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 140/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 141/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 142/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 143/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 144/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 145/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 146/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 147/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 148/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 149/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 150/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 151/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 152/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 153/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 154/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 155/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 156/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 157/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 158/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 159/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 160/170
747/747 - 4s - loss: 0.0059 - val_loss: 0.0059 - 4s/epoch - 5ms/step
Epoch 161/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 162/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 163/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 164/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 165/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 166/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 167/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 168/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
Epoch 169/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 5ms/step
Epoch 170/170
747/747 - 3s - loss: 0.0059 - val_loss: 0.0059 - 3s/epoch - 4ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.005874371621757746
  1/332 [..............................] - ETA: 1:00 45/332 [===>..........................] - ETA: 0s   88/332 [======>.......................] - ETA: 0s133/332 [===========>..................] - ETA: 0s178/332 [===============>..............] - ETA: 0s223/332 [===================>..........] - ETA: 0s267/332 [=======================>......] - ETA: 0s310/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 1ms/step
correlation 0.11605645438162641
cosine 0.09077645619208526
MAE: 0.04482407
RMSE: 0.09701299
r2: 0.3894517726342473
RMSE zero-vector: 0.23411466903540806
['1.6999999999999997custom_VAE', 'logcosh', 128, 170, 0.0004000000000000001, 0.2, 252, 0.005938221700489521, 0.005874371621757746, 0.11605645438162641, 0.09077645619208526, 0.04482407122850418, 0.09701298922300339, 0.3894517726342473, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'numpy.int64'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
[1.5999999999999996 165 0.0006000000000000001 128 1] 7
./tmp/ already created.
Shape of dataset to encode: (106113, 1264)
Model: "VAE"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_enc (InputLayer)         [(None, 1264)]       0           []                               
                                                                                                  
 dense_enc0 (Dense)             (None, 2022)         2557830     ['input_enc[0][0]']              
                                                                                                  
 batch_normalization (BatchNorm  (None, 2022)        8088        ['dense_enc0[0][0]']             
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, 2022)         0           ['batch_normalization[0][0]']    
                                                                                                  
 bottleneck_zmean (Dense)       (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck_zlog (Dense)        (None, 252)          509796      ['re_lu[0][0]']                  
                                                                                                  
 bottleneck (SamplingLayer)     (None, 252)          0           ['bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
 decoder_model (Functional)     (None, 1264)         3141490     ['bottleneck[0][0]']             
                                                                                                  
 vae_loss_layer (VAELossLayer)  (None, 1264)         0           ['input_enc[0][0]',              
                                                                  'decoder_model[0][0]',          
                                                                  'bottleneck_zmean[0][0]',       
                                                                  'bottleneck_zlog[0][0]']        
                                                                                                  
==================================================================================================
Total params: 6,727,000
Trainable params: 6,718,408
Non-trainable params: 8,592
__________________________________________________________________________________________________
/var/spool/slurmd/job36110051/slurm_script: line 23: 54026 Killed                  python3 -u genetic.py >> log.txt
Mon Feb 20 14:58:26 CET 2023
done
slurmstepd: error: Detected 1 oom-kill event(s) in StepId=36110051.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.
