architecture loss_fn batch_size epochs learning_rate n_bottleneck_ratio n_bottleneck train_loss val_loss correlation "cosine dist" MAE RMSE R2 "RMSE zero-vector" neurons
1.5custom_n_b mse 64 200 0.0005 0.2 252 0.00020555 0.00021332 0.00245947 0.00194048 0.00796308 0.0146054 0.98616192 0.23411467 1.5
1.6custom_n_b mse 64 200 0.0005 0.2 252 0.00020466 0.00020545 0.00236374 0.00186294 0.00781628 0.01433355 0.98667235 0.23411467 1.6
1.7custom_n_b mse 64 200 0.0005 0.2 252 0.00019599 0.00020181 0.00231466 0.00182407 0.00780714 0.01420598 0.98690853 0.23411467 1.7
1.8custom_n_b mse 64 200 0.0005 0.2 252 0.00019709 0.00021264 0.00244388 0.00192544 0.00781297 0.0145821 0.98620627 0.23411467 1.8
1.9custom_n_b mse 64 200 0.0005 0.2 252 0.00017894 0.00018844 0.00216357 0.00170412 0.00748442 0.01372747 0.98777581 0.23411467 1.9
2.0custom_n_b mse 64 200 0.0005 0.2 252 0.00018169 0.00020078 0.00228432 0.00179789 0.00773615 0.0141698 0.98697524 0.23411467 2.0
2.1custom_n_b mse 64 200 0.0005 0.2 252 0.00019047 0.0001999 0.00230264 0.00181222 0.00756583 0.01413867 0.9870324 0.23411467 2.1
2.2custom_n_b mse 64 200 0.0005 0.2 252 0.00018525 0.00018862 0.00217122 0.0017084 0.00743208 0.01373385 0.98776456 0.23411467 2.2
2.3custom_n_b mse 64 200 0.0005 0.2 252 0.00018605 0.00019439 0.00223726 0.00176106 0.00753533 0.01394237 0.98739008 0.23411467 2.3
2.4custom_n_b mse 64 200 0.0005 0.2 252 0.00019028 0.00020167 0.00232212 0.00182697 0.00763182 0.01420089 0.9869183 0.23411467 2.4
2.5custom_n_b mse 64 200 0.0005 0.2 252 0.00017889 0.00019096 0.00219254 0.001725 0.00750512 0.01381871 0.98761296 0.23411467 2.5
1.5custom_n_b mse 64 200 0.0005 0.5 632 0.00011211 0.00011858 0.00132834 0.00104602 0.00625037 0.01088964 0.99230754 0.23411467 1.5
1.5custom_n_b mse 64 200 0.0005 0.5 632 0.00011116 0.00011096 0.00126466 0.00099568 0.00588618 0.01053378 0.99280243 0.23411467 1.5
1.6custom_n_b mse 64 200 0.0005 0.5 632 0.00010821 0.00011479 0.0013059 0.00102826 0.00605602 0.0107142 0.99255388 0.23411467 1.6
1.7custom_n_b mse 64 200 0.0005 0.5 632 0.00010475 0.00011064 0.00125748 0.00099065 0.00591029 0.0105185 0.99282323 0.23411467 1.7
1.8custom_n_b mse 64 200 0.0005 0.5 632 0.00010375 0.00010621 0.00120731 0.00095012 0.00581959 0.01030558 0.99311185 0.23411467 1.8
1.9custom_n_b mse 64 200 0.0005 0.5 632 0.0001027 0.00010376 0.00118074 0.00093095 0.00570228 0.01018637 0.99327008 0.23411467 1.9
2.0custom_n_b mse 64 200 0.0005 0.5 632 0.00010137 0.00010687 0.00120408 0.00095018 0.00579359 0.01033758 0.99306874 0.23411467 2.0
2.1custom_n_b mse 64 200 0.0005 0.5 632 0.00010221 9.962e-05 0.0011304 0.00089013 0.00553267 0.00998078 0.99353867 0.23411467 2.1
2.2custom_n_b mse 64 200 0.0005 0.5 632 9.595e-05 9.495e-05 0.00107884 0.00085006 0.0053964 0.00974424 0.99384172 0.23411467 2.2
2.3custom_n_b mse 64 200 0.0005 0.5 632 9.612e-05 9.777e-05 0.00111072 0.00087526 0.00550407 0.00988803 0.99365838 0.23411467 2.3
2.4custom_n_b mse 64 200 0.0005 0.5 632 0.00010277 9.55e-05 0.00108582 0.00085564 0.0054715 0.00977215 0.99380633 0.23411467 2.4
1.5custom_n_b mse 64 200 0.0005 0.8 1011 9.707e-05 9.288e-05 0.00105836 0.00083435 0.00548435 0.00963729 0.99397537 0.23411467 1.5
1.6custom_n_b mse 64 200 0.0005 0.8 1011 9.309e-05 9.95e-05 0.00111999 0.00088096 0.0056163 0.00997505 0.99354564 0.23411467 1.6
1.7custom_n_b mse 64 200 0.0005 0.8 1011 9.276e-05 9.198e-05 0.00104951 0.00082765 0.00538205 0.00959054 0.99403372 0.23411467 1.7
1.8custom_n_b mse 64 200 0.0005 0.8 1011 8.68e-05 9.177e-05 0.00104123 0.00081966 0.00529774 0.00957977 0.99404719 0.23411467 1.8
1.9custom_n_b mse 64 200 0.0005 0.8 1011 8.731e-05 9.037e-05 0.00102416 0.00080613 0.00524657 0.00950646 0.99413863 0.23411467 1.9
2.0custom_n_b mse 64 200 0.0005 0.8 1011 8.514e-05 9.044e-05 0.00101793 0.0008019 0.0052984 0.00951006 0.99413296 0.23411467 2.0
2.1custom_n_b mse 64 200 0.0005 0.8 1011 8.625e-05 7.973e-05 0.00089865 0.00070862 0.00502315 0.008929 0.99482904 0.23411467 2.1
2.2custom_n_b mse 64 200 0.0005 0.8 1011 8.17e-05 7.948e-05 0.00090267 0.00071068 0.00488009 0.00891509 0.9948442 0.23411467 2.2
