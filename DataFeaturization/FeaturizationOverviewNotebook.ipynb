{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22587c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-12 17:19:50,732 - modnet - INFO - Loaded <modnet.preprocessing.MODData object at 0x7fb3340c5580> object, created with modnet version 0.1.12\n"
     ]
    }
   ],
   "source": [
    "from modnet.preprocessing import MODData\n",
    "data=MODData.load('../DATAFILES/matbench_perovskites_moddata.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa26c6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id0</th>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18923</th>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18924</th>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18925</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18926</th>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18927</th>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18928 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         e_form\n",
       "id0        2.16\n",
       "id1        1.52\n",
       "id2        1.48\n",
       "id3        1.24\n",
       "id4        0.62\n",
       "...         ...\n",
       "id18923    1.66\n",
       "id18924    2.12\n",
       "id18925    1.50\n",
       "id18926    2.48\n",
       "id18927    1.06\n",
       "\n",
       "[18928 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df_targets['e_form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0625dc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "BaggingLR_OFM.ipynb\t       OFM_customfeaturized18928.pkl\r\n",
      "DATAFILES\t\t       OFM_customfeaturized2000.pkl\r\n",
      "Featurization\t\t       OFM_customfeaturized3000.pkl\r\n",
      "FeaturizingData.ipynb\t       OFM_customfeaturized4000.pkl\r\n",
      "OFMClusterModel\t\t       OFM_customfeaturized5000.pkl\r\n",
      "OFM_customfeaturized1000.pkl   OFM_customfeaturized6000.pkl\r\n",
      "OFM_customfeaturized10000.pkl  OFM_customfeaturized7000.pkl\r\n",
      "OFM_customfeaturized11000.pkl  OFM_customfeaturized8000.pkl\r\n",
      "OFM_customfeaturized12000.pkl  OFM_customfeaturized9000.pkl\r\n",
      "OFM_customfeaturized13000.pkl  README.md\r\n",
      "OFM_customfeaturized14000.pkl  make_subsets_data.py\r\n",
      "OFM_customfeaturized15000.pkl  noOFM\r\n",
      "OFM_customfeaturized16000.pkl  run_benchmark.py\r\n",
      "OFM_customfeaturized17000.pkl  withOFM\r\n",
      "OFM_customfeaturized18000.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3800b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.featurizers.structure import OrbitalFieldMatrix\n",
    "import pickle, os\n",
    "try:\n",
    "    os.mkdir(\"OFM_featurization\")\n",
    "except:\n",
    "    pass\n",
    "featurizers=[OrbitalFieldMatrix(period_tag=False)]\n",
    "for featurizer in featurizers:\n",
    "    for idx in list(range(0,17000,1000)):\n",
    "        featurizer=OrbitalFieldMatrix()\n",
    "        featurizer.set_n_jobs(8)\n",
    "        #data.df_structure=data.df_structure #.sample(n=10, random_state=1)\n",
    "        print(idx,idx+1000)\n",
    "        df_feat=featurizer.featurize_dataframe(data.df_structure[idx:idx+1000], 'structure',)\n",
    "                                               #ignore_errors=True,return_errors=True)\n",
    "        # save complete featurized dataframe\n",
    "        pickle.dump(df_feat, open(f\"OFM_featurization/OFM_customfeaturized{idx+1000}.pkl\",\"wb\"))\n",
    "\n",
    "    df_feat=featurizer.featurize_dataframe(data.df_structure[17000:18000], 'structure',)\n",
    "    # save complete featurized dataframe\n",
    "    pickle.dump(df_feat, open(f\"OFM_featurization/OFM_customfeaturized18000.pkl\",\"wb\"))\n",
    "    df_feat=featurizer.featurize_dataframe(data.df_structure[18000:], 'structure',)\n",
    "    # save complete featurized dataframe\n",
    "    pickle.dump(df_feat, open(f\"OFM_featurization/OFM_customfeaturized18928.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a10cf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OFM_featurization/OFM_customfeaturized1000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized2000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized3000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized4000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized5000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized6000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized7000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized8000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized9000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized10000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized11000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized12000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized13000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized14000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized15000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized16000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized17000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized18000.pkl.\n",
      "Loaded OFM_featurization/OFM_customfeaturized18928.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>species</th>\n",
       "      <th>OFM: s^1 - s^1</th>\n",
       "      <th>OFM: s^1 - s^2</th>\n",
       "      <th>OFM: s^1 - p^1</th>\n",
       "      <th>OFM: s^1 - p^2</th>\n",
       "      <th>OFM: s^1 - p^3</th>\n",
       "      <th>OFM: s^1 - p^4</th>\n",
       "      <th>OFM: s^1 - p^5</th>\n",
       "      <th>OFM: s^1 - p^6</th>\n",
       "      <th>...</th>\n",
       "      <th>OFM: f^14 - f^5</th>\n",
       "      <th>OFM: f^14 - f^6</th>\n",
       "      <th>OFM: f^14 - f^7</th>\n",
       "      <th>OFM: f^14 - f^8</th>\n",
       "      <th>OFM: f^14 - f^9</th>\n",
       "      <th>OFM: f^14 - f^10</th>\n",
       "      <th>OFM: f^14 - f^11</th>\n",
       "      <th>OFM: f^14 - f^12</th>\n",
       "      <th>OFM: f^14 - f^13</th>\n",
       "      <th>OFM: f^14 - f^14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id0</th>\n",
       "      <td>[[0. 0. 0.] Rh, [1.97726555 1.97726555 1.97726...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.227089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>[[2.54041798 0.         0.        ] Hf, [1.020...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>[[0.60790913 0.         0.        ] Re, [2.186...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>[[2.83091357 0.         0.        ] W, [2.6573...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>[[0.00518937 0.         0.        ] Bi, [2.172...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18923</th>\n",
       "      <td>[[4.44077598 0.         0.        ] Rb, [2.652...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.440094e-07</td>\n",
       "      <td>0.184377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18924</th>\n",
       "      <td>[[4.56913824e-03 7.21569024e-19 0.00000000e+00...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.721372e-12</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064983</td>\n",
       "      <td>0.129850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18925</th>\n",
       "      <td>[[0.0040044 0.        0.       ] Zn, [1.821570...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18926</th>\n",
       "      <td>[[0. 0. 0.] Ca, [2.16744896 2.16744896 2.16744...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18927</th>\n",
       "      <td>[[1.23999712 4.09195837 4.09195837] Al, [2.500...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18928 rows Ã— 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 structure  species  \\\n",
       "id                                                                    \n",
       "id0      [[0. 0. 0.] Rh, [1.97726555 1.97726555 1.97726...        5   \n",
       "id1      [[2.54041798 0.         0.        ] Hf, [1.020...        5   \n",
       "id2      [[0.60790913 0.         0.        ] Re, [2.186...        5   \n",
       "id3      [[2.83091357 0.         0.        ] W, [2.6573...        5   \n",
       "id4      [[0.00518937 0.         0.        ] Bi, [2.172...        5   \n",
       "...                                                    ...      ...   \n",
       "id18923  [[4.44077598 0.         0.        ] Rb, [2.652...        5   \n",
       "id18924  [[4.56913824e-03 7.21569024e-19 0.00000000e+00...        5   \n",
       "id18925  [[0.0040044 0.        0.       ] Zn, [1.821570...        5   \n",
       "id18926  [[0. 0. 0.] Ca, [2.16744896 2.16744896 2.16744...        5   \n",
       "id18927  [[1.23999712 4.09195837 4.09195837] Al, [2.500...        5   \n",
       "\n",
       "         OFM: s^1 - s^1  OFM: s^1 - s^2  OFM: s^1 - p^1  OFM: s^1 - p^2  \\\n",
       "id                                                                        \n",
       "id0        0.000000e+00        0.227089             0.0             0.0   \n",
       "id1        0.000000e+00        0.000000             0.0             0.0   \n",
       "id2        0.000000e+00        0.000000             0.0             0.0   \n",
       "id3        0.000000e+00        0.000000             0.0             0.0   \n",
       "id4        0.000000e+00        0.000000             0.0             0.0   \n",
       "...                 ...             ...             ...             ...   \n",
       "id18923    2.440094e-07        0.184377             0.0             0.0   \n",
       "id18924    3.721372e-12        0.194835             0.0             0.0   \n",
       "id18925    0.000000e+00        0.000000             0.0             0.0   \n",
       "id18926    0.000000e+00        0.000000             0.0             0.0   \n",
       "id18927    0.000000e+00        0.000000             0.0             0.0   \n",
       "\n",
       "         OFM: s^1 - p^3  OFM: s^1 - p^4  OFM: s^1 - p^5  OFM: s^1 - p^6  ...  \\\n",
       "id                                                                       ...   \n",
       "id0            0.227089        0.000000             0.0        0.000000  ...   \n",
       "id1            0.000000        0.000000             0.0        0.000000  ...   \n",
       "id2            0.000000        0.000000             0.0        0.000000  ...   \n",
       "id3            0.000000        0.000000             0.0        0.000000  ...   \n",
       "id4            0.000000        0.000000             0.0        0.000000  ...   \n",
       "...                 ...             ...             ...             ...  ...   \n",
       "id18923        0.000000        0.181689             0.0        0.002688  ...   \n",
       "id18924        0.064983        0.129850             0.0        0.000000  ...   \n",
       "id18925        0.000000        0.000000             0.0        0.000000  ...   \n",
       "id18926        0.000000        0.000000             0.0        0.000000  ...   \n",
       "id18927        0.000000        0.000000             0.0        0.000000  ...   \n",
       "\n",
       "         OFM: f^14 - f^5  OFM: f^14 - f^6  OFM: f^14 - f^7  OFM: f^14 - f^8  \\\n",
       "id                                                                            \n",
       "id0                  0.0              0.0              0.0              0.0   \n",
       "id1                  0.0              0.0              0.0              0.0   \n",
       "id2                  0.0              0.0              0.0              0.0   \n",
       "id3                  0.0              0.0              0.0              0.0   \n",
       "id4                  0.0              0.0              0.0              0.0   \n",
       "...                  ...              ...              ...              ...   \n",
       "id18923              0.0              0.0              0.0              0.0   \n",
       "id18924              0.0              0.0              0.0              0.0   \n",
       "id18925              0.0              0.0              0.0              0.0   \n",
       "id18926              0.0              0.0              0.0              0.0   \n",
       "id18927              0.0              0.0              0.0              0.0   \n",
       "\n",
       "         OFM: f^14 - f^9  OFM: f^14 - f^10  OFM: f^14 - f^11  \\\n",
       "id                                                             \n",
       "id0                  0.0               0.0               0.0   \n",
       "id1                  0.0               0.0               0.0   \n",
       "id2                  0.0               0.0               0.0   \n",
       "id3                  0.0               0.0               0.0   \n",
       "id4                  0.0               0.0               0.0   \n",
       "...                  ...               ...               ...   \n",
       "id18923              0.0               0.0               0.0   \n",
       "id18924              0.0               0.0               0.0   \n",
       "id18925              0.0               0.0               0.0   \n",
       "id18926              0.0               0.0               0.0   \n",
       "id18927              0.0               0.0               0.0   \n",
       "\n",
       "         OFM: f^14 - f^12  OFM: f^14 - f^13  OFM: f^14 - f^14  \n",
       "id                                                             \n",
       "id0                   0.0               0.0          0.000000  \n",
       "id1                   0.0               0.0          0.008017  \n",
       "id2                   0.0               0.0          0.000475  \n",
       "id3                   0.0               0.0          0.038130  \n",
       "id4                   0.0               0.0          0.000056  \n",
       "...                   ...               ...               ...  \n",
       "id18923               0.0               0.0          0.000000  \n",
       "id18924               0.0               0.0          0.000000  \n",
       "id18925               0.0               0.0          0.000000  \n",
       "id18926               0.0               0.0          0.000000  \n",
       "id18927               0.0               0.0          0.000000  \n",
       "\n",
       "[18928 rows x 1026 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle, glob\n",
    "OFMs=[]\n",
    "for idx in list(range(0,18000,1000))+[17928]:\n",
    "    file=f\"OFM_featurization/OFM_customfeaturized{idx+1000}.pkl\"\n",
    "    OFM=pickle.load(open(file,\"rb\"))\n",
    "    OFMs.append(OFM)\n",
    "    print(f\"Loaded {file}.\")\n",
    "import pandas as pd\n",
    "featurizedOFM=pd.concat(OFMs,axis=0)\n",
    "featurizedOFM=featurizedOFM.drop(['species','structure'],axis=1)\n",
    "pickle.dump(featurizedOFM,open(\"OFM_featurization/OFM_featurizedDF.pkl\",\"wb\"))\n",
    "featurizedOFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db3cb8",
   "metadata": {},
   "source": [
    "###  Lets find the optimal PCA components to represent the OFM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5cba681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "# Separating the features\n",
    "X=featurizedOFM.drop(['species','structure'],axis=1)\n",
    "Xcolumns=X.columns\n",
    "# Standardizing the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "# Separating out the target ## !!! ideally I should implement this for the train set only. !!!\n",
    "y = data.df_targets['e_form'] \n",
    "\n",
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44727ca",
   "metadata": {},
   "source": [
    "### So around 200 components we have over 99% of the variance described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b1db8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941819169273535"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a182c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=200\n",
    "pca = PCA(n_components=n_components)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "OFM_PC_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = [f'OFM|PC_{idx+1}' for idx in range(n_components) ])\n",
    "OFM_PC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7389d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we should save the OFM components to retrieve the chemical information in each PC\n",
    "n_components=200\n",
    "OFM_PCAcomponents = pd.DataFrame(pca.components_[:n_components], \n",
    "                                 columns=Xcolumns,\n",
    "                                 index=[f'OFM|PC_{idx+1}' for idx in range(n_components)])\n",
    "import pickle\n",
    "pickle.dump(OFM_PCAcomponents,open(\"OFM_featurization/OFM_PCAcomponents.pkl\",\"wb\"))\n",
    "OFM_PCAcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003a228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "BaggingLR_OFM.ipynb\t       OFM_customfeaturized18928.pkl\r\n",
      "DATAFILES\t\t       OFM_customfeaturized2000.pkl\r\n",
      "Featurization\t\t       OFM_customfeaturized3000.pkl\r\n",
      "FeaturizingData.ipynb\t       OFM_customfeaturized4000.pkl\r\n",
      "OFMClusterModel\t\t       OFM_customfeaturized5000.pkl\r\n",
      "OFM_PCAcomponents.pkl\t       OFM_customfeaturized6000.pkl\r\n",
      "OFM_customfeaturized1000.pkl   OFM_customfeaturized7000.pkl\r\n",
      "OFM_customfeaturized10000.pkl  OFM_customfeaturized8000.pkl\r\n",
      "OFM_customfeaturized11000.pkl  OFM_customfeaturized9000.pkl\r\n",
      "OFM_customfeaturized12000.pkl  README.md\r\n",
      "OFM_customfeaturized13000.pkl  ase_structures.pkl\r\n",
      "OFM_customfeaturized14000.pkl  make_subsets_data.py\r\n",
      "OFM_customfeaturized15000.pkl  noOFM\r\n",
      "OFM_customfeaturized16000.pkl  run_benchmark.py\r\n",
      "OFM_customfeaturized17000.pkl  withOFM\r\n",
      "OFM_customfeaturized18000.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6f64dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18928, 1024)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we still can access each component allowing to restore the original data\n",
    "pca.components_[0].shape\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6693c53",
   "metadata": {},
   "source": [
    "### Now to featurize with SOAP. I will try to make the columns a bit more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c76b1941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([ 0.00024594,  0.00463535, -0.00517914, ...,  0.00927274,\n",
       "         -0.0251723 ,  0.06833416]),\n",
       "  array([ 309288,  309289,  309290, ..., 2115117, 2115118, 2115119])],\n",
       " [array([ 0.00071318,  0.00778535, -0.0035089 , ...,  0.14981408,\n",
       "         -0.13816099,  0.13395656]),\n",
       "  array([ 359268,  359269,  359270, ..., 2626397, 2626398, 2626399])],\n",
       " [array([ 0.00041332,  0.00405851, -0.00116177, ...,  0.10758495,\n",
       "         -0.08258327,  0.06553132]),\n",
       "  array([ 359268,  359269,  359270, ..., 2687633, 2687634, 2687635])]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dscribe.descriptors import SOAP\n",
    "import pickle\n",
    "import pymatgen\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from ase.data import atomic_numbers\n",
    "import os\n",
    "import pandas as pd\n",
    "structures=data.df_structure['structure']\n",
    "try:\n",
    "    structures_ase=pickle.load(open(\"ase_structures.pkl\",\"rb\"))\n",
    "except:\n",
    "    structures_ase=list(map(AseAtomsAdaptor.get_atoms,structures))\n",
    "    pickle.dump(structures_ase,open(\"ase_structures.pkl\",\"wb\"))\n",
    "    \n",
    "## declaring the SOAP featurizer\n",
    "species=list(atomic_numbers.keys())[1:] ## all chemical species\n",
    "nmax=8\n",
    "lmax=6\n",
    "rcut=5\n",
    "average_soap = SOAP(species=species,\n",
    "rcut=rcut, nmax=nmax, lmax=lmax,\n",
    "    average=\"inner\",\n",
    "    crossover=True,\n",
    "    periodic=True,\n",
    "    sparse=False\n",
    ")\n",
    "soap_results = average_soap.create(structures_ase[:3])\n",
    "results=[]\n",
    "for i in range(len(soap_results)):\n",
    "    ## SOAP data is too large and sparse, its better to work with values and index\n",
    "    results.append([soap_results[i][soap_results[i].nonzero()[0]],\n",
    "                     soap_results[i].nonzero()[0]])\n",
    "results\n",
    "# type(results)\n",
    "# results=pd.DataFrame.sparse.from_spmatrix(results)\n",
    "# ncpus=os.cpu_count()\n",
    "# ## this is very memory intensive has to be splitted\n",
    "# slices=[None]+list(range(100,len(structures_ase),100))+[None]\n",
    "# for i, slice1 in list(enumerate(slices))[:-1]:\n",
    "#     results = average_soap.create(structures_ase[slice1:slices[i+1]], n_jobs=ncpus)\n",
    "#     pickle.dump(results, open(f\"SOAP_perovsk_featurized_{i}.pkl\",\"wb\"))\n",
    "#     print(f\"{i} out of {len(slices)-2} subsets to complete SOAP featurization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09bd6406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16182/3537502687.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_results=np.array(results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[array([ 0.00024594,  0.00463535, -0.00517914, ...,  0.00927274,\n",
       "               -0.0251723 ,  0.06833416])                              ,\n",
       "        array([ 309288,  309289,  309290, ..., 2115117, 2115118, 2115119])],\n",
       "       [array([ 0.00071318,  0.00778535, -0.0035089 , ...,  0.14981408,\n",
       "               -0.13816099,  0.13395656])                              ,\n",
       "        array([ 359268,  359269,  359270, ..., 2626397, 2626398, 2626399])],\n",
       "       [array([ 0.00041332,  0.00405851, -0.00116177, ...,  0.10758495,\n",
       "               -0.08258327,  0.06553132])                              ,\n",
       "        array([ 359268,  359269,  359270, ..., 2687633, 2687634, 2687635])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_results=np.array(results)\n",
    "np_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67089e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "623f0812",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,2100) into shape (3122280,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m results0\u001b[38;5;241m=\u001b[39m[results[\u001b[38;5;241m0\u001b[39m][results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]],results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(results0)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,2100) into shape (3122280,)"
     ]
    }
   ],
   "source": [
    "results0=[results[0][results[0].nonzero()[0]],results[0].nonzero()[0]]\n",
    "results[0]=np.array(results0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c0607",
   "metadata": {},
   "source": [
    "## Now for the MEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df72a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slice 1 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 14:58:41.560868: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-12 14:58:41.560921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ROGERIO): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 14:58:41.565090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculated for model Eform_MP_2019.\n",
      "Features calculated for model Efermi_MP_2019.\n",
      "Features calculated for model Bandgap_MP_2018.\n",
      "Features calculated for model logK_MP_2019.\n",
      "Features calculated for model logG_MP_2019.\n",
      "Processing slice 2 out of 20\n",
      "Features calculated for model Eform_MP_2019.\n",
      "Features calculated for model Efermi_MP_2019.\n",
      "Features calculated for model Bandgap_MP_2018.\n",
      "Features calculated for model logK_MP_2019.\n",
      "Features calculated for model logG_MP_2019.\n",
      "Processing slice 3 out of 20\n",
      "Features calculated for model Eform_MP_2019.\n",
      "Features calculated for model Efermi_MP_2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Isolated atoms found in the structure. The cutoff radius might be small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculated for model Bandgap_MP_2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Isolated atoms found in the structure. The cutoff radius might be small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculated for model logK_MP_2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Isolated atoms found in the structure. The cutoff radius might be small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculated for model logG_MP_2019.\n",
      "Processing slice 4 out of 20\n",
      "Features calculated for model Eform_MP_2019.\n",
      "Features calculated for model Efermi_MP_2019.\n",
      "Features calculated for model Bandgap_MP_2018.\n",
      "Features calculated for model logK_MP_2019.\n",
      "Features calculated for model logG_MP_2019.\n",
      "Processing slice 5 out of 20\n",
      "Features calculated for model Eform_MP_2019.\n",
      "Features calculated for model Efermi_MP_2019.\n",
      "Features calculated for model Bandgap_MP_2018.\n",
      "Features calculated for model logK_MP_2019.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(slices)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing slice \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(slices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     MEGNetFeats_struct\u001b[38;5;241m=\u001b[39m\u001b[43mget_MEGNetFeaturesDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(MEGNetFeats_struct,\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMEGNetFeats_struct_slice\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m MEGNetFeats_struct\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mget_MEGNetFeaturesDF\u001b[0;34m(structures)\u001b[0m\n\u001b[1;32m     19\u001b[0m graph \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgraph_converter\u001b[38;5;241m.\u001b[39mconvert(s)\n\u001b[1;32m     20\u001b[0m inp \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgraph_converter\u001b[38;5;241m.\u001b[39mgraph_to_input(graph)\n\u001b[0;32m---> 21\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mintermediate_layer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m model_struct\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([pred[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]], \n\u001b[1;32m     23\u001b[0m                           columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMEGNet_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \n\u001b[1;32m     24\u001b[0m                                    \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pred[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]))])\n\u001b[1;32m     25\u001b[0m MEGNetModel_structs\u001b[38;5;241m.\u001b[39mappend(model_struct)\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/engine/training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2217\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2218\u001b[0m         )\n\u001b[0;32m-> 2220\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/engine/data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/engine/data_adapter.py:1283\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure_dataset_and_inferred_steps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribute\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/engine/data_adapter.py:1302\u001b[0m, in \u001b[0;36mDataHandler._configure_dataset_and_inferred_steps\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(dataset)\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/keras/engine/data_adapter.py:1467\u001b[0m, in \u001b[0;36mDataHandler._validate_data_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data_handler\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;66;03m# TODO(b/152094471): Support this with DistIter.get_next_as_optional.\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 1467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1468\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m     ):\n\u001b[1;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1471\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not infer the size of the data. With \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`steps_per_execution > 1`, you must specify the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1473\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps to run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1474\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:725\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 725\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    702\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    707\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    710\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    711\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    712\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    693\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 694\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:525\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    528\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from megnet.utils.models import load_model, AVAILABLE_MODELS\n",
    "from pymatgen.core import Structure, Lattice\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# print(AVAILABLE_MODELS)\n",
    "def get_MEGNetFeaturesDF(structures):\n",
    "    MEGNetFeats_structs=[]\n",
    "    for model_name in ['Eform_MP_2019','Efermi_MP_2019','Bandgap_MP_2018','logK_MP_2019','logG_MP_2019']:\n",
    "        model=load_model(model_name) \n",
    "        intermediate_layer_model = Model(inputs=model.input,\n",
    "                             outputs=model.layers[-3].output)   \n",
    "        MEGNetModel_structs=[]\n",
    "        for s in structures:\n",
    "            try:\n",
    "                graph = model.graph_converter.convert(s)\n",
    "                inp = model.graph_converter.graph_to_input(graph)\n",
    "                pred = intermediate_layer_model.predict(inp, verbose=False)\n",
    "                model_struct=pd.DataFrame([pred[0][0]], \n",
    "                                          columns=[f\"MEGNet_{model_name}_{idx+1}\" for idx in \n",
    "                                                   range(len(pred[0][0]))])\n",
    "                MEGNetModel_structs.append(model_struct)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Probably an invalid structure was passed to the model, continuing..\")\n",
    "                model_struct=pd.DataFrame([np.nan]*32, \n",
    "                                          columns=[f\"MEGNet_{model_name}_{idx+1}\" for idx in \n",
    "                                                   range(len(pred[0][0]))])\n",
    "                continue\n",
    "        ## now append the columns with the layer of each model\n",
    "        MEGNetModel_structs=pd.concat(MEGNetModel_structs,axis=0)\n",
    "        MEGNetFeats_structs.append(MEGNetModel_structs)\n",
    "        print(f\"Features calculated for model {model_name}.\")\n",
    "    ## now every structure calculated with each model is combined in a final dataframe\n",
    "    MEGNetFeats_structs=pd.concat(MEGNetFeats_structs,axis=1)\n",
    "    return MEGNetFeats_structs\n",
    "\n",
    "import pickle\n",
    "structures=data.df_structure['structure']\n",
    "slices=list(range(0,len(structures),1000))+[None]\n",
    "for idx in range(len(slices)-1):\n",
    "    print(f\"Processing slice {idx+1} out of {len(slices)}\")\n",
    "    MEGNetFeats_struct=get_MEGNetFeaturesDF(structures[slices[idx]:slices[idx+1]])\n",
    "    pickle.dump(MEGNetFeats_struct,open(f\"MEGNetFeats_struct_slice{idx}.pkl\", \"wb\"))\n",
    "    del MEGNetFeats_struct ## free memory\n",
    "\n",
    "# slices=list(range(0,len(structures),100))\n",
    "# slices_range=slices+[None]\n",
    "## lets save every 100 structures\n",
    "# for i in range(len(slices)):\n",
    "#     slice_1=slices_range[i]\n",
    "#     slice_2=slices_range[i]\n",
    "# MEGNetFeats_DF=[]\n",
    "\n",
    "#     try:\n",
    "#         MEGNetFeats_struct = get_MEGNetFeatures(s)\n",
    "#         MEGNetFeats_DF.append(MEGNetFeats_struct)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"Invalid structure found.\")\n",
    "#         continue\n",
    "#     ## assemble all samples together\n",
    "# MEGNetFeats_struct=pd.concat(MEGNetFeats_DF,axis=0)\n",
    "# MEGNetFeats_struct\n",
    "\n",
    "# # train the model using valid graphs and targets\n",
    "# model.train_from_graphs(graphs_valid, targets_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71657a32",
   "metadata": {},
   "source": [
    "### Compress MODNet featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff99e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtomicOrbitals|HOMO_character</th>\n",
       "      <th>AtomicOrbitals|HOMO_element</th>\n",
       "      <th>AtomicOrbitals|HOMO_energy</th>\n",
       "      <th>AtomicOrbitals|LUMO_character</th>\n",
       "      <th>AtomicOrbitals|LUMO_element</th>\n",
       "      <th>AtomicOrbitals|LUMO_energy</th>\n",
       "      <th>AtomicOrbitals|gap_AO</th>\n",
       "      <th>AtomicPackingEfficiency|mean simul. packing efficiency</th>\n",
       "      <th>AtomicPackingEfficiency|mean abs simul. packing efficiency</th>\n",
       "      <th>AtomicPackingEfficiency|dist from 1 clusters |APE| &lt; 0.010</th>\n",
       "      <th>...</th>\n",
       "      <th>VoronoiFingerprint|mean Voro_area_maximum</th>\n",
       "      <th>VoronoiFingerprint|std_dev Voro_area_maximum</th>\n",
       "      <th>VoronoiFingerprint|mean Voro_dist_mean</th>\n",
       "      <th>VoronoiFingerprint|std_dev Voro_dist_mean</th>\n",
       "      <th>VoronoiFingerprint|mean Voro_dist_std_dev</th>\n",
       "      <th>VoronoiFingerprint|std_dev Voro_dist_std_dev</th>\n",
       "      <th>VoronoiFingerprint|mean Voro_dist_minimum</th>\n",
       "      <th>VoronoiFingerprint|std_dev Voro_dist_minimum</th>\n",
       "      <th>VoronoiFingerprint|mean Voro_dist_maximum</th>\n",
       "      <th>VoronoiFingerprint|std_dev Voro_dist_maximum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id0</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.239422</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.239422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019853</td>\n",
       "      <td>0.025843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.680561</td>\n",
       "      <td>0.458036</td>\n",
       "      <td>2.562273</td>\n",
       "      <td>0.295993</td>\n",
       "      <td>0.171956</td>\n",
       "      <td>0.140402</td>\n",
       "      <td>2.141068</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>2.632474</td>\n",
       "      <td>0.327604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.226594</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.226594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>0.035127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.485496</td>\n",
       "      <td>2.757377</td>\n",
       "      <td>3.211060</td>\n",
       "      <td>0.180417</td>\n",
       "      <td>0.749061</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>2.062580</td>\n",
       "      <td>0.143762</td>\n",
       "      <td>4.231601</td>\n",
       "      <td>0.296694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233673</td>\n",
       "      <td>...</td>\n",
       "      <td>5.925071</td>\n",
       "      <td>0.642829</td>\n",
       "      <td>3.060591</td>\n",
       "      <td>0.221207</td>\n",
       "      <td>0.593054</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>2.052294</td>\n",
       "      <td>0.213951</td>\n",
       "      <td>3.943729</td>\n",
       "      <td>0.427326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.258639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.888409</td>\n",
       "      <td>1.379544</td>\n",
       "      <td>3.247859</td>\n",
       "      <td>0.400903</td>\n",
       "      <td>0.571037</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>2.264348</td>\n",
       "      <td>0.383090</td>\n",
       "      <td>3.994756</td>\n",
       "      <td>0.573237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233673</td>\n",
       "      <td>...</td>\n",
       "      <td>4.372985</td>\n",
       "      <td>0.567335</td>\n",
       "      <td>3.024505</td>\n",
       "      <td>0.186204</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.147899</td>\n",
       "      <td>2.308321</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>3.914740</td>\n",
       "      <td>0.494112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18923</th>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.160771</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.160771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035494</td>\n",
       "      <td>0.046774</td>\n",
       "      <td>0.049913</td>\n",
       "      <td>...</td>\n",
       "      <td>5.643630</td>\n",
       "      <td>1.284916</td>\n",
       "      <td>3.179486</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.522827</td>\n",
       "      <td>0.112538</td>\n",
       "      <td>2.322964</td>\n",
       "      <td>0.430795</td>\n",
       "      <td>4.131898</td>\n",
       "      <td>0.493932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18924</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061107</td>\n",
       "      <td>0.061107</td>\n",
       "      <td>0.036464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.006736</td>\n",
       "      <td>0.611867</td>\n",
       "      <td>3.255567</td>\n",
       "      <td>0.199980</td>\n",
       "      <td>0.558447</td>\n",
       "      <td>0.160526</td>\n",
       "      <td>2.491821</td>\n",
       "      <td>0.377426</td>\n",
       "      <td>4.213125</td>\n",
       "      <td>0.532796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18925</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.086951</td>\n",
       "      <td>0.390512</td>\n",
       "      <td>2.549946</td>\n",
       "      <td>0.156731</td>\n",
       "      <td>0.437165</td>\n",
       "      <td>0.125449</td>\n",
       "      <td>1.950288</td>\n",
       "      <td>0.299607</td>\n",
       "      <td>3.300138</td>\n",
       "      <td>0.417069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18926</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>...</td>\n",
       "      <td>4.422642</td>\n",
       "      <td>0.550386</td>\n",
       "      <td>2.808725</td>\n",
       "      <td>0.324463</td>\n",
       "      <td>0.188496</td>\n",
       "      <td>0.153906</td>\n",
       "      <td>2.347006</td>\n",
       "      <td>0.359115</td>\n",
       "      <td>2.885678</td>\n",
       "      <td>0.359115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18927</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.338381</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.338381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>...</td>\n",
       "      <td>5.764205</td>\n",
       "      <td>1.008234</td>\n",
       "      <td>2.813444</td>\n",
       "      <td>0.382193</td>\n",
       "      <td>0.511404</td>\n",
       "      <td>0.256855</td>\n",
       "      <td>2.058726</td>\n",
       "      <td>0.093642</td>\n",
       "      <td>3.522105</td>\n",
       "      <td>0.772769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18928 rows Ã— 2563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AtomicOrbitals|HOMO_character  AtomicOrbitals|HOMO_element  \\\n",
       "id                                                                    \n",
       "id0                                  3                           45   \n",
       "id1                                  2                           52   \n",
       "id2                                  3                           75   \n",
       "id3                                  3                           75   \n",
       "id4                                  2                           83   \n",
       "...                                ...                          ...   \n",
       "id18923                              3                           46   \n",
       "id18924                              2                            7   \n",
       "id18925                              2                            7   \n",
       "id18926                              2                            7   \n",
       "id18927                              2                            8   \n",
       "\n",
       "         AtomicOrbitals|HOMO_energy  AtomicOrbitals|LUMO_character  \\\n",
       "id                                                                   \n",
       "id0                       -0.239422                              3   \n",
       "id1                       -0.226594                              2   \n",
       "id2                       -0.258639                              3   \n",
       "id3                       -0.258639                              3   \n",
       "id4                       -0.180198                              2   \n",
       "...                             ...                            ...   \n",
       "id18923                   -0.160771                              3   \n",
       "id18924                   -0.266297                              2   \n",
       "id18925                   -0.266297                              2   \n",
       "id18926                   -0.266297                              2   \n",
       "id18927                   -0.338381                              2   \n",
       "\n",
       "         AtomicOrbitals|LUMO_element  AtomicOrbitals|LUMO_energy  \\\n",
       "id                                                                 \n",
       "id0                               45                   -0.239422   \n",
       "id1                               52                   -0.226594   \n",
       "id2                               75                   -0.258639   \n",
       "id3                               75                   -0.258639   \n",
       "id4                               83                   -0.180198   \n",
       "...                              ...                         ...   \n",
       "id18923                           46                   -0.160771   \n",
       "id18924                            7                   -0.266297   \n",
       "id18925                            7                   -0.266297   \n",
       "id18926                            7                   -0.266297   \n",
       "id18927                            8                   -0.338381   \n",
       "\n",
       "         AtomicOrbitals|gap_AO  \\\n",
       "id                               \n",
       "id0                        0.0   \n",
       "id1                        0.0   \n",
       "id2                        0.0   \n",
       "id3                        0.0   \n",
       "id4                        0.0   \n",
       "...                        ...   \n",
       "id18923                    0.0   \n",
       "id18924                    0.0   \n",
       "id18925                    0.0   \n",
       "id18926                    0.0   \n",
       "id18927                    0.0   \n",
       "\n",
       "         AtomicPackingEfficiency|mean simul. packing efficiency  \\\n",
       "id                                                                \n",
       "id0                                               0.019853        \n",
       "id1                                               0.033979        \n",
       "id2                                               0.000000        \n",
       "id3                                               0.010760        \n",
       "id4                                               0.000000        \n",
       "...                                                    ...        \n",
       "id18923                                           0.035494        \n",
       "id18924                                           0.061107        \n",
       "id18925                                           0.000000        \n",
       "id18926                                           0.004068        \n",
       "id18927                                           0.035503        \n",
       "\n",
       "         AtomicPackingEfficiency|mean abs simul. packing efficiency  \\\n",
       "id                                                                    \n",
       "id0                                               0.025843            \n",
       "id1                                               0.035127            \n",
       "id2                                               0.000000            \n",
       "id3                                               0.023126            \n",
       "id4                                               0.000000            \n",
       "...                                                    ...            \n",
       "id18923                                           0.046774            \n",
       "id18924                                           0.061107            \n",
       "id18925                                           0.000000            \n",
       "id18926                                           0.014496            \n",
       "id18927                                           0.039594            \n",
       "\n",
       "         AtomicPackingEfficiency|dist from 1 clusters |APE| < 0.010  ...  \\\n",
       "id                                                                   ...   \n",
       "id0                                               0.000000           ...   \n",
       "id1                                               0.000000           ...   \n",
       "id2                                               0.233673           ...   \n",
       "id3                                               0.000000           ...   \n",
       "id4                                               0.233673           ...   \n",
       "...                                                    ...           ...   \n",
       "id18923                                           0.049913           ...   \n",
       "id18924                                           0.036464           ...   \n",
       "id18925                                           0.227378           ...   \n",
       "id18926                                           0.034015           ...   \n",
       "id18927                                           0.020412           ...   \n",
       "\n",
       "         VoronoiFingerprint|mean Voro_area_maximum  \\\n",
       "id                                                   \n",
       "id0                                       3.680561   \n",
       "id1                                       8.485496   \n",
       "id2                                       5.925071   \n",
       "id3                                       4.888409   \n",
       "id4                                       4.372985   \n",
       "...                                            ...   \n",
       "id18923                                   5.643630   \n",
       "id18924                                   5.006736   \n",
       "id18925                                   3.086951   \n",
       "id18926                                   4.422642   \n",
       "id18927                                   5.764205   \n",
       "\n",
       "         VoronoiFingerprint|std_dev Voro_area_maximum  \\\n",
       "id                                                      \n",
       "id0                                          0.458036   \n",
       "id1                                          2.757377   \n",
       "id2                                          0.642829   \n",
       "id3                                          1.379544   \n",
       "id4                                          0.567335   \n",
       "...                                               ...   \n",
       "id18923                                      1.284916   \n",
       "id18924                                      0.611867   \n",
       "id18925                                      0.390512   \n",
       "id18926                                      0.550386   \n",
       "id18927                                      1.008234   \n",
       "\n",
       "         VoronoiFingerprint|mean Voro_dist_mean  \\\n",
       "id                                                \n",
       "id0                                    2.562273   \n",
       "id1                                    3.211060   \n",
       "id2                                    3.060591   \n",
       "id3                                    3.247859   \n",
       "id4                                    3.024505   \n",
       "...                                         ...   \n",
       "id18923                                3.179486   \n",
       "id18924                                3.255567   \n",
       "id18925                                2.549946   \n",
       "id18926                                2.808725   \n",
       "id18927                                2.813444   \n",
       "\n",
       "         VoronoiFingerprint|std_dev Voro_dist_mean  \\\n",
       "id                                                   \n",
       "id0                                       0.295993   \n",
       "id1                                       0.180417   \n",
       "id2                                       0.221207   \n",
       "id3                                       0.400903   \n",
       "id4                                       0.186204   \n",
       "...                                            ...   \n",
       "id18923                                   0.205128   \n",
       "id18924                                   0.199980   \n",
       "id18925                                   0.156731   \n",
       "id18926                                   0.324463   \n",
       "id18927                                   0.382193   \n",
       "\n",
       "         VoronoiFingerprint|mean Voro_dist_std_dev  \\\n",
       "id                                                   \n",
       "id0                                       0.171956   \n",
       "id1                                       0.749061   \n",
       "id2                                       0.593054   \n",
       "id3                                       0.571037   \n",
       "id4                                       0.517800   \n",
       "...                                            ...   \n",
       "id18923                                   0.522827   \n",
       "id18924                                   0.558447   \n",
       "id18925                                   0.437165   \n",
       "id18926                                   0.188496   \n",
       "id18927                                   0.511404   \n",
       "\n",
       "         VoronoiFingerprint|std_dev Voro_dist_std_dev  \\\n",
       "id                                                      \n",
       "id0                                          0.140402   \n",
       "id1                                          0.086845   \n",
       "id2                                          0.088100   \n",
       "id3                                          0.117785   \n",
       "id4                                          0.147899   \n",
       "...                                               ...   \n",
       "id18923                                      0.112538   \n",
       "id18924                                      0.160526   \n",
       "id18925                                      0.125449   \n",
       "id18926                                      0.153906   \n",
       "id18927                                      0.256855   \n",
       "\n",
       "         VoronoiFingerprint|mean Voro_dist_minimum  \\\n",
       "id                                                   \n",
       "id0                                       2.141068   \n",
       "id1                                       2.062580   \n",
       "id2                                       2.052294   \n",
       "id3                                       2.264348   \n",
       "id4                                       2.308321   \n",
       "...                                            ...   \n",
       "id18923                                   2.322964   \n",
       "id18924                                   2.491821   \n",
       "id18925                                   1.950288   \n",
       "id18926                                   2.347006   \n",
       "id18927                                   2.058726   \n",
       "\n",
       "         VoronoiFingerprint|std_dev Voro_dist_minimum  \\\n",
       "id                                                      \n",
       "id0                                          0.327604   \n",
       "id1                                          0.143762   \n",
       "id2                                          0.213951   \n",
       "id3                                          0.383090   \n",
       "id4                                          0.356250   \n",
       "...                                               ...   \n",
       "id18923                                      0.430795   \n",
       "id18924                                      0.377426   \n",
       "id18925                                      0.299607   \n",
       "id18926                                      0.359115   \n",
       "id18927                                      0.093642   \n",
       "\n",
       "         VoronoiFingerprint|mean Voro_dist_maximum  \\\n",
       "id                                                   \n",
       "id0                                       2.632474   \n",
       "id1                                       4.231601   \n",
       "id2                                       3.943729   \n",
       "id3                                       3.994756   \n",
       "id4                                       3.914740   \n",
       "...                                            ...   \n",
       "id18923                                   4.131898   \n",
       "id18924                                   4.213125   \n",
       "id18925                                   3.300138   \n",
       "id18926                                   2.885678   \n",
       "id18927                                   3.522105   \n",
       "\n",
       "         VoronoiFingerprint|std_dev Voro_dist_maximum  \n",
       "id                                                     \n",
       "id0                                          0.327604  \n",
       "id1                                          0.296694  \n",
       "id2                                          0.427326  \n",
       "id3                                          0.573237  \n",
       "id4                                          0.494112  \n",
       "...                                               ...  \n",
       "id18923                                      0.493932  \n",
       "id18924                                      0.532796  \n",
       "id18925                                      0.417069  \n",
       "id18926                                      0.359115  \n",
       "id18927                                      0.772769  \n",
       "\n",
       "[18928 rows x 2563 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df_featurized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8002cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed layer size: 18\n",
      "Epoch 1/400\n",
      "12/12 - 1s - loss: 0.7682 - val_loss: 0.2400 - 731ms/epoch - 61ms/step\n",
      "Epoch 2/400\n",
      "12/12 - 0s - loss: 0.4948 - val_loss: 0.2093 - 46ms/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "12/12 - 0s - loss: 0.3368 - val_loss: 0.1852 - 46ms/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "12/12 - 0s - loss: 0.2406 - val_loss: 0.1673 - 47ms/epoch - 4ms/step\n",
      "Epoch 5/400\n",
      "12/12 - 0s - loss: 0.1781 - val_loss: 0.1497 - 57ms/epoch - 5ms/step\n",
      "Epoch 6/400\n",
      "12/12 - 0s - loss: 0.1303 - val_loss: 0.1387 - 68ms/epoch - 6ms/step\n",
      "Epoch 7/400\n",
      "12/12 - 0s - loss: 0.1135 - val_loss: 0.1292 - 66ms/epoch - 5ms/step\n",
      "Epoch 8/400\n",
      "12/12 - 0s - loss: 0.1067 - val_loss: 0.1187 - 56ms/epoch - 5ms/step\n",
      "Epoch 9/400\n",
      "12/12 - 0s - loss: 0.0940 - val_loss: 0.1111 - 54ms/epoch - 4ms/step\n",
      "Epoch 10/400\n",
      "12/12 - 0s - loss: 0.0795 - val_loss: 0.1034 - 45ms/epoch - 4ms/step\n",
      "Epoch 11/400\n",
      "12/12 - 0s - loss: 0.0842 - val_loss: 0.0961 - 52ms/epoch - 4ms/step\n",
      "Epoch 12/400\n",
      "12/12 - 0s - loss: 0.0668 - val_loss: 0.0900 - 48ms/epoch - 4ms/step\n",
      "Epoch 13/400\n",
      "12/12 - 0s - loss: 0.0686 - val_loss: 0.0844 - 55ms/epoch - 5ms/step\n",
      "Epoch 14/400\n",
      "12/12 - 0s - loss: 0.0617 - val_loss: 0.0771 - 52ms/epoch - 4ms/step\n",
      "Epoch 15/400\n",
      "12/12 - 0s - loss: 0.0688 - val_loss: 0.0734 - 52ms/epoch - 4ms/step\n",
      "Epoch 16/400\n",
      "12/12 - 0s - loss: 0.0520 - val_loss: 0.0690 - 57ms/epoch - 5ms/step\n",
      "Epoch 17/400\n",
      "12/12 - 0s - loss: 0.0555 - val_loss: 0.0615 - 59ms/epoch - 5ms/step\n",
      "Epoch 18/400\n",
      "12/12 - 0s - loss: 0.0519 - val_loss: 0.0573 - 56ms/epoch - 5ms/step\n",
      "Epoch 19/400\n",
      "12/12 - 0s - loss: 0.0521 - val_loss: 0.0514 - 49ms/epoch - 4ms/step\n",
      "Epoch 20/400\n",
      "12/12 - 0s - loss: 0.0474 - val_loss: 0.0479 - 45ms/epoch - 4ms/step\n",
      "Epoch 21/400\n",
      "12/12 - 0s - loss: 0.0463 - val_loss: 0.0440 - 44ms/epoch - 4ms/step\n",
      "Epoch 22/400\n",
      "12/12 - 0s - loss: 0.0471 - val_loss: 0.0412 - 47ms/epoch - 4ms/step\n",
      "Epoch 23/400\n",
      "12/12 - 0s - loss: 0.0439 - val_loss: 0.0389 - 48ms/epoch - 4ms/step\n",
      "Epoch 24/400\n",
      "12/12 - 0s - loss: 0.0428 - val_loss: 0.0354 - 44ms/epoch - 4ms/step\n",
      "Epoch 25/400\n",
      "12/12 - 0s - loss: 0.0392 - val_loss: 0.0318 - 44ms/epoch - 4ms/step\n",
      "Epoch 26/400\n",
      "12/12 - 0s - loss: 0.0416 - val_loss: 0.0301 - 42ms/epoch - 4ms/step\n",
      "Epoch 27/400\n",
      "12/12 - 0s - loss: 0.0378 - val_loss: 0.0282 - 44ms/epoch - 4ms/step\n",
      "Epoch 28/400\n",
      "12/12 - 0s - loss: 0.0399 - val_loss: 0.0270 - 49ms/epoch - 4ms/step\n",
      "Epoch 29/400\n",
      "12/12 - 0s - loss: 0.0402 - val_loss: 0.0264 - 45ms/epoch - 4ms/step\n",
      "Epoch 30/400\n",
      "12/12 - 0s - loss: 0.0360 - val_loss: 0.0263 - 47ms/epoch - 4ms/step\n",
      "Epoch 31/400\n",
      "12/12 - 0s - loss: 0.0344 - val_loss: 0.0251 - 46ms/epoch - 4ms/step\n",
      "Epoch 32/400\n",
      "12/12 - 0s - loss: 0.0375 - val_loss: 0.0233 - 48ms/epoch - 4ms/step\n",
      "Epoch 33/400\n",
      "12/12 - 0s - loss: 0.0336 - val_loss: 0.0215 - 48ms/epoch - 4ms/step\n",
      "Epoch 34/400\n",
      "12/12 - 0s - loss: 0.0321 - val_loss: 0.0209 - 57ms/epoch - 5ms/step\n",
      "Epoch 35/400\n",
      "12/12 - 0s - loss: 0.0319 - val_loss: 0.0210 - 67ms/epoch - 6ms/step\n",
      "Epoch 36/400\n",
      "12/12 - 0s - loss: 0.0325 - val_loss: 0.0206 - 64ms/epoch - 5ms/step\n",
      "Epoch 37/400\n",
      "12/12 - 0s - loss: 0.0330 - val_loss: 0.0199 - 48ms/epoch - 4ms/step\n",
      "Epoch 38/400\n",
      "12/12 - 0s - loss: 0.0315 - val_loss: 0.0197 - 47ms/epoch - 4ms/step\n",
      "Epoch 39/400\n",
      "12/12 - 0s - loss: 0.0304 - val_loss: 0.0204 - 47ms/epoch - 4ms/step\n",
      "Epoch 40/400\n",
      "12/12 - 0s - loss: 0.0350 - val_loss: 0.0204 - 49ms/epoch - 4ms/step\n",
      "Epoch 41/400\n",
      "12/12 - 0s - loss: 0.0320 - val_loss: 0.0200 - 47ms/epoch - 4ms/step\n",
      "Epoch 42/400\n",
      "12/12 - 0s - loss: 0.0288 - val_loss: 0.0190 - 48ms/epoch - 4ms/step\n",
      "Epoch 43/400\n",
      "12/12 - 0s - loss: 0.0285 - val_loss: 0.0182 - 54ms/epoch - 4ms/step\n",
      "Epoch 44/400\n",
      "12/12 - 0s - loss: 0.0290 - val_loss: 0.0180 - 60ms/epoch - 5ms/step\n",
      "Epoch 45/400\n",
      "12/12 - 0s - loss: 0.0338 - val_loss: 0.0179 - 65ms/epoch - 5ms/step\n",
      "Epoch 46/400\n",
      "12/12 - 0s - loss: 0.0267 - val_loss: 0.0179 - 67ms/epoch - 6ms/step\n",
      "Epoch 47/400\n",
      "12/12 - 0s - loss: 0.0281 - val_loss: 0.0172 - 57ms/epoch - 5ms/step\n",
      "Epoch 48/400\n",
      "12/12 - 0s - loss: 0.0269 - val_loss: 0.0169 - 51ms/epoch - 4ms/step\n",
      "Epoch 49/400\n",
      "12/12 - 0s - loss: 0.0255 - val_loss: 0.0167 - 48ms/epoch - 4ms/step\n",
      "Epoch 50/400\n",
      "12/12 - 0s - loss: 0.0275 - val_loss: 0.0163 - 53ms/epoch - 4ms/step\n",
      "Epoch 51/400\n",
      "12/12 - 0s - loss: 0.0260 - val_loss: 0.0161 - 51ms/epoch - 4ms/step\n",
      "Epoch 52/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0159 - 51ms/epoch - 4ms/step\n",
      "Epoch 53/400\n",
      "12/12 - 0s - loss: 0.0286 - val_loss: 0.0158 - 48ms/epoch - 4ms/step\n",
      "Epoch 54/400\n",
      "12/12 - 0s - loss: 0.0259 - val_loss: 0.0156 - 47ms/epoch - 4ms/step\n",
      "Epoch 55/400\n",
      "12/12 - 0s - loss: 0.0274 - val_loss: 0.0156 - 46ms/epoch - 4ms/step\n",
      "Epoch 56/400\n",
      "12/12 - 0s - loss: 0.0241 - val_loss: 0.0153 - 48ms/epoch - 4ms/step\n",
      "Epoch 57/400\n",
      "12/12 - 0s - loss: 0.0278 - val_loss: 0.0153 - 47ms/epoch - 4ms/step\n",
      "Epoch 58/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0157 - 46ms/epoch - 4ms/step\n",
      "Epoch 59/400\n",
      "12/12 - 0s - loss: 0.0249 - val_loss: 0.0154 - 44ms/epoch - 4ms/step\n",
      "Epoch 60/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0147 - 43ms/epoch - 4ms/step\n",
      "Epoch 61/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 62/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0155 - 43ms/epoch - 4ms/step\n",
      "Epoch 63/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0143 - 43ms/epoch - 4ms/step\n",
      "Epoch 64/400\n",
      "12/12 - 0s - loss: 0.0221 - val_loss: 0.0136 - 43ms/epoch - 4ms/step\n",
      "Epoch 65/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0134 - 40ms/epoch - 3ms/step\n",
      "Epoch 66/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0133 - 45ms/epoch - 4ms/step\n",
      "Epoch 67/400\n",
      "12/12 - 0s - loss: 0.0230 - val_loss: 0.0134 - 41ms/epoch - 3ms/step\n",
      "Epoch 68/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0130 - 41ms/epoch - 3ms/step\n",
      "Epoch 69/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0127 - 43ms/epoch - 4ms/step\n",
      "Epoch 70/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0126 - 42ms/epoch - 4ms/step\n",
      "Epoch 71/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0128 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0125 - 44ms/epoch - 4ms/step\n",
      "Epoch 73/400\n",
      "12/12 - 0s - loss: 0.0254 - val_loss: 0.0126 - 42ms/epoch - 4ms/step\n",
      "Epoch 74/400\n",
      "12/12 - 0s - loss: 0.0172 - val_loss: 0.0124 - 43ms/epoch - 4ms/step\n",
      "Epoch 75/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0120 - 43ms/epoch - 4ms/step\n",
      "Epoch 76/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0121 - 43ms/epoch - 4ms/step\n",
      "Epoch 77/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0117 - 42ms/epoch - 3ms/step\n",
      "Epoch 78/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0114 - 47ms/epoch - 4ms/step\n",
      "Epoch 79/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0113 - 44ms/epoch - 4ms/step\n",
      "Epoch 80/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0117 - 43ms/epoch - 4ms/step\n",
      "Epoch 81/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0117 - 41ms/epoch - 3ms/step\n",
      "Epoch 82/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0115 - 43ms/epoch - 4ms/step\n",
      "Epoch 83/400\n",
      "12/12 - 0s - loss: 0.0181 - val_loss: 0.0113 - 44ms/epoch - 4ms/step\n",
      "Epoch 84/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0112 - 46ms/epoch - 4ms/step\n",
      "Epoch 85/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0115 - 43ms/epoch - 4ms/step\n",
      "Epoch 86/400\n",
      "12/12 - 0s - loss: 0.0234 - val_loss: 0.0114 - 42ms/epoch - 3ms/step\n",
      "Epoch 87/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0114 - 42ms/epoch - 3ms/step\n",
      "Epoch 88/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0111 - 43ms/epoch - 4ms/step\n",
      "Epoch 89/400\n",
      "12/12 - 0s - loss: 0.0188 - val_loss: 0.0108 - 43ms/epoch - 4ms/step\n",
      "Epoch 90/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0107 - 42ms/epoch - 4ms/step\n",
      "Epoch 91/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0108 - 43ms/epoch - 4ms/step\n",
      "Epoch 92/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0108 - 43ms/epoch - 4ms/step\n",
      "Epoch 93/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0112 - 45ms/epoch - 4ms/step\n",
      "Epoch 94/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0102 - 51ms/epoch - 4ms/step\n",
      "Epoch 95/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0101 - 42ms/epoch - 4ms/step\n",
      "Epoch 96/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0103 - 42ms/epoch - 4ms/step\n",
      "Epoch 97/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0097 - 42ms/epoch - 4ms/step\n",
      "Epoch 98/400\n",
      "12/12 - 0s - loss: 0.0164 - val_loss: 0.0093 - 45ms/epoch - 4ms/step\n",
      "Epoch 99/400\n",
      "12/12 - 0s - loss: 0.0174 - val_loss: 0.0090 - 43ms/epoch - 4ms/step\n",
      "Epoch 100/400\n",
      "12/12 - 0s - loss: 0.0167 - val_loss: 0.0095 - 43ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0094 - 44ms/epoch - 4ms/step\n",
      "Epoch 102/400\n",
      "12/12 - 0s - loss: 0.0176 - val_loss: 0.0096 - 41ms/epoch - 3ms/step\n",
      "Epoch 103/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0095 - 42ms/epoch - 3ms/step\n",
      "Epoch 104/400\n",
      "12/12 - 0s - loss: 0.0176 - val_loss: 0.0095 - 39ms/epoch - 3ms/step\n",
      "Epoch 105/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0097 - 39ms/epoch - 3ms/step\n",
      "Epoch 106/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0097 - 40ms/epoch - 3ms/step\n",
      "Epoch 107/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0096 - 41ms/epoch - 3ms/step\n",
      "Epoch 108/400\n",
      "12/12 - 0s - loss: 0.0176 - val_loss: 0.0092 - 40ms/epoch - 3ms/step\n",
      "Epoch 109/400\n",
      "12/12 - 0s - loss: 0.0178 - val_loss: 0.0091 - 40ms/epoch - 3ms/step\n",
      "Epoch 110/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0089 - 41ms/epoch - 3ms/step\n",
      "Epoch 111/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0087 - 51ms/epoch - 4ms/step\n",
      "Epoch 112/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0083 - 50ms/epoch - 4ms/step\n",
      "Epoch 113/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0084 - 52ms/epoch - 4ms/step\n",
      "Epoch 114/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0083 - 43ms/epoch - 4ms/step\n",
      "Epoch 115/400\n",
      "12/12 - 0s - loss: 0.0166 - val_loss: 0.0081 - 42ms/epoch - 4ms/step\n",
      "Epoch 116/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 117/400\n",
      "12/12 - 0s - loss: 0.0170 - val_loss: 0.0083 - 44ms/epoch - 4ms/step\n",
      "Epoch 118/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0085 - 42ms/epoch - 4ms/step\n",
      "Epoch 119/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0085 - 43ms/epoch - 4ms/step\n",
      "Epoch 120/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0079 - 44ms/epoch - 4ms/step\n",
      "Epoch 121/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 122/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0078 - 42ms/epoch - 4ms/step\n",
      "Epoch 123/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0077 - 43ms/epoch - 4ms/step\n",
      "Epoch 124/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0077 - 44ms/epoch - 4ms/step\n",
      "Epoch 125/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 126/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0080 - 42ms/epoch - 4ms/step\n",
      "Epoch 127/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0079 - 44ms/epoch - 4ms/step\n",
      "Epoch 128/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 129/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0079 - 43ms/epoch - 4ms/step\n",
      "Epoch 130/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0080 - 42ms/epoch - 4ms/step\n",
      "Epoch 131/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0077 - 43ms/epoch - 4ms/step\n",
      "Epoch 132/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0074 - 43ms/epoch - 4ms/step\n",
      "Epoch 133/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0073 - 43ms/epoch - 4ms/step\n",
      "Epoch 134/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0075 - 43ms/epoch - 4ms/step\n",
      "Epoch 135/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0076 - 43ms/epoch - 4ms/step\n",
      "Epoch 136/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0082 - 43ms/epoch - 4ms/step\n",
      "Epoch 137/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0076 - 43ms/epoch - 4ms/step\n",
      "Epoch 138/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 139/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0085 - 44ms/epoch - 4ms/step\n",
      "Epoch 140/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0082 - 42ms/epoch - 3ms/step\n",
      "Epoch 141/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0082 - 42ms/epoch - 4ms/step\n",
      "Epoch 142/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0083 - 43ms/epoch - 4ms/step\n",
      "Epoch 143/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0081 - 42ms/epoch - 4ms/step\n",
      "Epoch 144/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0083 - 43ms/epoch - 4ms/step\n",
      "Epoch 145/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0079 - 45ms/epoch - 4ms/step\n",
      "Epoch 146/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0073 - 44ms/epoch - 4ms/step\n",
      "Epoch 147/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0071 - 41ms/epoch - 3ms/step\n",
      "Epoch 148/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0075 - 40ms/epoch - 3ms/step\n",
      "Epoch 149/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0073 - 40ms/epoch - 3ms/step\n",
      "Epoch 150/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0072 - 40ms/epoch - 3ms/step\n",
      "Epoch 151/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0075 - 39ms/epoch - 3ms/step\n",
      "Epoch 152/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0073 - 40ms/epoch - 3ms/step\n",
      "Epoch 153/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0067 - 40ms/epoch - 3ms/step\n",
      "Epoch 154/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0065 - 40ms/epoch - 3ms/step\n",
      "Epoch 155/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0068 - 42ms/epoch - 3ms/step\n",
      "Epoch 156/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0070 - 43ms/epoch - 4ms/step\n",
      "Epoch 157/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0085 - 41ms/epoch - 3ms/step\n",
      "Epoch 158/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0070 - 41ms/epoch - 3ms/step\n",
      "Epoch 159/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0070 - 42ms/epoch - 4ms/step\n",
      "Epoch 160/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0067 - 43ms/epoch - 4ms/step\n",
      "Epoch 161/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 162/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0064 - 44ms/epoch - 4ms/step\n",
      "Epoch 163/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0064 - 42ms/epoch - 3ms/step\n",
      "Epoch 164/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 165/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0066 - 43ms/epoch - 4ms/step\n",
      "Epoch 166/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0067 - 44ms/epoch - 4ms/step\n",
      "Epoch 167/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0065 - 43ms/epoch - 4ms/step\n",
      "Epoch 168/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0067 - 42ms/epoch - 4ms/step\n",
      "Epoch 169/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0065 - 41ms/epoch - 3ms/step\n",
      "Epoch 170/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0063 - 43ms/epoch - 4ms/step\n",
      "Epoch 171/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 172/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0067 - 42ms/epoch - 4ms/step\n",
      "Epoch 173/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0066 - 43ms/epoch - 4ms/step\n",
      "Epoch 174/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0060 - 44ms/epoch - 4ms/step\n",
      "Epoch 175/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 176/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 177/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 178/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 179/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 180/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 181/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0063 - 43ms/epoch - 4ms/step\n",
      "Epoch 182/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 183/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0059 - 44ms/epoch - 4ms/step\n",
      "Epoch 184/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 185/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0062 - 45ms/epoch - 4ms/step\n",
      "Epoch 186/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 187/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0057 - 42ms/epoch - 3ms/step\n",
      "Epoch 188/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 189/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0056 - 42ms/epoch - 3ms/step\n",
      "Epoch 190/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0059 - 44ms/epoch - 4ms/step\n",
      "Epoch 191/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 192/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0058 - 43ms/epoch - 4ms/step\n",
      "Epoch 193/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 194/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0059 - 41ms/epoch - 3ms/step\n",
      "Epoch 195/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0056 - 41ms/epoch - 3ms/step\n",
      "Epoch 196/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0056 - 40ms/epoch - 3ms/step\n",
      "Epoch 197/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 198/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0055 - 38ms/epoch - 3ms/step\n",
      "Epoch 199/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0059 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0059 - 41ms/epoch - 3ms/step\n",
      "Epoch 201/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 202/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 203/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0055 - 41ms/epoch - 3ms/step\n",
      "Epoch 204/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 205/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 206/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 207/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0064 - 42ms/epoch - 4ms/step\n",
      "Epoch 208/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 209/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0056 - 44ms/epoch - 4ms/step\n",
      "Epoch 210/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 211/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0058 - 44ms/epoch - 4ms/step\n",
      "Epoch 212/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 213/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0056 - 42ms/epoch - 4ms/step\n",
      "Epoch 214/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 215/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 216/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0053 - 44ms/epoch - 4ms/step\n",
      "Epoch 217/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0051 - 41ms/epoch - 3ms/step\n",
      "Epoch 218/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0052 - 42ms/epoch - 3ms/step\n",
      "Epoch 219/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0052 - 41ms/epoch - 3ms/step\n",
      "Epoch 220/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 221/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 222/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0056 - 42ms/epoch - 4ms/step\n",
      "Epoch 223/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0053 - 44ms/epoch - 4ms/step\n",
      "Epoch 224/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 225/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 226/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 227/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 228/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0054 - 44ms/epoch - 4ms/step\n",
      "Epoch 229/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0055 - 44ms/epoch - 4ms/step\n",
      "Epoch 230/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 231/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 232/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 233/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 234/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 235/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 236/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0050 - 42ms/epoch - 4ms/step\n",
      "Epoch 237/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 238/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 239/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0048 - 40ms/epoch - 3ms/step\n",
      "Epoch 240/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0050 - 41ms/epoch - 3ms/step\n",
      "Epoch 241/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 242/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0046 - 47ms/epoch - 4ms/step\n",
      "Epoch 243/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0046 - 39ms/epoch - 3ms/step\n",
      "Epoch 244/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0045 - 39ms/epoch - 3ms/step\n",
      "Epoch 245/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0046 - 40ms/epoch - 3ms/step\n",
      "Epoch 246/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 247/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 248/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0047 - 44ms/epoch - 4ms/step\n",
      "Epoch 249/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 250/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0047 - 44ms/epoch - 4ms/step\n",
      "Epoch 251/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 252/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0047 - 44ms/epoch - 4ms/step\n",
      "Epoch 253/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 254/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 255/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0053 - 41ms/epoch - 3ms/step\n",
      "Epoch 256/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 257/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0046 - 45ms/epoch - 4ms/step\n",
      "Epoch 258/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0051 - 42ms/epoch - 3ms/step\n",
      "Epoch 259/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 260/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 261/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0048 - 44ms/epoch - 4ms/step\n",
      "Epoch 262/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 263/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0046 - 41ms/epoch - 3ms/step\n",
      "Epoch 264/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0045 - 41ms/epoch - 3ms/step\n",
      "Epoch 265/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0043 - 43ms/epoch - 4ms/step\n",
      "Epoch 266/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0044 - 43ms/epoch - 4ms/step\n",
      "Epoch 267/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0047 - 45ms/epoch - 4ms/step\n",
      "Epoch 268/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0045 - 42ms/epoch - 3ms/step\n",
      "Epoch 269/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0045 - 42ms/epoch - 4ms/step\n",
      "Epoch 270/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 271/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 272/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0046 - 41ms/epoch - 3ms/step\n",
      "Epoch 273/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0046 - 42ms/epoch - 4ms/step\n",
      "Epoch 274/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 275/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 276/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0043 - 42ms/epoch - 4ms/step\n",
      "Epoch 277/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 278/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0047 - 42ms/epoch - 3ms/step\n",
      "Epoch 279/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0048 - 42ms/epoch - 4ms/step\n",
      "Epoch 280/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0046 - 44ms/epoch - 4ms/step\n",
      "Epoch 281/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0048 - 42ms/epoch - 4ms/step\n",
      "Epoch 282/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 283/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0045 - 44ms/epoch - 4ms/step\n",
      "Epoch 284/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0045 - 42ms/epoch - 3ms/step\n",
      "Epoch 285/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0046 - 40ms/epoch - 3ms/step\n",
      "Epoch 286/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0044 - 40ms/epoch - 3ms/step\n",
      "Epoch 287/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0045 - 39ms/epoch - 3ms/step\n",
      "Epoch 288/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0046 - 39ms/epoch - 3ms/step\n",
      "Epoch 289/400\n",
      "12/12 - 0s - loss: 0.0078 - val_loss: 0.0043 - 40ms/epoch - 3ms/step\n",
      "Epoch 290/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0044 - 40ms/epoch - 3ms/step\n",
      "Epoch 291/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0045 - 40ms/epoch - 3ms/step\n",
      "Epoch 292/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 293/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 294/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0042 - 44ms/epoch - 4ms/step\n",
      "Epoch 295/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0043 - 44ms/epoch - 4ms/step\n",
      "Epoch 296/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 297/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0043 - 43ms/epoch - 4ms/step\n",
      "Epoch 298/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0043 - 42ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 300/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0041 - 44ms/epoch - 4ms/step\n",
      "Epoch 301/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 302/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0043 - 44ms/epoch - 4ms/step\n",
      "Epoch 303/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0043 - 44ms/epoch - 4ms/step\n",
      "Epoch 304/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0041 - 42ms/epoch - 3ms/step\n",
      "Epoch 305/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0039 - 42ms/epoch - 4ms/step\n",
      "Epoch 306/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 307/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0038 - 42ms/epoch - 3ms/step\n",
      "Epoch 308/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 309/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 310/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0040 - 43ms/epoch - 4ms/step\n",
      "Epoch 311/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 312/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0040 - 44ms/epoch - 4ms/step\n",
      "Epoch 313/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0043 - 44ms/epoch - 4ms/step\n",
      "Epoch 314/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0043 - 43ms/epoch - 4ms/step\n",
      "Epoch 315/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0040 - 42ms/epoch - 3ms/step\n",
      "Epoch 316/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0040 - 42ms/epoch - 3ms/step\n",
      "Epoch 317/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 318/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0042 - 47ms/epoch - 4ms/step\n",
      "Epoch 319/400\n",
      "12/12 - 0s - loss: 0.0082 - val_loss: 0.0041 - 46ms/epoch - 4ms/step\n",
      "Epoch 320/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0038 - 42ms/epoch - 4ms/step\n",
      "Epoch 321/400\n",
      "12/12 - 0s - loss: 0.0076 - val_loss: 0.0041 - 42ms/epoch - 3ms/step\n",
      "Epoch 322/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 323/400\n",
      "12/12 - 0s - loss: 0.0078 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 324/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0040 - 43ms/epoch - 4ms/step\n",
      "Epoch 325/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0037 - 42ms/epoch - 3ms/step\n",
      "Epoch 326/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0037 - 43ms/epoch - 4ms/step\n",
      "Epoch 327/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0039 - 42ms/epoch - 4ms/step\n",
      "Epoch 328/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0043 - 42ms/epoch - 4ms/step\n",
      "Epoch 329/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0042 - 41ms/epoch - 3ms/step\n",
      "Epoch 330/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0038 - 42ms/epoch - 3ms/step\n",
      "Epoch 331/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0039 - 40ms/epoch - 3ms/step\n",
      "Epoch 332/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0042 - 41ms/epoch - 3ms/step\n",
      "Epoch 333/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0042 - 39ms/epoch - 3ms/step\n",
      "Epoch 334/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0038 - 39ms/epoch - 3ms/step\n",
      "Epoch 335/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0042 - 40ms/epoch - 3ms/step\n",
      "Epoch 336/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0041 - 41ms/epoch - 3ms/step\n",
      "Epoch 337/400\n",
      "12/12 - 0s - loss: 0.0082 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 338/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 339/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0037 - 44ms/epoch - 4ms/step\n",
      "Epoch 340/400\n",
      "12/12 - 0s - loss: 0.0077 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 341/400\n",
      "12/12 - 0s - loss: 0.0079 - val_loss: 0.0039 - 42ms/epoch - 3ms/step\n",
      "Epoch 342/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0040 - 42ms/epoch - 3ms/step\n",
      "Epoch 343/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0041 - 45ms/epoch - 4ms/step\n",
      "Epoch 344/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 345/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0037 - 43ms/epoch - 4ms/step\n",
      "Epoch 346/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 347/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 348/400\n",
      "12/12 - 0s - loss: 0.0074 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 349/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0036 - 43ms/epoch - 4ms/step\n",
      "Epoch 350/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0038 - 45ms/epoch - 4ms/step\n",
      "Epoch 351/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 352/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 353/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 354/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 355/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 356/400\n",
      "12/12 - 0s - loss: 0.0082 - val_loss: 0.0041 - 44ms/epoch - 4ms/step\n",
      "Epoch 357/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 358/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0040 - 44ms/epoch - 4ms/step\n",
      "Epoch 359/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 360/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0044 - 43ms/epoch - 4ms/step\n",
      "Epoch 361/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0039 - 42ms/epoch - 4ms/step\n",
      "Epoch 362/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 363/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 364/400\n",
      "12/12 - 0s - loss: 0.0079 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 365/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0034 - 45ms/epoch - 4ms/step\n",
      "Epoch 366/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0035 - 43ms/epoch - 4ms/step\n",
      "Epoch 367/400\n",
      "12/12 - 0s - loss: 0.0072 - val_loss: 0.0040 - 43ms/epoch - 4ms/step\n",
      "Epoch 368/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0042 - 45ms/epoch - 4ms/step\n",
      "Epoch 369/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0037 - 42ms/epoch - 4ms/step\n",
      "Epoch 370/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0040 - 43ms/epoch - 4ms/step\n",
      "Epoch 371/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0038 - 42ms/epoch - 4ms/step\n",
      "Epoch 372/400\n",
      "12/12 - 0s - loss: 0.0076 - val_loss: 0.0040 - 42ms/epoch - 3ms/step\n",
      "Epoch 373/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0036 - 42ms/epoch - 4ms/step\n",
      "Epoch 374/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0036 - 42ms/epoch - 3ms/step\n",
      "Epoch 375/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0036 - 40ms/epoch - 3ms/step\n",
      "Epoch 376/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0040 - 40ms/epoch - 3ms/step\n",
      "Epoch 377/400\n",
      "12/12 - 0s - loss: 0.0071 - val_loss: 0.0035 - 40ms/epoch - 3ms/step\n",
      "Epoch 378/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0038 - 39ms/epoch - 3ms/step\n",
      "Epoch 379/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0035 - 46ms/epoch - 4ms/step\n",
      "Epoch 380/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0035 - 39ms/epoch - 3ms/step\n",
      "Epoch 381/400\n",
      "12/12 - 0s - loss: 0.0076 - val_loss: 0.0046 - 39ms/epoch - 3ms/step\n",
      "Epoch 382/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0035 - 43ms/epoch - 4ms/step\n",
      "Epoch 383/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0037 - 44ms/epoch - 4ms/step\n",
      "Epoch 384/400\n",
      "12/12 - 0s - loss: 0.0067 - val_loss: 0.0036 - 44ms/epoch - 4ms/step\n",
      "Epoch 385/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0035 - 43ms/epoch - 4ms/step\n",
      "Epoch 386/400\n",
      "12/12 - 0s - loss: 0.0082 - val_loss: 0.0038 - 42ms/epoch - 4ms/step\n",
      "Epoch 387/400\n",
      "12/12 - 0s - loss: 0.0078 - val_loss: 0.0034 - 43ms/epoch - 4ms/step\n",
      "Epoch 388/400\n",
      "12/12 - 0s - loss: 0.0074 - val_loss: 0.0033 - 44ms/epoch - 4ms/step\n",
      "Epoch 389/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0034 - 42ms/epoch - 4ms/step\n",
      "Epoch 390/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0036 - 42ms/epoch - 4ms/step\n",
      "Epoch 391/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 392/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0034 - 43ms/epoch - 4ms/step\n",
      "Epoch 393/400\n",
      "12/12 - 0s - loss: 0.0078 - val_loss: 0.0033 - 44ms/epoch - 4ms/step\n",
      "Epoch 394/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0034 - 42ms/epoch - 4ms/step\n",
      "Epoch 395/400\n",
      "12/12 - 0s - loss: 0.0072 - val_loss: 0.0033 - 42ms/epoch - 4ms/step\n",
      "Epoch 396/400\n",
      "12/12 - 0s - loss: 0.0077 - val_loss: 0.0032 - 44ms/epoch - 4ms/step\n",
      "Epoch 397/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0033 - 45ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/400\n",
      "12/12 - 0s - loss: 0.0067 - val_loss: 0.0034 - 43ms/epoch - 4ms/step\n",
      "Epoch 399/400\n",
      "12/12 - 0s - loss: 0.0073 - val_loss: 0.0032 - 42ms/epoch - 4ms/step\n",
      "Epoch 400/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0033 - 43ms/epoch - 4ms/step\n",
      "COMPRESSED VECTOR SIZE: 18\n",
      "Loss in the autoencoder: 0.0033383495174348354\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Compressed layer size: 14\n",
      "Epoch 1/400\n",
      "12/12 - 1s - loss: 0.9193 - val_loss: 0.2567 - 769ms/epoch - 64ms/step\n",
      "Epoch 2/400\n",
      "12/12 - 0s - loss: 0.6260 - val_loss: 0.2140 - 43ms/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "12/12 - 0s - loss: 0.4435 - val_loss: 0.1805 - 48ms/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "12/12 - 0s - loss: 0.3274 - val_loss: 0.1557 - 46ms/epoch - 4ms/step\n",
      "Epoch 5/400\n",
      "12/12 - 0s - loss: 0.2318 - val_loss: 0.1341 - 45ms/epoch - 4ms/step\n",
      "Epoch 6/400\n",
      "12/12 - 0s - loss: 0.1788 - val_loss: 0.1185 - 43ms/epoch - 4ms/step\n",
      "Epoch 7/400\n",
      "12/12 - 0s - loss: 0.1391 - val_loss: 0.1121 - 45ms/epoch - 4ms/step\n",
      "Epoch 8/400\n",
      "12/12 - 0s - loss: 0.1202 - val_loss: 0.1043 - 46ms/epoch - 4ms/step\n",
      "Epoch 9/400\n",
      "12/12 - 0s - loss: 0.1014 - val_loss: 0.0974 - 43ms/epoch - 4ms/step\n",
      "Epoch 10/400\n",
      "12/12 - 0s - loss: 0.0959 - val_loss: 0.0900 - 43ms/epoch - 4ms/step\n",
      "Epoch 11/400\n",
      "12/12 - 0s - loss: 0.0803 - val_loss: 0.0829 - 42ms/epoch - 3ms/step\n",
      "Epoch 12/400\n",
      "12/12 - 0s - loss: 0.0701 - val_loss: 0.0781 - 40ms/epoch - 3ms/step\n",
      "Epoch 13/400\n",
      "12/12 - 0s - loss: 0.0715 - val_loss: 0.0708 - 42ms/epoch - 4ms/step\n",
      "Epoch 14/400\n",
      "12/12 - 0s - loss: 0.0705 - val_loss: 0.0665 - 42ms/epoch - 4ms/step\n",
      "Epoch 15/400\n",
      "12/12 - 0s - loss: 0.0593 - val_loss: 0.0624 - 42ms/epoch - 4ms/step\n",
      "Epoch 16/400\n",
      "12/12 - 0s - loss: 0.0574 - val_loss: 0.0589 - 44ms/epoch - 4ms/step\n",
      "Epoch 17/400\n",
      "12/12 - 0s - loss: 0.0574 - val_loss: 0.0545 - 42ms/epoch - 3ms/step\n",
      "Epoch 18/400\n",
      "12/12 - 0s - loss: 0.0489 - val_loss: 0.0497 - 43ms/epoch - 4ms/step\n",
      "Epoch 19/400\n",
      "12/12 - 0s - loss: 0.0495 - val_loss: 0.0457 - 41ms/epoch - 3ms/step\n",
      "Epoch 20/400\n",
      "12/12 - 0s - loss: 0.0511 - val_loss: 0.0429 - 43ms/epoch - 4ms/step\n",
      "Epoch 21/400\n",
      "12/12 - 0s - loss: 0.0424 - val_loss: 0.0398 - 41ms/epoch - 3ms/step\n",
      "Epoch 22/400\n",
      "12/12 - 0s - loss: 0.0480 - val_loss: 0.0374 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/400\n",
      "12/12 - 0s - loss: 0.0404 - val_loss: 0.0343 - 41ms/epoch - 3ms/step\n",
      "Epoch 24/400\n",
      "12/12 - 0s - loss: 0.0401 - val_loss: 0.0317 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/400\n",
      "12/12 - 0s - loss: 0.0359 - val_loss: 0.0301 - 42ms/epoch - 4ms/step\n",
      "Epoch 26/400\n",
      "12/12 - 0s - loss: 0.0409 - val_loss: 0.0282 - 42ms/epoch - 4ms/step\n",
      "Epoch 27/400\n",
      "12/12 - 0s - loss: 0.0372 - val_loss: 0.0273 - 43ms/epoch - 4ms/step\n",
      "Epoch 28/400\n",
      "12/12 - 0s - loss: 0.0366 - val_loss: 0.0264 - 42ms/epoch - 3ms/step\n",
      "Epoch 29/400\n",
      "12/12 - 0s - loss: 0.0360 - val_loss: 0.0258 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/400\n",
      "12/12 - 0s - loss: 0.0350 - val_loss: 0.0244 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/400\n",
      "12/12 - 0s - loss: 0.0333 - val_loss: 0.0226 - 42ms/epoch - 4ms/step\n",
      "Epoch 32/400\n",
      "12/12 - 0s - loss: 0.0389 - val_loss: 0.0222 - 42ms/epoch - 4ms/step\n",
      "Epoch 33/400\n",
      "12/12 - 0s - loss: 0.0354 - val_loss: 0.0217 - 44ms/epoch - 4ms/step\n",
      "Epoch 34/400\n",
      "12/12 - 0s - loss: 0.0310 - val_loss: 0.0213 - 42ms/epoch - 4ms/step\n",
      "Epoch 35/400\n",
      "12/12 - 0s - loss: 0.0293 - val_loss: 0.0212 - 42ms/epoch - 4ms/step\n",
      "Epoch 36/400\n",
      "12/12 - 0s - loss: 0.0295 - val_loss: 0.0209 - 41ms/epoch - 3ms/step\n",
      "Epoch 37/400\n",
      "12/12 - 0s - loss: 0.0312 - val_loss: 0.0197 - 41ms/epoch - 3ms/step\n",
      "Epoch 38/400\n",
      "12/12 - 0s - loss: 0.0298 - val_loss: 0.0192 - 41ms/epoch - 3ms/step\n",
      "Epoch 39/400\n",
      "12/12 - 0s - loss: 0.0278 - val_loss: 0.0191 - 41ms/epoch - 3ms/step\n",
      "Epoch 40/400\n",
      "12/12 - 0s - loss: 0.0293 - val_loss: 0.0191 - 42ms/epoch - 4ms/step\n",
      "Epoch 41/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0182 - 40ms/epoch - 3ms/step\n",
      "Epoch 42/400\n",
      "12/12 - 0s - loss: 0.0277 - val_loss: 0.0177 - 39ms/epoch - 3ms/step\n",
      "Epoch 43/400\n",
      "12/12 - 0s - loss: 0.0315 - val_loss: 0.0171 - 40ms/epoch - 3ms/step\n",
      "Epoch 44/400\n",
      "12/12 - 0s - loss: 0.0253 - val_loss: 0.0165 - 40ms/epoch - 3ms/step\n",
      "Epoch 45/400\n",
      "12/12 - 0s - loss: 0.0276 - val_loss: 0.0173 - 38ms/epoch - 3ms/step\n",
      "Epoch 46/400\n",
      "12/12 - 0s - loss: 0.0256 - val_loss: 0.0170 - 40ms/epoch - 3ms/step\n",
      "Epoch 47/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0163 - 40ms/epoch - 3ms/step\n",
      "Epoch 48/400\n",
      "12/12 - 0s - loss: 0.0246 - val_loss: 0.0159 - 43ms/epoch - 4ms/step\n",
      "Epoch 49/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0162 - 42ms/epoch - 3ms/step\n",
      "Epoch 50/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0158 - 42ms/epoch - 3ms/step\n",
      "Epoch 51/400\n",
      "12/12 - 0s - loss: 0.0245 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 52/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 53/400\n",
      "12/12 - 0s - loss: 0.0191 - val_loss: 0.0149 - 42ms/epoch - 4ms/step\n",
      "Epoch 54/400\n",
      "12/12 - 0s - loss: 0.0239 - val_loss: 0.0140 - 42ms/epoch - 3ms/step\n",
      "Epoch 55/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0141 - 44ms/epoch - 4ms/step\n",
      "Epoch 56/400\n",
      "12/12 - 0s - loss: 0.0230 - val_loss: 0.0140 - 43ms/epoch - 4ms/step\n",
      "Epoch 57/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0137 - 44ms/epoch - 4ms/step\n",
      "Epoch 58/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0130 - 42ms/epoch - 3ms/step\n",
      "Epoch 59/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0127 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0130 - 42ms/epoch - 4ms/step\n",
      "Epoch 61/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0128 - 43ms/epoch - 4ms/step\n",
      "Epoch 62/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0125 - 42ms/epoch - 4ms/step\n",
      "Epoch 63/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0122 - 42ms/epoch - 4ms/step\n",
      "Epoch 64/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0122 - 42ms/epoch - 4ms/step\n",
      "Epoch 65/400\n",
      "12/12 - 0s - loss: 0.0214 - val_loss: 0.0124 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0119 - 42ms/epoch - 3ms/step\n",
      "Epoch 67/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0117 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0122 - 42ms/epoch - 4ms/step\n",
      "Epoch 69/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0118 - 42ms/epoch - 3ms/step\n",
      "Epoch 70/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0117 - 42ms/epoch - 4ms/step\n",
      "Epoch 71/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0113 - 43ms/epoch - 4ms/step\n",
      "Epoch 72/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0115 - 45ms/epoch - 4ms/step\n",
      "Epoch 73/400\n",
      "12/12 - 0s - loss: 0.0193 - val_loss: 0.0116 - 42ms/epoch - 4ms/step\n",
      "Epoch 74/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0119 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0117 - 41ms/epoch - 3ms/step\n",
      "Epoch 76/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0114 - 43ms/epoch - 4ms/step\n",
      "Epoch 77/400\n",
      "12/12 - 0s - loss: 0.0188 - val_loss: 0.0118 - 43ms/epoch - 4ms/step\n",
      "Epoch 78/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0117 - 43ms/epoch - 4ms/step\n",
      "Epoch 79/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0115 - 43ms/epoch - 4ms/step\n",
      "Epoch 80/400\n",
      "12/12 - 0s - loss: 0.0179 - val_loss: 0.0112 - 44ms/epoch - 4ms/step\n",
      "Epoch 81/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0106 - 42ms/epoch - 4ms/step\n",
      "Epoch 82/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0110 - 43ms/epoch - 4ms/step\n",
      "Epoch 83/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0105 - 42ms/epoch - 3ms/step\n",
      "Epoch 84/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0105 - 42ms/epoch - 3ms/step\n",
      "Epoch 85/400\n",
      "12/12 - 0s - loss: 0.0188 - val_loss: 0.0100 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/400\n",
      "12/12 - 0s - loss: 0.0179 - val_loss: 0.0104 - 41ms/epoch - 3ms/step\n",
      "Epoch 87/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0107 - 39ms/epoch - 3ms/step\n",
      "Epoch 88/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0105 - 41ms/epoch - 3ms/step\n",
      "Epoch 89/400\n",
      "12/12 - 0s - loss: 0.0196 - val_loss: 0.0105 - 40ms/epoch - 3ms/step\n",
      "Epoch 90/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0105 - 39ms/epoch - 3ms/step\n",
      "Epoch 91/400\n",
      "12/12 - 0s - loss: 0.0167 - val_loss: 0.0097 - 38ms/epoch - 3ms/step\n",
      "Epoch 92/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0101 - 40ms/epoch - 3ms/step\n",
      "Epoch 93/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0098 - 39ms/epoch - 3ms/step\n",
      "Epoch 94/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0103 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0106 - 43ms/epoch - 4ms/step\n",
      "Epoch 96/400\n",
      "12/12 - 0s - loss: 0.0176 - val_loss: 0.0103 - 47ms/epoch - 4ms/step\n",
      "Epoch 97/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0100 - 43ms/epoch - 4ms/step\n",
      "Epoch 98/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0102 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0101 - 43ms/epoch - 4ms/step\n",
      "Epoch 100/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0095 - 44ms/epoch - 4ms/step\n",
      "Epoch 101/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0092 - 42ms/epoch - 3ms/step\n",
      "Epoch 102/400\n",
      "12/12 - 0s - loss: 0.0185 - val_loss: 0.0094 - 42ms/epoch - 3ms/step\n",
      "Epoch 103/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0097 - 42ms/epoch - 4ms/step\n",
      "Epoch 104/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0094 - 41ms/epoch - 3ms/step\n",
      "Epoch 105/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0093 - 41ms/epoch - 3ms/step\n",
      "Epoch 106/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0093 - 42ms/epoch - 4ms/step\n",
      "Epoch 107/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0098 - 44ms/epoch - 4ms/step\n",
      "Epoch 108/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0093 - 42ms/epoch - 4ms/step\n",
      "Epoch 109/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0093 - 42ms/epoch - 3ms/step\n",
      "Epoch 110/400\n",
      "12/12 - 0s - loss: 0.0154 - val_loss: 0.0092 - 42ms/epoch - 3ms/step\n",
      "Epoch 111/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0088 - 42ms/epoch - 4ms/step\n",
      "Epoch 112/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0090 - 42ms/epoch - 4ms/step\n",
      "Epoch 113/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0087 - 42ms/epoch - 4ms/step\n",
      "Epoch 114/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0087 - 47ms/epoch - 4ms/step\n",
      "Epoch 115/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0085 - 42ms/epoch - 3ms/step\n",
      "Epoch 116/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0081 - 41ms/epoch - 3ms/step\n",
      "Epoch 117/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 118/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 119/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0081 - 42ms/epoch - 3ms/step\n",
      "Epoch 120/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0080 - 42ms/epoch - 3ms/step\n",
      "Epoch 121/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0076 - 42ms/epoch - 4ms/step\n",
      "Epoch 122/400\n",
      "12/12 - 0s - loss: 0.0176 - val_loss: 0.0077 - 42ms/epoch - 4ms/step\n",
      "Epoch 123/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0080 - 43ms/epoch - 4ms/step\n",
      "Epoch 124/400\n",
      "12/12 - 0s - loss: 0.0166 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 125/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0080 - 43ms/epoch - 4ms/step\n",
      "Epoch 126/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0082 - 42ms/epoch - 4ms/step\n",
      "Epoch 127/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0082 - 42ms/epoch - 3ms/step\n",
      "Epoch 128/400\n",
      "12/12 - 0s - loss: 0.0153 - val_loss: 0.0079 - 41ms/epoch - 3ms/step\n",
      "Epoch 129/400\n",
      "12/12 - 0s - loss: 0.0166 - val_loss: 0.0084 - 42ms/epoch - 4ms/step\n",
      "Epoch 130/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0083 - 43ms/epoch - 4ms/step\n",
      "Epoch 131/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 132/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0078 - 39ms/epoch - 3ms/step\n",
      "Epoch 133/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0079 - 39ms/epoch - 3ms/step\n",
      "Epoch 134/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0079 - 40ms/epoch - 3ms/step\n",
      "Epoch 135/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0082 - 40ms/epoch - 3ms/step\n",
      "Epoch 136/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0077 - 40ms/epoch - 3ms/step\n",
      "Epoch 137/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0073 - 39ms/epoch - 3ms/step\n",
      "Epoch 138/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0074 - 40ms/epoch - 3ms/step\n",
      "Epoch 139/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0075 - 43ms/epoch - 4ms/step\n",
      "Epoch 140/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0074 - 46ms/epoch - 4ms/step\n",
      "Epoch 141/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0075 - 44ms/epoch - 4ms/step\n",
      "Epoch 142/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0075 - 44ms/epoch - 4ms/step\n",
      "Epoch 143/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0073 - 45ms/epoch - 4ms/step\n",
      "Epoch 144/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0072 - 48ms/epoch - 4ms/step\n",
      "Epoch 145/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0070 - 44ms/epoch - 4ms/step\n",
      "Epoch 146/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0070 - 44ms/epoch - 4ms/step\n",
      "Epoch 147/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0069 - 43ms/epoch - 4ms/step\n",
      "Epoch 148/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0074 - 44ms/epoch - 4ms/step\n",
      "Epoch 149/400\n",
      "12/12 - 0s - loss: 0.0180 - val_loss: 0.0076 - 43ms/epoch - 4ms/step\n",
      "Epoch 150/400\n",
      "12/12 - 0s - loss: 0.0164 - val_loss: 0.0076 - 42ms/epoch - 4ms/step\n",
      "Epoch 151/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0078 - 42ms/epoch - 4ms/step\n",
      "Epoch 152/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0076 - 42ms/epoch - 4ms/step\n",
      "Epoch 153/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0074 - 43ms/epoch - 4ms/step\n",
      "Epoch 154/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0076 - 44ms/epoch - 4ms/step\n",
      "Epoch 155/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0081 - 42ms/epoch - 4ms/step\n",
      "Epoch 156/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0074 - 41ms/epoch - 3ms/step\n",
      "Epoch 157/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0075 - 41ms/epoch - 3ms/step\n",
      "Epoch 158/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0072 - 43ms/epoch - 4ms/step\n",
      "Epoch 159/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0071 - 43ms/epoch - 4ms/step\n",
      "Epoch 160/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0072 - 42ms/epoch - 4ms/step\n",
      "Epoch 161/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0075 - 42ms/epoch - 3ms/step\n",
      "Epoch 162/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0076 - 43ms/epoch - 4ms/step\n",
      "Epoch 163/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0074 - 44ms/epoch - 4ms/step\n",
      "Epoch 164/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0073 - 44ms/epoch - 4ms/step\n",
      "Epoch 165/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0070 - 46ms/epoch - 4ms/step\n",
      "Epoch 166/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0072 - 47ms/epoch - 4ms/step\n",
      "Epoch 167/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0068 - 47ms/epoch - 4ms/step\n",
      "Epoch 168/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0065 - 51ms/epoch - 4ms/step\n",
      "Epoch 169/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0070 - 47ms/epoch - 4ms/step\n",
      "Epoch 170/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0066 - 46ms/epoch - 4ms/step\n",
      "Epoch 171/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0066 - 47ms/epoch - 4ms/step\n",
      "Epoch 172/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0067 - 46ms/epoch - 4ms/step\n",
      "Epoch 173/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0063 - 46ms/epoch - 4ms/step\n",
      "Epoch 174/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0063 - 45ms/epoch - 4ms/step\n",
      "Epoch 175/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0063 - 48ms/epoch - 4ms/step\n",
      "Epoch 176/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0063 - 43ms/epoch - 4ms/step\n",
      "Epoch 177/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0061 - 44ms/epoch - 4ms/step\n",
      "Epoch 178/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0068 - 42ms/epoch - 3ms/step\n",
      "Epoch 179/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0071 - 42ms/epoch - 4ms/step\n",
      "Epoch 180/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0068 - 42ms/epoch - 4ms/step\n",
      "Epoch 181/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0068 - 45ms/epoch - 4ms/step\n",
      "Epoch 182/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 183/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0064 - 44ms/epoch - 4ms/step\n",
      "Epoch 184/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0061 - 47ms/epoch - 4ms/step\n",
      "Epoch 185/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0063 - 48ms/epoch - 4ms/step\n",
      "Epoch 186/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0065 - 45ms/epoch - 4ms/step\n",
      "Epoch 187/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0061 - 46ms/epoch - 4ms/step\n",
      "Epoch 188/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0059 - 48ms/epoch - 4ms/step\n",
      "Epoch 189/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0061 - 49ms/epoch - 4ms/step\n",
      "Epoch 190/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0059 - 48ms/epoch - 4ms/step\n",
      "Epoch 191/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0058 - 49ms/epoch - 4ms/step\n",
      "Epoch 192/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0057 - 48ms/epoch - 4ms/step\n",
      "Epoch 193/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0057 - 48ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0060 - 48ms/epoch - 4ms/step\n",
      "Epoch 195/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0060 - 48ms/epoch - 4ms/step\n",
      "Epoch 196/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0061 - 48ms/epoch - 4ms/step\n",
      "Epoch 197/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0063 - 51ms/epoch - 4ms/step\n",
      "Epoch 198/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0060 - 49ms/epoch - 4ms/step\n",
      "Epoch 199/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0058 - 49ms/epoch - 4ms/step\n",
      "Epoch 200/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0056 - 47ms/epoch - 4ms/step\n",
      "Epoch 201/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0057 - 56ms/epoch - 5ms/step\n",
      "Epoch 202/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0057 - 48ms/epoch - 4ms/step\n",
      "Epoch 203/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0056 - 50ms/epoch - 4ms/step\n",
      "Epoch 204/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0057 - 52ms/epoch - 4ms/step\n",
      "Epoch 205/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0057 - 49ms/epoch - 4ms/step\n",
      "Epoch 206/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0057 - 48ms/epoch - 4ms/step\n",
      "Epoch 207/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0056 - 50ms/epoch - 4ms/step\n",
      "Epoch 208/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0055 - 45ms/epoch - 4ms/step\n",
      "Epoch 209/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0055 - 48ms/epoch - 4ms/step\n",
      "Epoch 210/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0056 - 48ms/epoch - 4ms/step\n",
      "Epoch 211/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0055 - 54ms/epoch - 4ms/step\n",
      "Epoch 212/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0052 - 50ms/epoch - 4ms/step\n",
      "Epoch 213/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0052 - 48ms/epoch - 4ms/step\n",
      "Epoch 214/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0055 - 41ms/epoch - 3ms/step\n",
      "Epoch 215/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 216/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0058 - 43ms/epoch - 4ms/step\n",
      "Epoch 217/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0053 - 42ms/epoch - 3ms/step\n",
      "Epoch 218/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 219/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0055 - 39ms/epoch - 3ms/step\n",
      "Epoch 220/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0052 - 39ms/epoch - 3ms/step\n",
      "Epoch 221/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0050 - 40ms/epoch - 3ms/step\n",
      "Epoch 222/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0054 - 40ms/epoch - 3ms/step\n",
      "Epoch 223/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0054 - 40ms/epoch - 3ms/step\n",
      "Epoch 224/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0055 - 39ms/epoch - 3ms/step\n",
      "Epoch 225/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 226/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 227/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 228/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0060 - 42ms/epoch - 3ms/step\n",
      "Epoch 229/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0054 - 42ms/epoch - 3ms/step\n",
      "Epoch 230/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 231/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 232/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0053 - 44ms/epoch - 4ms/step\n",
      "Epoch 233/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 234/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 235/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 236/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 237/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0055 - 45ms/epoch - 4ms/step\n",
      "Epoch 238/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 239/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 240/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 241/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0051 - 42ms/epoch - 4ms/step\n",
      "Epoch 242/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 243/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 244/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 245/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0054 - 42ms/epoch - 3ms/step\n",
      "Epoch 246/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0051 - 45ms/epoch - 4ms/step\n",
      "Epoch 247/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0058 - 43ms/epoch - 4ms/step\n",
      "Epoch 248/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 249/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0054 - 45ms/epoch - 4ms/step\n",
      "Epoch 250/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 251/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 252/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 253/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0056 - 42ms/epoch - 4ms/step\n",
      "Epoch 254/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0056 - 44ms/epoch - 4ms/step\n",
      "Epoch 255/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 256/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 257/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0052 - 44ms/epoch - 4ms/step\n",
      "Epoch 258/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 259/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0051 - 42ms/epoch - 3ms/step\n",
      "Epoch 260/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0055 - 50ms/epoch - 4ms/step\n",
      "Epoch 261/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0048 - 42ms/epoch - 3ms/step\n",
      "Epoch 262/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 263/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 264/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 265/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0052 - 40ms/epoch - 3ms/step\n",
      "Epoch 266/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 267/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0048 - 40ms/epoch - 3ms/step\n",
      "Epoch 268/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0047 - 42ms/epoch - 3ms/step\n",
      "Epoch 269/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0055 - 40ms/epoch - 3ms/step\n",
      "Epoch 270/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 271/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 272/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0053 - 45ms/epoch - 4ms/step\n",
      "Epoch 273/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0048 - 42ms/epoch - 3ms/step\n",
      "Epoch 274/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 275/400\n",
      "12/12 - 0s - loss: 0.0080 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 276/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 277/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 278/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0046 - 42ms/epoch - 4ms/step\n",
      "Epoch 279/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0046 - 44ms/epoch - 4ms/step\n",
      "Epoch 280/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 281/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0049 - 44ms/epoch - 4ms/step\n",
      "Epoch 282/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0050 - 44ms/epoch - 4ms/step\n",
      "Epoch 283/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 284/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0048 - 42ms/epoch - 4ms/step\n",
      "Epoch 285/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 286/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0045 - 41ms/epoch - 3ms/step\n",
      "Epoch 287/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 288/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 289/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 290/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0048 - 42ms/epoch - 4ms/step\n",
      "Epoch 291/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 292/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0043 - 46ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 294/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0054 - 42ms/epoch - 3ms/step\n",
      "Epoch 295/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 296/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 297/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 298/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0047 - 55ms/epoch - 5ms/step\n",
      "Epoch 299/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0048 - 49ms/epoch - 4ms/step\n",
      "Epoch 300/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0046 - 42ms/epoch - 4ms/step\n",
      "Epoch 301/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0047 - 44ms/epoch - 4ms/step\n",
      "Epoch 302/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0054 - 44ms/epoch - 4ms/step\n",
      "Epoch 303/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0050 - 44ms/epoch - 4ms/step\n",
      "Epoch 304/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0047 - 42ms/epoch - 4ms/step\n",
      "Epoch 305/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 306/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 307/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 308/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0048 - 40ms/epoch - 3ms/step\n",
      "Epoch 309/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0047 - 39ms/epoch - 3ms/step\n",
      "Epoch 310/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0050 - 40ms/epoch - 3ms/step\n",
      "Epoch 311/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0048 - 39ms/epoch - 3ms/step\n",
      "Epoch 312/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0044 - 40ms/epoch - 3ms/step\n",
      "Epoch 313/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0044 - 40ms/epoch - 3ms/step\n",
      "Epoch 314/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0044 - 41ms/epoch - 3ms/step\n",
      "Epoch 315/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0046 - 41ms/epoch - 3ms/step\n",
      "Epoch 316/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0048 - 44ms/epoch - 4ms/step\n",
      "Epoch 317/400\n",
      "12/12 - 0s - loss: 0.0079 - val_loss: 0.0044 - 43ms/epoch - 4ms/step\n",
      "Epoch 318/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0043 - 43ms/epoch - 4ms/step\n",
      "Epoch 319/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0044 - 42ms/epoch - 4ms/step\n",
      "Epoch 320/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0047 - 44ms/epoch - 4ms/step\n",
      "Epoch 321/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 322/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0048 - 42ms/epoch - 4ms/step\n",
      "Epoch 323/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 324/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0045 - 42ms/epoch - 4ms/step\n",
      "Epoch 325/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0045 - 45ms/epoch - 4ms/step\n",
      "Epoch 326/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 327/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0045 - 44ms/epoch - 4ms/step\n",
      "Epoch 328/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0044 - 44ms/epoch - 4ms/step\n",
      "Epoch 329/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0047 - 42ms/epoch - 4ms/step\n",
      "Epoch 330/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0044 - 43ms/epoch - 4ms/step\n",
      "Epoch 331/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0046 - 43ms/epoch - 4ms/step\n",
      "Epoch 332/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0050 - 44ms/epoch - 4ms/step\n",
      "Epoch 333/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 334/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0043 - 42ms/epoch - 3ms/step\n",
      "Epoch 335/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0046 - 44ms/epoch - 4ms/step\n",
      "Epoch 336/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 337/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0045 - 44ms/epoch - 4ms/step\n",
      "Epoch 338/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0045 - 41ms/epoch - 3ms/step\n",
      "Epoch 339/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 340/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 341/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 342/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 343/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0051 - 47ms/epoch - 4ms/step\n",
      "Epoch 344/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 345/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 346/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 347/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0054 - 44ms/epoch - 4ms/step\n",
      "Epoch 348/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0046 - 44ms/epoch - 4ms/step\n",
      "Epoch 349/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 350/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0047 - 42ms/epoch - 3ms/step\n",
      "Epoch 351/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0045 - 42ms/epoch - 4ms/step\n",
      "Epoch 352/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 353/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0045 - 42ms/epoch - 3ms/step\n",
      "Epoch 354/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0041 - 40ms/epoch - 3ms/step\n",
      "Epoch 355/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0042 - 41ms/epoch - 3ms/step\n",
      "Epoch 356/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0045 - 40ms/epoch - 3ms/step\n",
      "Epoch 357/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0043 - 40ms/epoch - 3ms/step\n",
      "Epoch 358/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0044 - 39ms/epoch - 3ms/step\n",
      "Epoch 359/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0047 - 40ms/epoch - 3ms/step\n",
      "Epoch 360/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0042 - 42ms/epoch - 3ms/step\n",
      "Epoch 361/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0038 - 44ms/epoch - 4ms/step\n",
      "Epoch 362/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 363/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 364/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0041 - 44ms/epoch - 4ms/step\n",
      "Epoch 365/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 366/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0039 - 42ms/epoch - 4ms/step\n",
      "Epoch 367/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0040 - 43ms/epoch - 4ms/step\n",
      "Epoch 368/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 369/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0040 - 44ms/epoch - 4ms/step\n",
      "Epoch 370/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0039 - 45ms/epoch - 4ms/step\n",
      "Epoch 371/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0041 - 42ms/epoch - 4ms/step\n",
      "Epoch 372/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 373/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0043 - 44ms/epoch - 4ms/step\n",
      "Epoch 374/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 375/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 376/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 377/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0036 - 43ms/epoch - 4ms/step\n",
      "Epoch 378/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0039 - 42ms/epoch - 4ms/step\n",
      "Epoch 379/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0039 - 42ms/epoch - 3ms/step\n",
      "Epoch 380/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 381/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0042 - 43ms/epoch - 4ms/step\n",
      "Epoch 382/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0037 - 46ms/epoch - 4ms/step\n",
      "Epoch 383/400\n",
      "12/12 - 0s - loss: 0.0086 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 384/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0039 - 43ms/epoch - 4ms/step\n",
      "Epoch 385/400\n",
      "12/12 - 0s - loss: 0.0082 - val_loss: 0.0043 - 43ms/epoch - 4ms/step\n",
      "Epoch 386/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 387/400\n",
      "12/12 - 0s - loss: 0.0074 - val_loss: 0.0039 - 44ms/epoch - 4ms/step\n",
      "Epoch 388/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0037 - 42ms/epoch - 4ms/step\n",
      "Epoch 389/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 390/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0038 - 43ms/epoch - 4ms/step\n",
      "Epoch 391/400\n",
      "12/12 - 0s - loss: 0.0077 - val_loss: 0.0040 - 44ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0036 - 53ms/epoch - 4ms/step\n",
      "Epoch 393/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0037 - 43ms/epoch - 4ms/step\n",
      "Epoch 394/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0041 - 42ms/epoch - 4ms/step\n",
      "Epoch 395/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 396/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0036 - 42ms/epoch - 3ms/step\n",
      "Epoch 397/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0040 - 40ms/epoch - 3ms/step\n",
      "Epoch 398/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0038 - 40ms/epoch - 3ms/step\n",
      "Epoch 399/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0041 - 40ms/epoch - 3ms/step\n",
      "Epoch 400/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0039 - 40ms/epoch - 3ms/step\n",
      "COMPRESSED VECTOR SIZE: 14\n",
      "Loss in the autoencoder: 0.00393646489828825\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Compressed layer size: 10\n",
      "Epoch 1/400\n",
      "12/12 - 1s - loss: 0.5831 - val_loss: 0.1694 - 784ms/epoch - 65ms/step\n",
      "Epoch 2/400\n",
      "12/12 - 0s - loss: 0.3657 - val_loss: 0.1446 - 51ms/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "12/12 - 0s - loss: 0.2582 - val_loss: 0.1294 - 45ms/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "12/12 - 0s - loss: 0.1784 - val_loss: 0.1148 - 42ms/epoch - 4ms/step\n",
      "Epoch 5/400\n",
      "12/12 - 0s - loss: 0.1258 - val_loss: 0.1077 - 44ms/epoch - 4ms/step\n",
      "Epoch 6/400\n",
      "12/12 - 0s - loss: 0.1045 - val_loss: 0.1039 - 46ms/epoch - 4ms/step\n",
      "Epoch 7/400\n",
      "12/12 - 0s - loss: 0.0965 - val_loss: 0.0971 - 43ms/epoch - 4ms/step\n",
      "Epoch 8/400\n",
      "12/12 - 0s - loss: 0.0823 - val_loss: 0.0885 - 43ms/epoch - 4ms/step\n",
      "Epoch 9/400\n",
      "12/12 - 0s - loss: 0.0715 - val_loss: 0.0800 - 44ms/epoch - 4ms/step\n",
      "Epoch 10/400\n",
      "12/12 - 0s - loss: 0.0662 - val_loss: 0.0723 - 42ms/epoch - 4ms/step\n",
      "Epoch 11/400\n",
      "12/12 - 0s - loss: 0.0597 - val_loss: 0.0661 - 43ms/epoch - 4ms/step\n",
      "Epoch 12/400\n",
      "12/12 - 0s - loss: 0.0579 - val_loss: 0.0603 - 41ms/epoch - 3ms/step\n",
      "Epoch 13/400\n",
      "12/12 - 0s - loss: 0.0540 - val_loss: 0.0558 - 47ms/epoch - 4ms/step\n",
      "Epoch 14/400\n",
      "12/12 - 0s - loss: 0.0531 - val_loss: 0.0511 - 44ms/epoch - 4ms/step\n",
      "Epoch 15/400\n",
      "12/12 - 0s - loss: 0.0539 - val_loss: 0.0471 - 42ms/epoch - 3ms/step\n",
      "Epoch 16/400\n",
      "12/12 - 0s - loss: 0.0500 - val_loss: 0.0426 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/400\n",
      "12/12 - 0s - loss: 0.0440 - val_loss: 0.0403 - 42ms/epoch - 3ms/step\n",
      "Epoch 18/400\n",
      "12/12 - 0s - loss: 0.0437 - val_loss: 0.0375 - 44ms/epoch - 4ms/step\n",
      "Epoch 19/400\n",
      "12/12 - 0s - loss: 0.0507 - val_loss: 0.0353 - 42ms/epoch - 4ms/step\n",
      "Epoch 20/400\n",
      "12/12 - 0s - loss: 0.0438 - val_loss: 0.0340 - 41ms/epoch - 3ms/step\n",
      "Epoch 21/400\n",
      "12/12 - 0s - loss: 0.0428 - val_loss: 0.0316 - 38ms/epoch - 3ms/step\n",
      "Epoch 22/400\n",
      "12/12 - 0s - loss: 0.0375 - val_loss: 0.0290 - 38ms/epoch - 3ms/step\n",
      "Epoch 23/400\n",
      "12/12 - 0s - loss: 0.0363 - val_loss: 0.0277 - 38ms/epoch - 3ms/step\n",
      "Epoch 24/400\n",
      "12/12 - 0s - loss: 0.0359 - val_loss: 0.0256 - 39ms/epoch - 3ms/step\n",
      "Epoch 25/400\n",
      "12/12 - 0s - loss: 0.0355 - val_loss: 0.0255 - 39ms/epoch - 3ms/step\n",
      "Epoch 26/400\n",
      "12/12 - 0s - loss: 0.0345 - val_loss: 0.0240 - 40ms/epoch - 3ms/step\n",
      "Epoch 27/400\n",
      "12/12 - 0s - loss: 0.0332 - val_loss: 0.0231 - 43ms/epoch - 4ms/step\n",
      "Epoch 28/400\n",
      "12/12 - 0s - loss: 0.0341 - val_loss: 0.0216 - 42ms/epoch - 4ms/step\n",
      "Epoch 29/400\n",
      "12/12 - 0s - loss: 0.0314 - val_loss: 0.0207 - 41ms/epoch - 3ms/step\n",
      "Epoch 30/400\n",
      "12/12 - 0s - loss: 0.0336 - val_loss: 0.0202 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/400\n",
      "12/12 - 0s - loss: 0.0308 - val_loss: 0.0199 - 43ms/epoch - 4ms/step\n",
      "Epoch 32/400\n",
      "12/12 - 0s - loss: 0.0299 - val_loss: 0.0192 - 43ms/epoch - 4ms/step\n",
      "Epoch 33/400\n",
      "12/12 - 0s - loss: 0.0312 - val_loss: 0.0188 - 41ms/epoch - 3ms/step\n",
      "Epoch 34/400\n",
      "12/12 - 0s - loss: 0.0337 - val_loss: 0.0180 - 42ms/epoch - 3ms/step\n",
      "Epoch 35/400\n",
      "12/12 - 0s - loss: 0.0314 - val_loss: 0.0183 - 44ms/epoch - 4ms/step\n",
      "Epoch 36/400\n",
      "12/12 - 0s - loss: 0.0290 - val_loss: 0.0176 - 42ms/epoch - 4ms/step\n",
      "Epoch 37/400\n",
      "12/12 - 0s - loss: 0.0330 - val_loss: 0.0174 - 42ms/epoch - 3ms/step\n",
      "Epoch 38/400\n",
      "12/12 - 0s - loss: 0.0282 - val_loss: 0.0174 - 41ms/epoch - 3ms/step\n",
      "Epoch 39/400\n",
      "12/12 - 0s - loss: 0.0309 - val_loss: 0.0171 - 43ms/epoch - 4ms/step\n",
      "Epoch 40/400\n",
      "12/12 - 0s - loss: 0.0268 - val_loss: 0.0169 - 42ms/epoch - 4ms/step\n",
      "Epoch 41/400\n",
      "12/12 - 0s - loss: 0.0288 - val_loss: 0.0164 - 43ms/epoch - 4ms/step\n",
      "Epoch 42/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0165 - 43ms/epoch - 4ms/step\n",
      "Epoch 43/400\n",
      "12/12 - 0s - loss: 0.0260 - val_loss: 0.0160 - 42ms/epoch - 3ms/step\n",
      "Epoch 44/400\n",
      "12/12 - 0s - loss: 0.0285 - val_loss: 0.0158 - 42ms/epoch - 4ms/step\n",
      "Epoch 45/400\n",
      "12/12 - 0s - loss: 0.0288 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 46/400\n",
      "12/12 - 0s - loss: 0.0290 - val_loss: 0.0158 - 42ms/epoch - 3ms/step\n",
      "Epoch 47/400\n",
      "12/12 - 0s - loss: 0.0274 - val_loss: 0.0159 - 44ms/epoch - 4ms/step\n",
      "Epoch 48/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/400\n",
      "12/12 - 0s - loss: 0.0270 - val_loss: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 50/400\n",
      "12/12 - 0s - loss: 0.0255 - val_loss: 0.0155 - 42ms/epoch - 4ms/step\n",
      "Epoch 51/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0155 - 42ms/epoch - 4ms/step\n",
      "Epoch 52/400\n",
      "12/12 - 0s - loss: 0.0291 - val_loss: 0.0150 - 43ms/epoch - 4ms/step\n",
      "Epoch 53/400\n",
      "12/12 - 0s - loss: 0.0270 - val_loss: 0.0153 - 42ms/epoch - 3ms/step\n",
      "Epoch 54/400\n",
      "12/12 - 0s - loss: 0.0265 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 55/400\n",
      "12/12 - 0s - loss: 0.0272 - val_loss: 0.0148 - 43ms/epoch - 4ms/step\n",
      "Epoch 56/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0143 - 42ms/epoch - 3ms/step\n",
      "Epoch 57/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0141 - 42ms/epoch - 3ms/step\n",
      "Epoch 58/400\n",
      "12/12 - 0s - loss: 0.0262 - val_loss: 0.0146 - 41ms/epoch - 3ms/step\n",
      "Epoch 59/400\n",
      "12/12 - 0s - loss: 0.0256 - val_loss: 0.0145 - 43ms/epoch - 4ms/step\n",
      "Epoch 60/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0142 - 42ms/epoch - 3ms/step\n",
      "Epoch 61/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0138 - 42ms/epoch - 4ms/step\n",
      "Epoch 62/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0137 - 44ms/epoch - 4ms/step\n",
      "Epoch 63/400\n",
      "12/12 - 0s - loss: 0.0284 - val_loss: 0.0139 - 42ms/epoch - 3ms/step\n",
      "Epoch 64/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0141 - 42ms/epoch - 4ms/step\n",
      "Epoch 65/400\n",
      "12/12 - 0s - loss: 0.0265 - val_loss: 0.0139 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0136 - 41ms/epoch - 3ms/step\n",
      "Epoch 67/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0136 - 39ms/epoch - 3ms/step\n",
      "Epoch 68/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0133 - 40ms/epoch - 3ms/step\n",
      "Epoch 69/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0131 - 38ms/epoch - 3ms/step\n",
      "Epoch 70/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0136 - 38ms/epoch - 3ms/step\n",
      "Epoch 71/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0134 - 39ms/epoch - 3ms/step\n",
      "Epoch 72/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0131 - 39ms/epoch - 3ms/step\n",
      "Epoch 73/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0130 - 43ms/epoch - 4ms/step\n",
      "Epoch 74/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0132 - 41ms/epoch - 3ms/step\n",
      "Epoch 75/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0126 - 41ms/epoch - 3ms/step\n",
      "Epoch 76/400\n",
      "12/12 - 0s - loss: 0.0232 - val_loss: 0.0124 - 41ms/epoch - 3ms/step\n",
      "Epoch 77/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0122 - 42ms/epoch - 4ms/step\n",
      "Epoch 78/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0122 - 42ms/epoch - 3ms/step\n",
      "Epoch 79/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0125 - 42ms/epoch - 4ms/step\n",
      "Epoch 80/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0118 - 42ms/epoch - 3ms/step\n",
      "Epoch 81/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0122 - 41ms/epoch - 3ms/step\n",
      "Epoch 82/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0122 - 42ms/epoch - 4ms/step\n",
      "Epoch 83/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0117 - 42ms/epoch - 3ms/step\n",
      "Epoch 84/400\n",
      "12/12 - 0s - loss: 0.0244 - val_loss: 0.0118 - 41ms/epoch - 3ms/step\n",
      "Epoch 85/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0113 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0114 - 42ms/epoch - 4ms/step\n",
      "Epoch 87/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0113 - 42ms/epoch - 4ms/step\n",
      "Epoch 88/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0116 - 42ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0117 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0121 - 42ms/epoch - 4ms/step\n",
      "Epoch 91/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0121 - 42ms/epoch - 4ms/step\n",
      "Epoch 92/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0114 - 41ms/epoch - 3ms/step\n",
      "Epoch 93/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0115 - 41ms/epoch - 3ms/step\n",
      "Epoch 94/400\n",
      "12/12 - 0s - loss: 0.0184 - val_loss: 0.0115 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0113 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/400\n",
      "12/12 - 0s - loss: 0.0185 - val_loss: 0.0109 - 42ms/epoch - 4ms/step\n",
      "Epoch 97/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0107 - 41ms/epoch - 3ms/step\n",
      "Epoch 98/400\n",
      "12/12 - 0s - loss: 0.0172 - val_loss: 0.0111 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/400\n",
      "12/12 - 0s - loss: 0.0181 - val_loss: 0.0107 - 42ms/epoch - 4ms/step\n",
      "Epoch 100/400\n",
      "12/12 - 0s - loss: 0.0185 - val_loss: 0.0107 - 42ms/epoch - 4ms/step\n",
      "Epoch 101/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0109 - 42ms/epoch - 4ms/step\n",
      "Epoch 102/400\n",
      "12/12 - 0s - loss: 0.0180 - val_loss: 0.0104 - 42ms/epoch - 4ms/step\n",
      "Epoch 103/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0103 - 44ms/epoch - 4ms/step\n",
      "Epoch 104/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0106 - 41ms/epoch - 3ms/step\n",
      "Epoch 105/400\n",
      "12/12 - 0s - loss: 0.0179 - val_loss: 0.0105 - 41ms/epoch - 3ms/step\n",
      "Epoch 106/400\n",
      "12/12 - 0s - loss: 0.0179 - val_loss: 0.0104 - 43ms/epoch - 4ms/step\n",
      "Epoch 107/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0103 - 41ms/epoch - 3ms/step\n",
      "Epoch 108/400\n",
      "12/12 - 0s - loss: 0.0174 - val_loss: 0.0108 - 42ms/epoch - 4ms/step\n",
      "Epoch 109/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0104 - 42ms/epoch - 4ms/step\n",
      "Epoch 110/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0103 - 41ms/epoch - 3ms/step\n",
      "Epoch 111/400\n",
      "12/12 - 0s - loss: 0.0183 - val_loss: 0.0102 - 43ms/epoch - 4ms/step\n",
      "Epoch 112/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0099 - 40ms/epoch - 3ms/step\n",
      "Epoch 113/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0097 - 39ms/epoch - 3ms/step\n",
      "Epoch 114/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0100 - 38ms/epoch - 3ms/step\n",
      "Epoch 115/400\n",
      "12/12 - 0s - loss: 0.0180 - val_loss: 0.0097 - 39ms/epoch - 3ms/step\n",
      "Epoch 116/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0096 - 39ms/epoch - 3ms/step\n",
      "Epoch 117/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0095 - 39ms/epoch - 3ms/step\n",
      "Epoch 118/400\n",
      "12/12 - 0s - loss: 0.0178 - val_loss: 0.0095 - 39ms/epoch - 3ms/step\n",
      "Epoch 119/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0093 - 39ms/epoch - 3ms/step\n",
      "Epoch 120/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0093 - 42ms/epoch - 4ms/step\n",
      "Epoch 121/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0094 - 41ms/epoch - 3ms/step\n",
      "Epoch 122/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0089 - 53ms/epoch - 4ms/step\n",
      "Epoch 123/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0090 - 49ms/epoch - 4ms/step\n",
      "Epoch 124/400\n",
      "12/12 - 0s - loss: 0.0159 - val_loss: 0.0097 - 45ms/epoch - 4ms/step\n",
      "Epoch 125/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0093 - 47ms/epoch - 4ms/step\n",
      "Epoch 126/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0092 - 41ms/epoch - 3ms/step\n",
      "Epoch 127/400\n",
      "12/12 - 0s - loss: 0.0164 - val_loss: 0.0093 - 43ms/epoch - 4ms/step\n",
      "Epoch 128/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0097 - 43ms/epoch - 4ms/step\n",
      "Epoch 129/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0089 - 43ms/epoch - 4ms/step\n",
      "Epoch 130/400\n",
      "12/12 - 0s - loss: 0.0170 - val_loss: 0.0089 - 42ms/epoch - 4ms/step\n",
      "Epoch 131/400\n",
      "12/12 - 0s - loss: 0.0164 - val_loss: 0.0089 - 42ms/epoch - 4ms/step\n",
      "Epoch 132/400\n",
      "12/12 - 0s - loss: 0.0178 - val_loss: 0.0089 - 40ms/epoch - 3ms/step\n",
      "Epoch 133/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0083 - 41ms/epoch - 3ms/step\n",
      "Epoch 134/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 135/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0079 - 42ms/epoch - 4ms/step\n",
      "Epoch 136/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 137/400\n",
      "12/12 - 0s - loss: 0.0174 - val_loss: 0.0084 - 51ms/epoch - 4ms/step\n",
      "Epoch 138/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0084 - 42ms/epoch - 3ms/step\n",
      "Epoch 139/400\n",
      "12/12 - 0s - loss: 0.0162 - val_loss: 0.0083 - 42ms/epoch - 3ms/step\n",
      "Epoch 140/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0080 - 41ms/epoch - 3ms/step\n",
      "Epoch 141/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0084 - 41ms/epoch - 3ms/step\n",
      "Epoch 142/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0078 - 42ms/epoch - 3ms/step\n",
      "Epoch 143/400\n",
      "12/12 - 0s - loss: 0.0154 - val_loss: 0.0077 - 44ms/epoch - 4ms/step\n",
      "Epoch 144/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0078 - 44ms/epoch - 4ms/step\n",
      "Epoch 145/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0079 - 45ms/epoch - 4ms/step\n",
      "Epoch 146/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0077 - 48ms/epoch - 4ms/step\n",
      "Epoch 147/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0078 - 41ms/epoch - 3ms/step\n",
      "Epoch 148/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0076 - 42ms/epoch - 3ms/step\n",
      "Epoch 149/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0080 - 46ms/epoch - 4ms/step\n",
      "Epoch 150/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 151/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0074 - 42ms/epoch - 4ms/step\n",
      "Epoch 152/400\n",
      "12/12 - 0s - loss: 0.0170 - val_loss: 0.0071 - 41ms/epoch - 3ms/step\n",
      "Epoch 153/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0077 - 43ms/epoch - 4ms/step\n",
      "Epoch 154/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0072 - 44ms/epoch - 4ms/step\n",
      "Epoch 155/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0073 - 44ms/epoch - 4ms/step\n",
      "Epoch 156/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0074 - 43ms/epoch - 4ms/step\n",
      "Epoch 157/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0076 - 41ms/epoch - 3ms/step\n",
      "Epoch 158/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0073 - 38ms/epoch - 3ms/step\n",
      "Epoch 159/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0071 - 39ms/epoch - 3ms/step\n",
      "Epoch 160/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0072 - 39ms/epoch - 3ms/step\n",
      "Epoch 161/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0074 - 40ms/epoch - 3ms/step\n",
      "Epoch 162/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0074 - 40ms/epoch - 3ms/step\n",
      "Epoch 163/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0072 - 40ms/epoch - 3ms/step\n",
      "Epoch 164/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0074 - 42ms/epoch - 3ms/step\n",
      "Epoch 165/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0074 - 41ms/epoch - 3ms/step\n",
      "Epoch 166/400\n",
      "12/12 - 0s - loss: 0.0183 - val_loss: 0.0073 - 40ms/epoch - 3ms/step\n",
      "Epoch 167/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0076 - 42ms/epoch - 4ms/step\n",
      "Epoch 168/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0075 - 47ms/epoch - 4ms/step\n",
      "Epoch 169/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0073 - 45ms/epoch - 4ms/step\n",
      "Epoch 170/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0070 - 44ms/epoch - 4ms/step\n",
      "Epoch 171/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0070 - 42ms/epoch - 3ms/step\n",
      "Epoch 172/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0073 - 42ms/epoch - 4ms/step\n",
      "Epoch 173/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0068 - 44ms/epoch - 4ms/step\n",
      "Epoch 174/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0070 - 43ms/epoch - 4ms/step\n",
      "Epoch 175/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0069 - 43ms/epoch - 4ms/step\n",
      "Epoch 176/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0070 - 42ms/epoch - 3ms/step\n",
      "Epoch 177/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0068 - 41ms/epoch - 3ms/step\n",
      "Epoch 178/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0066 - 42ms/epoch - 3ms/step\n",
      "Epoch 179/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0073 - 43ms/epoch - 4ms/step\n",
      "Epoch 180/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0070 - 44ms/epoch - 4ms/step\n",
      "Epoch 181/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0069 - 41ms/epoch - 3ms/step\n",
      "Epoch 182/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0067 - 40ms/epoch - 3ms/step\n",
      "Epoch 183/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0066 - 42ms/epoch - 3ms/step\n",
      "Epoch 184/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0065 - 43ms/epoch - 4ms/step\n",
      "Epoch 185/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 186/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0067 - 47ms/epoch - 4ms/step\n",
      "Epoch 187/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0068 - 50ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0065 - 51ms/epoch - 4ms/step\n",
      "Epoch 189/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0067 - 42ms/epoch - 4ms/step\n",
      "Epoch 190/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0068 - 42ms/epoch - 3ms/step\n",
      "Epoch 191/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0066 - 42ms/epoch - 3ms/step\n",
      "Epoch 192/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0066 - 43ms/epoch - 4ms/step\n",
      "Epoch 193/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0065 - 43ms/epoch - 4ms/step\n",
      "Epoch 194/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0064 - 42ms/epoch - 4ms/step\n",
      "Epoch 195/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0063 - 51ms/epoch - 4ms/step\n",
      "Epoch 196/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0065 - 42ms/epoch - 3ms/step\n",
      "Epoch 197/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0063 - 41ms/epoch - 3ms/step\n",
      "Epoch 198/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 199/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0062 - 44ms/epoch - 4ms/step\n",
      "Epoch 200/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 201/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0063 - 42ms/epoch - 3ms/step\n",
      "Epoch 202/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0063 - 40ms/epoch - 3ms/step\n",
      "Epoch 203/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0061 - 40ms/epoch - 3ms/step\n",
      "Epoch 204/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0059 - 40ms/epoch - 3ms/step\n",
      "Epoch 205/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0061 - 40ms/epoch - 3ms/step\n",
      "Epoch 206/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0062 - 40ms/epoch - 3ms/step\n",
      "Epoch 207/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0062 - 40ms/epoch - 3ms/step\n",
      "Epoch 208/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0059 - 40ms/epoch - 3ms/step\n",
      "Epoch 209/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0060 - 41ms/epoch - 3ms/step\n",
      "Epoch 210/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0060 - 44ms/epoch - 4ms/step\n",
      "Epoch 211/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 212/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0060 - 41ms/epoch - 3ms/step\n",
      "Epoch 213/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 214/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0064 - 42ms/epoch - 3ms/step\n",
      "Epoch 215/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0063 - 43ms/epoch - 4ms/step\n",
      "Epoch 216/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0060 - 42ms/epoch - 3ms/step\n",
      "Epoch 217/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0063 - 42ms/epoch - 4ms/step\n",
      "Epoch 218/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0062 - 42ms/epoch - 4ms/step\n",
      "Epoch 219/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 220/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0063 - 43ms/epoch - 4ms/step\n",
      "Epoch 221/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 222/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 223/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 224/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0060 - 42ms/epoch - 3ms/step\n",
      "Epoch 225/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 226/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 227/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 228/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 229/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 230/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 231/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0061 - 42ms/epoch - 4ms/step\n",
      "Epoch 232/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0056 - 42ms/epoch - 4ms/step\n",
      "Epoch 233/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0059 - 41ms/epoch - 3ms/step\n",
      "Epoch 234/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 235/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0065 - 43ms/epoch - 4ms/step\n",
      "Epoch 236/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 237/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0061 - 44ms/epoch - 4ms/step\n",
      "Epoch 238/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0062 - 43ms/epoch - 4ms/step\n",
      "Epoch 239/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0060 - 42ms/epoch - 3ms/step\n",
      "Epoch 240/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 241/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0058 - 44ms/epoch - 4ms/step\n",
      "Epoch 242/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 243/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 244/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0057 - 44ms/epoch - 4ms/step\n",
      "Epoch 245/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 246/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 247/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0056 - 42ms/epoch - 3ms/step\n",
      "Epoch 248/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0057 - 40ms/epoch - 3ms/step\n",
      "Epoch 249/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0056 - 40ms/epoch - 3ms/step\n",
      "Epoch 250/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0065 - 40ms/epoch - 3ms/step\n",
      "Epoch 251/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0056 - 39ms/epoch - 3ms/step\n",
      "Epoch 252/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0056 - 40ms/epoch - 3ms/step\n",
      "Epoch 253/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0055 - 41ms/epoch - 3ms/step\n",
      "Epoch 254/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0060 - 41ms/epoch - 3ms/step\n",
      "Epoch 255/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 256/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 257/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 258/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 259/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0059 - 44ms/epoch - 4ms/step\n",
      "Epoch 260/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0055 - 46ms/epoch - 4ms/step\n",
      "Epoch 261/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 262/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 263/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0055 - 44ms/epoch - 4ms/step\n",
      "Epoch 264/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 265/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0053 - 41ms/epoch - 3ms/step\n",
      "Epoch 266/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0053 - 41ms/epoch - 3ms/step\n",
      "Epoch 267/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0054 - 42ms/epoch - 3ms/step\n",
      "Epoch 268/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0057 - 42ms/epoch - 3ms/step\n",
      "Epoch 269/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 270/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 271/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 272/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0054 - 53ms/epoch - 4ms/step\n",
      "Epoch 273/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 274/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0053 - 42ms/epoch - 3ms/step\n",
      "Epoch 275/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 276/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 277/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0056 - 44ms/epoch - 4ms/step\n",
      "Epoch 278/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 279/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 280/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 281/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 282/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0061 - 44ms/epoch - 4ms/step\n",
      "Epoch 283/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0061 - 46ms/epoch - 4ms/step\n",
      "Epoch 284/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 285/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 286/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 288/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0053 - 44ms/epoch - 4ms/step\n",
      "Epoch 289/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0051 - 42ms/epoch - 4ms/step\n",
      "Epoch 290/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0051 - 42ms/epoch - 4ms/step\n",
      "Epoch 291/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0059 - 46ms/epoch - 4ms/step\n",
      "Epoch 292/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 293/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0059 - 40ms/epoch - 3ms/step\n",
      "Epoch 294/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0060 - 40ms/epoch - 3ms/step\n",
      "Epoch 295/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0056 - 39ms/epoch - 3ms/step\n",
      "Epoch 296/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0057 - 40ms/epoch - 3ms/step\n",
      "Epoch 297/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0055 - 41ms/epoch - 3ms/step\n",
      "Epoch 298/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0053 - 41ms/epoch - 3ms/step\n",
      "Epoch 299/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 300/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 301/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 302/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0052 - 41ms/epoch - 3ms/step\n",
      "Epoch 303/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 304/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0051 - 44ms/epoch - 4ms/step\n",
      "Epoch 305/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0049 - 44ms/epoch - 4ms/step\n",
      "Epoch 306/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 307/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 308/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 309/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 310/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 311/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 312/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 313/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0054 - 45ms/epoch - 4ms/step\n",
      "Epoch 314/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 315/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0052 - 42ms/epoch - 3ms/step\n",
      "Epoch 316/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0054 - 44ms/epoch - 4ms/step\n",
      "Epoch 317/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 318/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0057 - 44ms/epoch - 4ms/step\n",
      "Epoch 319/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0055 - 45ms/epoch - 4ms/step\n",
      "Epoch 320/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0054 - 44ms/epoch - 4ms/step\n",
      "Epoch 321/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0056 - 41ms/epoch - 3ms/step\n",
      "Epoch 322/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 323/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 324/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 325/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0052 - 44ms/epoch - 4ms/step\n",
      "Epoch 326/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 327/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0052 - 44ms/epoch - 4ms/step\n",
      "Epoch 328/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0060 - 47ms/epoch - 4ms/step\n",
      "Epoch 329/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 330/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 331/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0055 - 42ms/epoch - 4ms/step\n",
      "Epoch 332/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 333/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 334/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 335/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 336/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 337/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 338/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0051 - 41ms/epoch - 3ms/step\n",
      "Epoch 339/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 340/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 341/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 342/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0051 - 40ms/epoch - 3ms/step\n",
      "Epoch 343/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0048 - 40ms/epoch - 3ms/step\n",
      "Epoch 344/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0048 - 40ms/epoch - 3ms/step\n",
      "Epoch 345/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 346/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 347/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0047 - 42ms/epoch - 3ms/step\n",
      "Epoch 348/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 349/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 350/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 351/400\n",
      "12/12 - 0s - loss: 0.0096 - val_loss: 0.0050 - 42ms/epoch - 4ms/step\n",
      "Epoch 352/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 353/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 354/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 355/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0049 - 42ms/epoch - 4ms/step\n",
      "Epoch 356/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0050 - 42ms/epoch - 4ms/step\n",
      "Epoch 357/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 358/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0049 - 44ms/epoch - 4ms/step\n",
      "Epoch 359/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 360/400\n",
      "12/12 - 0s - loss: 0.0079 - val_loss: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 361/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0051 - 42ms/epoch - 4ms/step\n",
      "Epoch 362/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 363/400\n",
      "12/12 - 0s - loss: 0.0085 - val_loss: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 364/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0048 - 41ms/epoch - 3ms/step\n",
      "Epoch 365/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0049 - 43ms/epoch - 4ms/step\n",
      "Epoch 366/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0047 - 43ms/epoch - 4ms/step\n",
      "Epoch 367/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 368/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0048 - 43ms/epoch - 4ms/step\n",
      "Epoch 369/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0044 - 42ms/epoch - 4ms/step\n",
      "Epoch 370/400\n",
      "12/12 - 0s - loss: 0.0098 - val_loss: 0.0046 - 42ms/epoch - 4ms/step\n",
      "Epoch 371/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0045 - 41ms/epoch - 3ms/step\n",
      "Epoch 372/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0045 - 42ms/epoch - 4ms/step\n",
      "Epoch 373/400\n",
      "12/12 - 0s - loss: 0.0090 - val_loss: 0.0043 - 45ms/epoch - 4ms/step\n",
      "Epoch 374/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0041 - 41ms/epoch - 3ms/step\n",
      "Epoch 375/400\n",
      "12/12 - 0s - loss: 0.0091 - val_loss: 0.0044 - 43ms/epoch - 4ms/step\n",
      "Epoch 376/400\n",
      "12/12 - 0s - loss: 0.0089 - val_loss: 0.0043 - 42ms/epoch - 4ms/step\n",
      "Epoch 377/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0045 - 47ms/epoch - 4ms/step\n",
      "Epoch 378/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0047 - 48ms/epoch - 4ms/step\n",
      "Epoch 379/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0045 - 51ms/epoch - 4ms/step\n",
      "Epoch 380/400\n",
      "12/12 - 0s - loss: 0.0094 - val_loss: 0.0045 - 42ms/epoch - 4ms/step\n",
      "Epoch 381/400\n",
      "12/12 - 0s - loss: 0.0093 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 382/400\n",
      "12/12 - 0s - loss: 0.0077 - val_loss: 0.0041 - 42ms/epoch - 4ms/step\n",
      "Epoch 383/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0041 - 40ms/epoch - 3ms/step\n",
      "Epoch 384/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0041 - 39ms/epoch - 3ms/step\n",
      "Epoch 385/400\n",
      "12/12 - 0s - loss: 0.0087 - val_loss: 0.0040 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/400\n",
      "12/12 - 0s - loss: 0.0088 - val_loss: 0.0039 - 40ms/epoch - 3ms/step\n",
      "Epoch 387/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0040 - 42ms/epoch - 3ms/step\n",
      "Epoch 388/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0043 - 40ms/epoch - 3ms/step\n",
      "Epoch 389/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0041 - 39ms/epoch - 3ms/step\n",
      "Epoch 390/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0041 - 41ms/epoch - 3ms/step\n",
      "Epoch 391/400\n",
      "12/12 - 0s - loss: 0.0095 - val_loss: 0.0042 - 42ms/epoch - 3ms/step\n",
      "Epoch 392/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0043 - 41ms/epoch - 3ms/step\n",
      "Epoch 393/400\n",
      "12/12 - 0s - loss: 0.0083 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 394/400\n",
      "12/12 - 0s - loss: 0.0077 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 395/400\n",
      "12/12 - 0s - loss: 0.0081 - val_loss: 0.0045 - 43ms/epoch - 4ms/step\n",
      "Epoch 396/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0041 - 45ms/epoch - 4ms/step\n",
      "Epoch 397/400\n",
      "12/12 - 0s - loss: 0.0080 - val_loss: 0.0041 - 43ms/epoch - 4ms/step\n",
      "Epoch 398/400\n",
      "12/12 - 0s - loss: 0.0084 - val_loss: 0.0041 - 42ms/epoch - 3ms/step\n",
      "Epoch 399/400\n",
      "12/12 - 0s - loss: 0.0092 - val_loss: 0.0040 - 42ms/epoch - 4ms/step\n",
      "Epoch 400/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0042 - 44ms/epoch - 4ms/step\n",
      "COMPRESSED VECTOR SIZE: 10\n",
      "Loss in the autoencoder: 0.004189779981970787\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Compressed layer size: 7\n",
      "Epoch 1/400\n",
      "12/12 - 1s - loss: 0.7419 - val_loss: 0.2154 - 853ms/epoch - 71ms/step\n",
      "Epoch 2/400\n",
      "12/12 - 0s - loss: 0.4797 - val_loss: 0.1979 - 47ms/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "12/12 - 0s - loss: 0.3295 - val_loss: 0.1830 - 45ms/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "12/12 - 0s - loss: 0.2313 - val_loss: 0.1699 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/400\n",
      "12/12 - 0s - loss: 0.1727 - val_loss: 0.1609 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/400\n",
      "12/12 - 0s - loss: 0.1384 - val_loss: 0.1508 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/400\n",
      "12/12 - 0s - loss: 0.1145 - val_loss: 0.1409 - 40ms/epoch - 3ms/step\n",
      "Epoch 8/400\n",
      "12/12 - 0s - loss: 0.0930 - val_loss: 0.1329 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/400\n",
      "12/12 - 0s - loss: 0.0855 - val_loss: 0.1259 - 38ms/epoch - 3ms/step\n",
      "Epoch 10/400\n",
      "12/12 - 0s - loss: 0.0770 - val_loss: 0.1179 - 41ms/epoch - 3ms/step\n",
      "Epoch 11/400\n",
      "12/12 - 0s - loss: 0.0736 - val_loss: 0.1091 - 42ms/epoch - 3ms/step\n",
      "Epoch 12/400\n",
      "12/12 - 0s - loss: 0.0722 - val_loss: 0.1017 - 43ms/epoch - 4ms/step\n",
      "Epoch 13/400\n",
      "12/12 - 0s - loss: 0.0620 - val_loss: 0.0959 - 42ms/epoch - 4ms/step\n",
      "Epoch 14/400\n",
      "12/12 - 0s - loss: 0.0592 - val_loss: 0.0910 - 41ms/epoch - 3ms/step\n",
      "Epoch 15/400\n",
      "12/12 - 0s - loss: 0.0541 - val_loss: 0.0846 - 42ms/epoch - 3ms/step\n",
      "Epoch 16/400\n",
      "12/12 - 0s - loss: 0.0503 - val_loss: 0.0802 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/400\n",
      "12/12 - 0s - loss: 0.0491 - val_loss: 0.0744 - 41ms/epoch - 3ms/step\n",
      "Epoch 18/400\n",
      "12/12 - 0s - loss: 0.0497 - val_loss: 0.0688 - 42ms/epoch - 3ms/step\n",
      "Epoch 19/400\n",
      "12/12 - 0s - loss: 0.0453 - val_loss: 0.0645 - 44ms/epoch - 4ms/step\n",
      "Epoch 20/400\n",
      "12/12 - 0s - loss: 0.0473 - val_loss: 0.0598 - 42ms/epoch - 4ms/step\n",
      "Epoch 21/400\n",
      "12/12 - 0s - loss: 0.0505 - val_loss: 0.0558 - 41ms/epoch - 3ms/step\n",
      "Epoch 22/400\n",
      "12/12 - 0s - loss: 0.0450 - val_loss: 0.0520 - 52ms/epoch - 4ms/step\n",
      "Epoch 23/400\n",
      "12/12 - 0s - loss: 0.0428 - val_loss: 0.0487 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/400\n",
      "12/12 - 0s - loss: 0.0395 - val_loss: 0.0461 - 42ms/epoch - 3ms/step\n",
      "Epoch 25/400\n",
      "12/12 - 0s - loss: 0.0422 - val_loss: 0.0441 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/400\n",
      "12/12 - 0s - loss: 0.0413 - val_loss: 0.0414 - 43ms/epoch - 4ms/step\n",
      "Epoch 27/400\n",
      "12/12 - 0s - loss: 0.0385 - val_loss: 0.0390 - 43ms/epoch - 4ms/step\n",
      "Epoch 28/400\n",
      "12/12 - 0s - loss: 0.0375 - val_loss: 0.0367 - 42ms/epoch - 4ms/step\n",
      "Epoch 29/400\n",
      "12/12 - 0s - loss: 0.0367 - val_loss: 0.0349 - 41ms/epoch - 3ms/step\n",
      "Epoch 30/400\n",
      "12/12 - 0s - loss: 0.0325 - val_loss: 0.0335 - 45ms/epoch - 4ms/step\n",
      "Epoch 31/400\n",
      "12/12 - 0s - loss: 0.0353 - val_loss: 0.0325 - 41ms/epoch - 3ms/step\n",
      "Epoch 32/400\n",
      "12/12 - 0s - loss: 0.0363 - val_loss: 0.0307 - 41ms/epoch - 3ms/step\n",
      "Epoch 33/400\n",
      "12/12 - 0s - loss: 0.0357 - val_loss: 0.0302 - 44ms/epoch - 4ms/step\n",
      "Epoch 34/400\n",
      "12/12 - 0s - loss: 0.0345 - val_loss: 0.0295 - 44ms/epoch - 4ms/step\n",
      "Epoch 35/400\n",
      "12/12 - 0s - loss: 0.0326 - val_loss: 0.0283 - 41ms/epoch - 3ms/step\n",
      "Epoch 36/400\n",
      "12/12 - 0s - loss: 0.0326 - val_loss: 0.0268 - 41ms/epoch - 3ms/step\n",
      "Epoch 37/400\n",
      "12/12 - 0s - loss: 0.0325 - val_loss: 0.0260 - 43ms/epoch - 4ms/step\n",
      "Epoch 38/400\n",
      "12/12 - 0s - loss: 0.0357 - val_loss: 0.0262 - 41ms/epoch - 3ms/step\n",
      "Epoch 39/400\n",
      "12/12 - 0s - loss: 0.0319 - val_loss: 0.0258 - 41ms/epoch - 3ms/step\n",
      "Epoch 40/400\n",
      "12/12 - 0s - loss: 0.0311 - val_loss: 0.0253 - 43ms/epoch - 4ms/step\n",
      "Epoch 41/400\n",
      "12/12 - 0s - loss: 0.0287 - val_loss: 0.0243 - 45ms/epoch - 4ms/step\n",
      "Epoch 42/400\n",
      "12/12 - 0s - loss: 0.0334 - val_loss: 0.0237 - 44ms/epoch - 4ms/step\n",
      "Epoch 43/400\n",
      "12/12 - 0s - loss: 0.0276 - val_loss: 0.0238 - 42ms/epoch - 4ms/step\n",
      "Epoch 44/400\n",
      "12/12 - 0s - loss: 0.0289 - val_loss: 0.0241 - 42ms/epoch - 3ms/step\n",
      "Epoch 45/400\n",
      "12/12 - 0s - loss: 0.0307 - val_loss: 0.0234 - 42ms/epoch - 4ms/step\n",
      "Epoch 46/400\n",
      "12/12 - 0s - loss: 0.0278 - val_loss: 0.0236 - 46ms/epoch - 4ms/step\n",
      "Epoch 47/400\n",
      "12/12 - 0s - loss: 0.0285 - val_loss: 0.0220 - 47ms/epoch - 4ms/step\n",
      "Epoch 48/400\n",
      "12/12 - 0s - loss: 0.0309 - val_loss: 0.0218 - 47ms/epoch - 4ms/step\n",
      "Epoch 49/400\n",
      "12/12 - 0s - loss: 0.0285 - val_loss: 0.0219 - 45ms/epoch - 4ms/step\n",
      "Epoch 50/400\n",
      "12/12 - 0s - loss: 0.0296 - val_loss: 0.0215 - 45ms/epoch - 4ms/step\n",
      "Epoch 51/400\n",
      "12/12 - 0s - loss: 0.0283 - val_loss: 0.0209 - 43ms/epoch - 4ms/step\n",
      "Epoch 52/400\n",
      "12/12 - 0s - loss: 0.0263 - val_loss: 0.0208 - 42ms/epoch - 3ms/step\n",
      "Epoch 53/400\n",
      "12/12 - 0s - loss: 0.0292 - val_loss: 0.0207 - 42ms/epoch - 4ms/step\n",
      "Epoch 54/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0205 - 42ms/epoch - 4ms/step\n",
      "Epoch 55/400\n",
      "12/12 - 0s - loss: 0.0241 - val_loss: 0.0204 - 46ms/epoch - 4ms/step\n",
      "Epoch 56/400\n",
      "12/12 - 0s - loss: 0.0278 - val_loss: 0.0198 - 44ms/epoch - 4ms/step\n",
      "Epoch 57/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0191 - 48ms/epoch - 4ms/step\n",
      "Epoch 58/400\n",
      "12/12 - 0s - loss: 0.0276 - val_loss: 0.0192 - 42ms/epoch - 3ms/step\n",
      "Epoch 59/400\n",
      "12/12 - 0s - loss: 0.0281 - val_loss: 0.0190 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/400\n",
      "12/12 - 0s - loss: 0.0262 - val_loss: 0.0190 - 44ms/epoch - 4ms/step\n",
      "Epoch 61/400\n",
      "12/12 - 0s - loss: 0.0272 - val_loss: 0.0188 - 43ms/epoch - 4ms/step\n",
      "Epoch 62/400\n",
      "12/12 - 0s - loss: 0.0250 - val_loss: 0.0184 - 43ms/epoch - 4ms/step\n",
      "Epoch 63/400\n",
      "12/12 - 0s - loss: 0.0267 - val_loss: 0.0174 - 42ms/epoch - 4ms/step\n",
      "Epoch 64/400\n",
      "12/12 - 0s - loss: 0.0277 - val_loss: 0.0170 - 42ms/epoch - 3ms/step\n",
      "Epoch 65/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0169 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0173 - 41ms/epoch - 3ms/step\n",
      "Epoch 67/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0167 - 43ms/epoch - 4ms/step\n",
      "Epoch 68/400\n",
      "12/12 - 0s - loss: 0.0249 - val_loss: 0.0170 - 42ms/epoch - 4ms/step\n",
      "Epoch 69/400\n",
      "12/12 - 0s - loss: 0.0260 - val_loss: 0.0170 - 42ms/epoch - 3ms/step\n",
      "Epoch 70/400\n",
      "12/12 - 0s - loss: 0.0230 - val_loss: 0.0173 - 43ms/epoch - 4ms/step\n",
      "Epoch 71/400\n",
      "12/12 - 0s - loss: 0.0243 - val_loss: 0.0167 - 41ms/epoch - 3ms/step\n",
      "Epoch 72/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0167 - 41ms/epoch - 3ms/step\n",
      "Epoch 73/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0161 - 42ms/epoch - 3ms/step\n",
      "Epoch 74/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0159 - 42ms/epoch - 4ms/step\n",
      "Epoch 75/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0157 - 44ms/epoch - 4ms/step\n",
      "Epoch 76/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0160 - 41ms/epoch - 3ms/step\n",
      "Epoch 77/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 78/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0167 - 41ms/epoch - 3ms/step\n",
      "Epoch 79/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0164 - 41ms/epoch - 3ms/step\n",
      "Epoch 80/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0155 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0153 - 42ms/epoch - 4ms/step\n",
      "Epoch 82/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0147 - 42ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0144 - 41ms/epoch - 3ms/step\n",
      "Epoch 84/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0143 - 41ms/epoch - 3ms/step\n",
      "Epoch 85/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0144 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0143 - 41ms/epoch - 3ms/step\n",
      "Epoch 87/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0139 - 42ms/epoch - 4ms/step\n",
      "Epoch 88/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0137 - 42ms/epoch - 3ms/step\n",
      "Epoch 89/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0138 - 41ms/epoch - 3ms/step\n",
      "Epoch 90/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0139 - 41ms/epoch - 3ms/step\n",
      "Epoch 91/400\n",
      "12/12 - 0s - loss: 0.0237 - val_loss: 0.0135 - 42ms/epoch - 3ms/step\n",
      "Epoch 92/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0139 - 41ms/epoch - 3ms/step\n",
      "Epoch 93/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0135 - 41ms/epoch - 3ms/step\n",
      "Epoch 94/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0138 - 41ms/epoch - 3ms/step\n",
      "Epoch 95/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0133 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0131 - 39ms/epoch - 3ms/step\n",
      "Epoch 97/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0129 - 38ms/epoch - 3ms/step\n",
      "Epoch 98/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0129 - 38ms/epoch - 3ms/step\n",
      "Epoch 99/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0128 - 39ms/epoch - 3ms/step\n",
      "Epoch 100/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0128 - 39ms/epoch - 3ms/step\n",
      "Epoch 101/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0131 - 42ms/epoch - 4ms/step\n",
      "Epoch 102/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0124 - 42ms/epoch - 3ms/step\n",
      "Epoch 103/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0121 - 42ms/epoch - 4ms/step\n",
      "Epoch 104/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0124 - 42ms/epoch - 3ms/step\n",
      "Epoch 105/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0121 - 40ms/epoch - 3ms/step\n",
      "Epoch 106/400\n",
      "12/12 - 0s - loss: 0.0196 - val_loss: 0.0118 - 42ms/epoch - 4ms/step\n",
      "Epoch 107/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0118 - 74ms/epoch - 6ms/step\n",
      "Epoch 108/400\n",
      "12/12 - 0s - loss: 0.0179 - val_loss: 0.0117 - 41ms/epoch - 3ms/step\n",
      "Epoch 109/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0120 - 41ms/epoch - 3ms/step\n",
      "Epoch 110/400\n",
      "12/12 - 0s - loss: 0.0181 - val_loss: 0.0118 - 42ms/epoch - 3ms/step\n",
      "Epoch 111/400\n",
      "12/12 - 0s - loss: 0.0181 - val_loss: 0.0114 - 50ms/epoch - 4ms/step\n",
      "Epoch 112/400\n",
      "12/12 - 0s - loss: 0.0166 - val_loss: 0.0112 - 42ms/epoch - 4ms/step\n",
      "Epoch 113/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0111 - 41ms/epoch - 3ms/step\n",
      "Epoch 114/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0113 - 42ms/epoch - 3ms/step\n",
      "Epoch 115/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0111 - 43ms/epoch - 4ms/step\n",
      "Epoch 116/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0110 - 42ms/epoch - 4ms/step\n",
      "Epoch 117/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0109 - 43ms/epoch - 4ms/step\n",
      "Epoch 118/400\n",
      "12/12 - 0s - loss: 0.0178 - val_loss: 0.0107 - 42ms/epoch - 4ms/step\n",
      "Epoch 119/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0106 - 42ms/epoch - 4ms/step\n",
      "Epoch 120/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0107 - 46ms/epoch - 4ms/step\n",
      "Epoch 121/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0106 - 42ms/epoch - 3ms/step\n",
      "Epoch 122/400\n",
      "12/12 - 0s - loss: 0.0182 - val_loss: 0.0106 - 41ms/epoch - 3ms/step\n",
      "Epoch 123/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0107 - 42ms/epoch - 3ms/step\n",
      "Epoch 124/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0105 - 42ms/epoch - 4ms/step\n",
      "Epoch 125/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0104 - 42ms/epoch - 3ms/step\n",
      "Epoch 126/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0103 - 42ms/epoch - 3ms/step\n",
      "Epoch 127/400\n",
      "12/12 - 0s - loss: 0.0184 - val_loss: 0.0103 - 41ms/epoch - 3ms/step\n",
      "Epoch 128/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0103 - 43ms/epoch - 4ms/step\n",
      "Epoch 129/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0104 - 50ms/epoch - 4ms/step\n",
      "Epoch 130/400\n",
      "12/12 - 0s - loss: 0.0182 - val_loss: 0.0106 - 43ms/epoch - 4ms/step\n",
      "Epoch 131/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0102 - 41ms/epoch - 3ms/step\n",
      "Epoch 132/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0102 - 41ms/epoch - 3ms/step\n",
      "Epoch 133/400\n",
      "12/12 - 0s - loss: 0.0167 - val_loss: 0.0102 - 42ms/epoch - 4ms/step\n",
      "Epoch 134/400\n",
      "12/12 - 0s - loss: 0.0178 - val_loss: 0.0101 - 45ms/epoch - 4ms/step\n",
      "Epoch 135/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0102 - 43ms/epoch - 4ms/step\n",
      "Epoch 136/400\n",
      "12/12 - 0s - loss: 0.0172 - val_loss: 0.0107 - 43ms/epoch - 4ms/step\n",
      "Epoch 137/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0106 - 40ms/epoch - 3ms/step\n",
      "Epoch 138/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0100 - 40ms/epoch - 3ms/step\n",
      "Epoch 139/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0102 - 40ms/epoch - 3ms/step\n",
      "Epoch 140/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0102 - 40ms/epoch - 3ms/step\n",
      "Epoch 141/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0101 - 40ms/epoch - 3ms/step\n",
      "Epoch 142/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0102 - 38ms/epoch - 3ms/step\n",
      "Epoch 143/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0100 - 38ms/epoch - 3ms/step\n",
      "Epoch 144/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0098 - 40ms/epoch - 3ms/step\n",
      "Epoch 145/400\n",
      "12/12 - 0s - loss: 0.0181 - val_loss: 0.0096 - 40ms/epoch - 3ms/step\n",
      "Epoch 146/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0098 - 43ms/epoch - 4ms/step\n",
      "Epoch 147/400\n",
      "12/12 - 0s - loss: 0.0177 - val_loss: 0.0096 - 43ms/epoch - 4ms/step\n",
      "Epoch 148/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0098 - 40ms/epoch - 3ms/step\n",
      "Epoch 149/400\n",
      "12/12 - 0s - loss: 0.0184 - val_loss: 0.0098 - 42ms/epoch - 4ms/step\n",
      "Epoch 150/400\n",
      "12/12 - 0s - loss: 0.0182 - val_loss: 0.0098 - 41ms/epoch - 3ms/step\n",
      "Epoch 151/400\n",
      "12/12 - 0s - loss: 0.0182 - val_loss: 0.0095 - 42ms/epoch - 4ms/step\n",
      "Epoch 152/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0098 - 43ms/epoch - 4ms/step\n",
      "Epoch 153/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0095 - 43ms/epoch - 4ms/step\n",
      "Epoch 154/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0092 - 43ms/epoch - 4ms/step\n",
      "Epoch 155/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0094 - 42ms/epoch - 3ms/step\n",
      "Epoch 156/400\n",
      "12/12 - 0s - loss: 0.0171 - val_loss: 0.0090 - 42ms/epoch - 4ms/step\n",
      "Epoch 157/400\n",
      "12/12 - 0s - loss: 0.0153 - val_loss: 0.0092 - 56ms/epoch - 5ms/step\n",
      "Epoch 158/400\n",
      "12/12 - 0s - loss: 0.0167 - val_loss: 0.0092 - 41ms/epoch - 3ms/step\n",
      "Epoch 159/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0092 - 41ms/epoch - 3ms/step\n",
      "Epoch 160/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0091 - 42ms/epoch - 3ms/step\n",
      "Epoch 161/400\n",
      "12/12 - 0s - loss: 0.0169 - val_loss: 0.0093 - 42ms/epoch - 4ms/step\n",
      "Epoch 162/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0093 - 42ms/epoch - 4ms/step\n",
      "Epoch 163/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0097 - 43ms/epoch - 4ms/step\n",
      "Epoch 164/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0099 - 43ms/epoch - 4ms/step\n",
      "Epoch 165/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0103 - 42ms/epoch - 4ms/step\n",
      "Epoch 166/400\n",
      "12/12 - 0s - loss: 0.0175 - val_loss: 0.0099 - 41ms/epoch - 3ms/step\n",
      "Epoch 167/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0099 - 42ms/epoch - 3ms/step\n",
      "Epoch 168/400\n",
      "12/12 - 0s - loss: 0.0165 - val_loss: 0.0096 - 43ms/epoch - 4ms/step\n",
      "Epoch 169/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0094 - 42ms/epoch - 3ms/step\n",
      "Epoch 170/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0092 - 46ms/epoch - 4ms/step\n",
      "Epoch 171/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0092 - 43ms/epoch - 4ms/step\n",
      "Epoch 172/400\n",
      "12/12 - 0s - loss: 0.0154 - val_loss: 0.0093 - 42ms/epoch - 3ms/step\n",
      "Epoch 173/400\n",
      "12/12 - 0s - loss: 0.0172 - val_loss: 0.0091 - 41ms/epoch - 3ms/step\n",
      "Epoch 174/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0098 - 45ms/epoch - 4ms/step\n",
      "Epoch 175/400\n",
      "12/12 - 0s - loss: 0.0166 - val_loss: 0.0096 - 42ms/epoch - 3ms/step\n",
      "Epoch 176/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0091 - 43ms/epoch - 4ms/step\n",
      "Epoch 177/400\n",
      "12/12 - 0s - loss: 0.0154 - val_loss: 0.0088 - 42ms/epoch - 3ms/step\n",
      "Epoch 178/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0088 - 42ms/epoch - 3ms/step\n",
      "Epoch 179/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0090 - 44ms/epoch - 4ms/step\n",
      "Epoch 180/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0089 - 43ms/epoch - 4ms/step\n",
      "Epoch 181/400\n",
      "12/12 - 0s - loss: 0.0163 - val_loss: 0.0090 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0088 - 42ms/epoch - 4ms/step\n",
      "Epoch 183/400\n",
      "12/12 - 0s - loss: 0.0168 - val_loss: 0.0089 - 43ms/epoch - 4ms/step\n",
      "Epoch 184/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0086 - 40ms/epoch - 3ms/step\n",
      "Epoch 185/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0086 - 40ms/epoch - 3ms/step\n",
      "Epoch 186/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0087 - 39ms/epoch - 3ms/step\n",
      "Epoch 187/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0090 - 39ms/epoch - 3ms/step\n",
      "Epoch 188/400\n",
      "12/12 - 0s - loss: 0.0153 - val_loss: 0.0090 - 43ms/epoch - 4ms/step\n",
      "Epoch 189/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0085 - 41ms/epoch - 3ms/step\n",
      "Epoch 190/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0084 - 40ms/epoch - 3ms/step\n",
      "Epoch 191/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0081 - 40ms/epoch - 3ms/step\n",
      "Epoch 192/400\n",
      "12/12 - 0s - loss: 0.0160 - val_loss: 0.0082 - 41ms/epoch - 3ms/step\n",
      "Epoch 193/400\n",
      "12/12 - 0s - loss: 0.0149 - val_loss: 0.0083 - 41ms/epoch - 3ms/step\n",
      "Epoch 194/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0083 - 41ms/epoch - 3ms/step\n",
      "Epoch 195/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0082 - 41ms/epoch - 3ms/step\n",
      "Epoch 196/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0083 - 42ms/epoch - 3ms/step\n",
      "Epoch 197/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0083 - 44ms/epoch - 4ms/step\n",
      "Epoch 198/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0081 - 41ms/epoch - 3ms/step\n",
      "Epoch 199/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 200/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 201/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0082 - 44ms/epoch - 4ms/step\n",
      "Epoch 202/400\n",
      "12/12 - 0s - loss: 0.0157 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 203/400\n",
      "12/12 - 0s - loss: 0.0173 - val_loss: 0.0082 - 43ms/epoch - 4ms/step\n",
      "Epoch 204/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 205/400\n",
      "12/12 - 0s - loss: 0.0154 - val_loss: 0.0081 - 41ms/epoch - 3ms/step\n",
      "Epoch 206/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0081 - 42ms/epoch - 3ms/step\n",
      "Epoch 207/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0081 - 49ms/epoch - 4ms/step\n",
      "Epoch 208/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0080 - 42ms/epoch - 4ms/step\n",
      "Epoch 209/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 210/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0081 - 43ms/epoch - 4ms/step\n",
      "Epoch 211/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0079 - 43ms/epoch - 4ms/step\n",
      "Epoch 212/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0079 - 42ms/epoch - 4ms/step\n",
      "Epoch 213/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0079 - 41ms/epoch - 3ms/step\n",
      "Epoch 214/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0086 - 43ms/epoch - 4ms/step\n",
      "Epoch 215/400\n",
      "12/12 - 0s - loss: 0.0167 - val_loss: 0.0082 - 41ms/epoch - 3ms/step\n",
      "Epoch 216/400\n",
      "12/12 - 0s - loss: 0.0155 - val_loss: 0.0080 - 41ms/epoch - 3ms/step\n",
      "Epoch 217/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0079 - 42ms/epoch - 4ms/step\n",
      "Epoch 218/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0077 - 46ms/epoch - 4ms/step\n",
      "Epoch 219/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0077 - 42ms/epoch - 4ms/step\n",
      "Epoch 220/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0080 - 42ms/epoch - 3ms/step\n",
      "Epoch 221/400\n",
      "12/12 - 0s - loss: 0.0156 - val_loss: 0.0078 - 42ms/epoch - 3ms/step\n",
      "Epoch 222/400\n",
      "12/12 - 0s - loss: 0.0161 - val_loss: 0.0080 - 42ms/epoch - 3ms/step\n",
      "Epoch 223/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0074 - 42ms/epoch - 4ms/step\n",
      "Epoch 224/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0077 - 43ms/epoch - 4ms/step\n",
      "Epoch 225/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0076 - 44ms/epoch - 4ms/step\n",
      "Epoch 226/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0076 - 43ms/epoch - 4ms/step\n",
      "Epoch 227/400\n",
      "12/12 - 0s - loss: 0.0144 - val_loss: 0.0077 - 40ms/epoch - 3ms/step\n",
      "Epoch 228/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0077 - 42ms/epoch - 3ms/step\n",
      "Epoch 229/400\n",
      "12/12 - 0s - loss: 0.0146 - val_loss: 0.0075 - 42ms/epoch - 4ms/step\n",
      "Epoch 230/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0074 - 40ms/epoch - 3ms/step\n",
      "Epoch 231/400\n",
      "12/12 - 0s - loss: 0.0151 - val_loss: 0.0075 - 39ms/epoch - 3ms/step\n",
      "Epoch 232/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0074 - 40ms/epoch - 3ms/step\n",
      "Epoch 233/400\n",
      "12/12 - 0s - loss: 0.0147 - val_loss: 0.0077 - 40ms/epoch - 3ms/step\n",
      "Epoch 234/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0075 - 39ms/epoch - 3ms/step\n",
      "Epoch 235/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0073 - 39ms/epoch - 3ms/step\n",
      "Epoch 236/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0075 - 41ms/epoch - 3ms/step\n",
      "Epoch 237/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0075 - 53ms/epoch - 4ms/step\n",
      "Epoch 238/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0078 - 42ms/epoch - 3ms/step\n",
      "Epoch 239/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0075 - 41ms/epoch - 3ms/step\n",
      "Epoch 240/400\n",
      "12/12 - 0s - loss: 0.0153 - val_loss: 0.0073 - 42ms/epoch - 3ms/step\n",
      "Epoch 241/400\n",
      "12/12 - 0s - loss: 0.0148 - val_loss: 0.0073 - 42ms/epoch - 4ms/step\n",
      "Epoch 242/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0078 - 42ms/epoch - 4ms/step\n",
      "Epoch 243/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0078 - 43ms/epoch - 4ms/step\n",
      "Epoch 244/400\n",
      "12/12 - 0s - loss: 0.0145 - val_loss: 0.0072 - 49ms/epoch - 4ms/step\n",
      "Epoch 245/400\n",
      "12/12 - 0s - loss: 0.0158 - val_loss: 0.0075 - 51ms/epoch - 4ms/step\n",
      "Epoch 246/400\n",
      "12/12 - 0s - loss: 0.0143 - val_loss: 0.0074 - 48ms/epoch - 4ms/step\n",
      "Epoch 247/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0075 - 48ms/epoch - 4ms/step\n",
      "Epoch 248/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0072 - 42ms/epoch - 3ms/step\n",
      "Epoch 249/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0067 - 40ms/epoch - 3ms/step\n",
      "Epoch 250/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0069 - 41ms/epoch - 3ms/step\n",
      "Epoch 251/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0068 - 44ms/epoch - 4ms/step\n",
      "Epoch 252/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0066 - 44ms/epoch - 4ms/step\n",
      "Epoch 253/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0068 - 43ms/epoch - 4ms/step\n",
      "Epoch 254/400\n",
      "12/12 - 0s - loss: 0.0152 - val_loss: 0.0072 - 41ms/epoch - 3ms/step\n",
      "Epoch 255/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0074 - 42ms/epoch - 3ms/step\n",
      "Epoch 256/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0069 - 42ms/epoch - 3ms/step\n",
      "Epoch 257/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0070 - 43ms/epoch - 4ms/step\n",
      "Epoch 258/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0070 - 43ms/epoch - 4ms/step\n",
      "Epoch 259/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0067 - 42ms/epoch - 3ms/step\n",
      "Epoch 260/400\n",
      "12/12 - 0s - loss: 0.0133 - val_loss: 0.0072 - 43ms/epoch - 4ms/step\n",
      "Epoch 261/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0069 - 46ms/epoch - 4ms/step\n",
      "Epoch 262/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0068 - 42ms/epoch - 4ms/step\n",
      "Epoch 263/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0067 - 43ms/epoch - 4ms/step\n",
      "Epoch 264/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0068 - 42ms/epoch - 4ms/step\n",
      "Epoch 265/400\n",
      "12/12 - 0s - loss: 0.0150 - val_loss: 0.0066 - 44ms/epoch - 4ms/step\n",
      "Epoch 266/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0067 - 43ms/epoch - 4ms/step\n",
      "Epoch 267/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0067 - 42ms/epoch - 4ms/step\n",
      "Epoch 268/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0066 - 41ms/epoch - 3ms/step\n",
      "Epoch 269/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0069 - 41ms/epoch - 3ms/step\n",
      "Epoch 270/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0069 - 41ms/epoch - 3ms/step\n",
      "Epoch 271/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0069 - 42ms/epoch - 4ms/step\n",
      "Epoch 272/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0065 - 42ms/epoch - 3ms/step\n",
      "Epoch 273/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 274/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0064 - 43ms/epoch - 4ms/step\n",
      "Epoch 275/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0067 - 41ms/epoch - 3ms/step\n",
      "Epoch 276/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0066 - 39ms/epoch - 3ms/step\n",
      "Epoch 277/400\n",
      "12/12 - 0s - loss: 0.0132 - val_loss: 0.0063 - 40ms/epoch - 3ms/step\n",
      "Epoch 278/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0066 - 39ms/epoch - 3ms/step\n",
      "Epoch 279/400\n",
      "12/12 - 0s - loss: 0.0137 - val_loss: 0.0063 - 39ms/epoch - 3ms/step\n",
      "Epoch 280/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0064 - 39ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/400\n",
      "12/12 - 0s - loss: 0.0138 - val_loss: 0.0064 - 39ms/epoch - 3ms/step\n",
      "Epoch 282/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0063 - 41ms/epoch - 3ms/step\n",
      "Epoch 283/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0066 - 42ms/epoch - 4ms/step\n",
      "Epoch 284/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0062 - 41ms/epoch - 3ms/step\n",
      "Epoch 285/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0061 - 41ms/epoch - 3ms/step\n",
      "Epoch 286/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0061 - 42ms/epoch - 3ms/step\n",
      "Epoch 287/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 288/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 289/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 290/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 291/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 292/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0061 - 44ms/epoch - 4ms/step\n",
      "Epoch 293/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 294/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 295/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 296/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0061 - 43ms/epoch - 4ms/step\n",
      "Epoch 297/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0056 - 42ms/epoch - 3ms/step\n",
      "Epoch 298/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 299/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0060 - 42ms/epoch - 4ms/step\n",
      "Epoch 300/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0060 - 54ms/epoch - 5ms/step\n",
      "Epoch 301/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0057 - 41ms/epoch - 3ms/step\n",
      "Epoch 302/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0059 - 41ms/epoch - 3ms/step\n",
      "Epoch 303/400\n",
      "12/12 - 0s - loss: 0.0127 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 304/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0061 - 42ms/epoch - 4ms/step\n",
      "Epoch 305/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0059 - 42ms/epoch - 4ms/step\n",
      "Epoch 306/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 307/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 308/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 309/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0055 - 41ms/epoch - 3ms/step\n",
      "Epoch 310/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0058 - 43ms/epoch - 4ms/step\n",
      "Epoch 311/400\n",
      "12/12 - 0s - loss: 0.0131 - val_loss: 0.0057 - 46ms/epoch - 4ms/step\n",
      "Epoch 312/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0059 - 43ms/epoch - 4ms/step\n",
      "Epoch 313/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0061 - 41ms/epoch - 3ms/step\n",
      "Epoch 314/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0058 - 43ms/epoch - 4ms/step\n",
      "Epoch 315/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0053 - 45ms/epoch - 4ms/step\n",
      "Epoch 316/400\n",
      "12/12 - 0s - loss: 0.0130 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 317/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0059 - 40ms/epoch - 3ms/step\n",
      "Epoch 318/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0062 - 41ms/epoch - 3ms/step\n",
      "Epoch 319/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0058 - 42ms/epoch - 4ms/step\n",
      "Epoch 320/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0057 - 41ms/epoch - 3ms/step\n",
      "Epoch 321/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0058 - 40ms/epoch - 3ms/step\n",
      "Epoch 322/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0060 - 40ms/epoch - 3ms/step\n",
      "Epoch 323/400\n",
      "12/12 - 0s - loss: 0.0141 - val_loss: 0.0059 - 41ms/epoch - 3ms/step\n",
      "Epoch 324/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0061 - 38ms/epoch - 3ms/step\n",
      "Epoch 325/400\n",
      "12/12 - 0s - loss: 0.0140 - val_loss: 0.0063 - 40ms/epoch - 3ms/step\n",
      "Epoch 326/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0061 - 40ms/epoch - 3ms/step\n",
      "Epoch 327/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0063 - 39ms/epoch - 3ms/step\n",
      "Epoch 328/400\n",
      "12/12 - 0s - loss: 0.0120 - val_loss: 0.0065 - 42ms/epoch - 4ms/step\n",
      "Epoch 329/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0062 - 41ms/epoch - 3ms/step\n",
      "Epoch 330/400\n",
      "12/12 - 0s - loss: 0.0135 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 331/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0060 - 43ms/epoch - 4ms/step\n",
      "Epoch 332/400\n",
      "12/12 - 0s - loss: 0.0139 - val_loss: 0.0063 - 42ms/epoch - 3ms/step\n",
      "Epoch 333/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0060 - 44ms/epoch - 4ms/step\n",
      "Epoch 334/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0055 - 45ms/epoch - 4ms/step\n",
      "Epoch 335/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0057 - 42ms/epoch - 4ms/step\n",
      "Epoch 336/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0056 - 42ms/epoch - 3ms/step\n",
      "Epoch 337/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 338/400\n",
      "12/12 - 0s - loss: 0.0104 - val_loss: 0.0057 - 41ms/epoch - 3ms/step\n",
      "Epoch 339/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 340/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0056 - 41ms/epoch - 3ms/step\n",
      "Epoch 341/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0053 - 42ms/epoch - 3ms/step\n",
      "Epoch 342/400\n",
      "12/12 - 0s - loss: 0.0134 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 343/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0057 - 43ms/epoch - 4ms/step\n",
      "Epoch 344/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 345/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0056 - 44ms/epoch - 4ms/step\n",
      "Epoch 346/400\n",
      "12/12 - 0s - loss: 0.0142 - val_loss: 0.0053 - 46ms/epoch - 4ms/step\n",
      "Epoch 347/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0062 - 42ms/epoch - 3ms/step\n",
      "Epoch 348/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0059 - 42ms/epoch - 3ms/step\n",
      "Epoch 349/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0056 - 41ms/epoch - 3ms/step\n",
      "Epoch 350/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 351/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 352/400\n",
      "12/12 - 0s - loss: 0.0106 - val_loss: 0.0054 - 45ms/epoch - 4ms/step\n",
      "Epoch 353/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 354/400\n",
      "12/12 - 0s - loss: 0.0100 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 355/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0052 - 43ms/epoch - 4ms/step\n",
      "Epoch 356/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0053 - 42ms/epoch - 3ms/step\n",
      "Epoch 357/400\n",
      "12/12 - 0s - loss: 0.0105 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 358/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 359/400\n",
      "12/12 - 0s - loss: 0.0126 - val_loss: 0.0054 - 42ms/epoch - 3ms/step\n",
      "Epoch 360/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 361/400\n",
      "12/12 - 0s - loss: 0.0129 - val_loss: 0.0052 - 44ms/epoch - 4ms/step\n",
      "Epoch 362/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 363/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 364/400\n",
      "12/12 - 0s - loss: 0.0107 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 365/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 366/400\n",
      "12/12 - 0s - loss: 0.0124 - val_loss: 0.0054 - 40ms/epoch - 3ms/step\n",
      "Epoch 367/400\n",
      "12/12 - 0s - loss: 0.0121 - val_loss: 0.0057 - 39ms/epoch - 3ms/step\n",
      "Epoch 368/400\n",
      "12/12 - 0s - loss: 0.0128 - val_loss: 0.0056 - 40ms/epoch - 3ms/step\n",
      "Epoch 369/400\n",
      "12/12 - 0s - loss: 0.0122 - val_loss: 0.0055 - 40ms/epoch - 3ms/step\n",
      "Epoch 370/400\n",
      "12/12 - 0s - loss: 0.0115 - val_loss: 0.0054 - 40ms/epoch - 3ms/step\n",
      "Epoch 371/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0055 - 40ms/epoch - 3ms/step\n",
      "Epoch 372/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0054 - 38ms/epoch - 3ms/step\n",
      "Epoch 373/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0051 - 40ms/epoch - 3ms/step\n",
      "Epoch 374/400\n",
      "12/12 - 0s - loss: 0.0117 - val_loss: 0.0054 - 42ms/epoch - 4ms/step\n",
      "Epoch 375/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 376/400\n",
      "12/12 - 0s - loss: 0.0097 - val_loss: 0.0057 - 44ms/epoch - 4ms/step\n",
      "Epoch 377/400\n",
      "12/12 - 0s - loss: 0.0109 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 378/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 379/400\n",
      "12/12 - 0s - loss: 0.0103 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/400\n",
      "12/12 - 0s - loss: 0.0119 - val_loss: 0.0058 - 42ms/epoch - 3ms/step\n",
      "Epoch 381/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0051 - 42ms/epoch - 3ms/step\n",
      "Epoch 382/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0052 - 41ms/epoch - 3ms/step\n",
      "Epoch 383/400\n",
      "12/12 - 0s - loss: 0.0136 - val_loss: 0.0055 - 43ms/epoch - 4ms/step\n",
      "Epoch 384/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 385/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0053 - 43ms/epoch - 4ms/step\n",
      "Epoch 386/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 387/400\n",
      "12/12 - 0s - loss: 0.0112 - val_loss: 0.0050 - 45ms/epoch - 4ms/step\n",
      "Epoch 388/400\n",
      "12/12 - 0s - loss: 0.0113 - val_loss: 0.0051 - 42ms/epoch - 3ms/step\n",
      "Epoch 389/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 390/400\n",
      "12/12 - 0s - loss: 0.0108 - val_loss: 0.0052 - 42ms/epoch - 3ms/step\n",
      "Epoch 391/400\n",
      "12/12 - 0s - loss: 0.0123 - val_loss: 0.0052 - 42ms/epoch - 4ms/step\n",
      "Epoch 392/400\n",
      "12/12 - 0s - loss: 0.0101 - val_loss: 0.0053 - 42ms/epoch - 4ms/step\n",
      "Epoch 393/400\n",
      "12/12 - 0s - loss: 0.0111 - val_loss: 0.0056 - 43ms/epoch - 4ms/step\n",
      "Epoch 394/400\n",
      "12/12 - 0s - loss: 0.0102 - val_loss: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 395/400\n",
      "12/12 - 0s - loss: 0.0114 - val_loss: 0.0054 - 43ms/epoch - 4ms/step\n",
      "Epoch 396/400\n",
      "12/12 - 0s - loss: 0.0116 - val_loss: 0.0051 - 42ms/epoch - 4ms/step\n",
      "Epoch 397/400\n",
      "12/12 - 0s - loss: 0.0110 - val_loss: 0.0051 - 43ms/epoch - 4ms/step\n",
      "Epoch 398/400\n",
      "12/12 - 0s - loss: 0.0118 - val_loss: 0.0049 - 45ms/epoch - 4ms/step\n",
      "Epoch 399/400\n",
      "12/12 - 0s - loss: 0.0125 - val_loss: 0.0050 - 43ms/epoch - 4ms/step\n",
      "Epoch 400/400\n",
      "12/12 - 0s - loss: 0.0099 - val_loss: 0.0060 - 42ms/epoch - 3ms/step\n",
      "COMPRESSED VECTOR SIZE: 7\n",
      "Loss in the autoencoder: 0.005993738304823637\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Compressed layer size: 3\n",
      "Epoch 1/400\n",
      "12/12 - 1s - loss: 0.6636 - val_loss: 0.2140 - 743ms/epoch - 62ms/step\n",
      "Epoch 2/400\n",
      "12/12 - 0s - loss: 0.4287 - val_loss: 0.2010 - 53ms/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "12/12 - 0s - loss: 0.2785 - val_loss: 0.1920 - 48ms/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "12/12 - 0s - loss: 0.1961 - val_loss: 0.1862 - 45ms/epoch - 4ms/step\n",
      "Epoch 5/400\n",
      "12/12 - 0s - loss: 0.1463 - val_loss: 0.1797 - 42ms/epoch - 4ms/step\n",
      "Epoch 6/400\n",
      "12/12 - 0s - loss: 0.1169 - val_loss: 0.1738 - 46ms/epoch - 4ms/step\n",
      "Epoch 7/400\n",
      "12/12 - 0s - loss: 0.1063 - val_loss: 0.1684 - 45ms/epoch - 4ms/step\n",
      "Epoch 8/400\n",
      "12/12 - 0s - loss: 0.1028 - val_loss: 0.1615 - 45ms/epoch - 4ms/step\n",
      "Epoch 9/400\n",
      "12/12 - 0s - loss: 0.0782 - val_loss: 0.1553 - 42ms/epoch - 3ms/step\n",
      "Epoch 10/400\n",
      "12/12 - 0s - loss: 0.0739 - val_loss: 0.1484 - 42ms/epoch - 4ms/step\n",
      "Epoch 11/400\n",
      "12/12 - 0s - loss: 0.0789 - val_loss: 0.1412 - 42ms/epoch - 4ms/step\n",
      "Epoch 12/400\n",
      "12/12 - 0s - loss: 0.0683 - val_loss: 0.1334 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/400\n",
      "12/12 - 0s - loss: 0.0621 - val_loss: 0.1272 - 43ms/epoch - 4ms/step\n",
      "Epoch 14/400\n",
      "12/12 - 0s - loss: 0.0618 - val_loss: 0.1210 - 47ms/epoch - 4ms/step\n",
      "Epoch 15/400\n",
      "12/12 - 0s - loss: 0.0559 - val_loss: 0.1155 - 42ms/epoch - 4ms/step\n",
      "Epoch 16/400\n",
      "12/12 - 0s - loss: 0.0608 - val_loss: 0.1102 - 42ms/epoch - 4ms/step\n",
      "Epoch 17/400\n",
      "12/12 - 0s - loss: 0.0563 - val_loss: 0.1029 - 42ms/epoch - 4ms/step\n",
      "Epoch 18/400\n",
      "12/12 - 0s - loss: 0.0554 - val_loss: 0.0965 - 42ms/epoch - 3ms/step\n",
      "Epoch 19/400\n",
      "12/12 - 0s - loss: 0.0478 - val_loss: 0.0902 - 41ms/epoch - 3ms/step\n",
      "Epoch 20/400\n",
      "12/12 - 0s - loss: 0.0523 - val_loss: 0.0857 - 43ms/epoch - 4ms/step\n",
      "Epoch 21/400\n",
      "12/12 - 0s - loss: 0.0484 - val_loss: 0.0806 - 42ms/epoch - 3ms/step\n",
      "Epoch 22/400\n",
      "12/12 - 0s - loss: 0.0474 - val_loss: 0.0747 - 45ms/epoch - 4ms/step\n",
      "Epoch 23/400\n",
      "12/12 - 0s - loss: 0.0475 - val_loss: 0.0692 - 42ms/epoch - 4ms/step\n",
      "Epoch 24/400\n",
      "12/12 - 0s - loss: 0.0498 - val_loss: 0.0641 - 42ms/epoch - 3ms/step\n",
      "Epoch 25/400\n",
      "12/12 - 0s - loss: 0.0475 - val_loss: 0.0600 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/400\n",
      "12/12 - 0s - loss: 0.0481 - val_loss: 0.0562 - 41ms/epoch - 3ms/step\n",
      "Epoch 27/400\n",
      "12/12 - 0s - loss: 0.0460 - val_loss: 0.0519 - 42ms/epoch - 3ms/step\n",
      "Epoch 28/400\n",
      "12/12 - 0s - loss: 0.0442 - val_loss: 0.0485 - 42ms/epoch - 3ms/step\n",
      "Epoch 29/400\n",
      "12/12 - 0s - loss: 0.0457 - val_loss: 0.0450 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/400\n",
      "12/12 - 0s - loss: 0.0404 - val_loss: 0.0444 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/400\n",
      "12/12 - 0s - loss: 0.0381 - val_loss: 0.0403 - 43ms/epoch - 4ms/step\n",
      "Epoch 32/400\n",
      "12/12 - 0s - loss: 0.0422 - val_loss: 0.0383 - 42ms/epoch - 4ms/step\n",
      "Epoch 33/400\n",
      "12/12 - 0s - loss: 0.0372 - val_loss: 0.0372 - 41ms/epoch - 3ms/step\n",
      "Epoch 34/400\n",
      "12/12 - 0s - loss: 0.0374 - val_loss: 0.0364 - 39ms/epoch - 3ms/step\n",
      "Epoch 35/400\n",
      "12/12 - 0s - loss: 0.0357 - val_loss: 0.0353 - 39ms/epoch - 3ms/step\n",
      "Epoch 36/400\n",
      "12/12 - 0s - loss: 0.0360 - val_loss: 0.0339 - 39ms/epoch - 3ms/step\n",
      "Epoch 37/400\n",
      "12/12 - 0s - loss: 0.0373 - val_loss: 0.0340 - 39ms/epoch - 3ms/step\n",
      "Epoch 38/400\n",
      "12/12 - 0s - loss: 0.0404 - val_loss: 0.0334 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/400\n",
      "12/12 - 0s - loss: 0.0371 - val_loss: 0.0321 - 38ms/epoch - 3ms/step\n",
      "Epoch 40/400\n",
      "12/12 - 0s - loss: 0.0359 - val_loss: 0.0316 - 38ms/epoch - 3ms/step\n",
      "Epoch 41/400\n",
      "12/12 - 0s - loss: 0.0340 - val_loss: 0.0305 - 40ms/epoch - 3ms/step\n",
      "Epoch 42/400\n",
      "12/12 - 0s - loss: 0.0340 - val_loss: 0.0302 - 43ms/epoch - 4ms/step\n",
      "Epoch 43/400\n",
      "12/12 - 0s - loss: 0.0366 - val_loss: 0.0294 - 41ms/epoch - 3ms/step\n",
      "Epoch 44/400\n",
      "12/12 - 0s - loss: 0.0380 - val_loss: 0.0292 - 40ms/epoch - 3ms/step\n",
      "Epoch 45/400\n",
      "12/12 - 0s - loss: 0.0321 - val_loss: 0.0286 - 41ms/epoch - 3ms/step\n",
      "Epoch 46/400\n",
      "12/12 - 0s - loss: 0.0325 - val_loss: 0.0278 - 43ms/epoch - 4ms/step\n",
      "Epoch 47/400\n",
      "12/12 - 0s - loss: 0.0344 - val_loss: 0.0270 - 43ms/epoch - 4ms/step\n",
      "Epoch 48/400\n",
      "12/12 - 0s - loss: 0.0353 - val_loss: 0.0263 - 50ms/epoch - 4ms/step\n",
      "Epoch 49/400\n",
      "12/12 - 0s - loss: 0.0318 - val_loss: 0.0260 - 41ms/epoch - 3ms/step\n",
      "Epoch 50/400\n",
      "12/12 - 0s - loss: 0.0328 - val_loss: 0.0257 - 41ms/epoch - 3ms/step\n",
      "Epoch 51/400\n",
      "12/12 - 0s - loss: 0.0322 - val_loss: 0.0267 - 40ms/epoch - 3ms/step\n",
      "Epoch 52/400\n",
      "12/12 - 0s - loss: 0.0327 - val_loss: 0.0263 - 43ms/epoch - 4ms/step\n",
      "Epoch 53/400\n",
      "12/12 - 0s - loss: 0.0307 - val_loss: 0.0261 - 42ms/epoch - 4ms/step\n",
      "Epoch 54/400\n",
      "12/12 - 0s - loss: 0.0331 - val_loss: 0.0259 - 42ms/epoch - 4ms/step\n",
      "Epoch 55/400\n",
      "12/12 - 0s - loss: 0.0299 - val_loss: 0.0254 - 41ms/epoch - 3ms/step\n",
      "Epoch 56/400\n",
      "12/12 - 0s - loss: 0.0299 - val_loss: 0.0250 - 42ms/epoch - 4ms/step\n",
      "Epoch 57/400\n",
      "12/12 - 0s - loss: 0.0311 - val_loss: 0.0246 - 42ms/epoch - 4ms/step\n",
      "Epoch 58/400\n",
      "12/12 - 0s - loss: 0.0314 - val_loss: 0.0250 - 44ms/epoch - 4ms/step\n",
      "Epoch 59/400\n",
      "12/12 - 0s - loss: 0.0350 - val_loss: 0.0245 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/400\n",
      "12/12 - 0s - loss: 0.0317 - val_loss: 0.0254 - 41ms/epoch - 3ms/step\n",
      "Epoch 61/400\n",
      "12/12 - 0s - loss: 0.0304 - val_loss: 0.0251 - 41ms/epoch - 3ms/step\n",
      "Epoch 62/400\n",
      "12/12 - 0s - loss: 0.0298 - val_loss: 0.0251 - 40ms/epoch - 3ms/step\n",
      "Epoch 63/400\n",
      "12/12 - 0s - loss: 0.0291 - val_loss: 0.0248 - 42ms/epoch - 3ms/step\n",
      "Epoch 64/400\n",
      "12/12 - 0s - loss: 0.0292 - val_loss: 0.0244 - 43ms/epoch - 4ms/step\n",
      "Epoch 65/400\n",
      "12/12 - 0s - loss: 0.0273 - val_loss: 0.0240 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/400\n",
      "12/12 - 0s - loss: 0.0300 - val_loss: 0.0239 - 42ms/epoch - 4ms/step\n",
      "Epoch 67/400\n",
      "12/12 - 0s - loss: 0.0289 - val_loss: 0.0241 - 43ms/epoch - 4ms/step\n",
      "Epoch 68/400\n",
      "12/12 - 0s - loss: 0.0283 - val_loss: 0.0240 - 41ms/epoch - 3ms/step\n",
      "Epoch 69/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0235 - 41ms/epoch - 3ms/step\n",
      "Epoch 70/400\n",
      "12/12 - 0s - loss: 0.0265 - val_loss: 0.0232 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/400\n",
      "12/12 - 0s - loss: 0.0292 - val_loss: 0.0230 - 43ms/epoch - 4ms/step\n",
      "Epoch 72/400\n",
      "12/12 - 0s - loss: 0.0302 - val_loss: 0.0228 - 43ms/epoch - 4ms/step\n",
      "Epoch 73/400\n",
      "12/12 - 0s - loss: 0.0292 - val_loss: 0.0231 - 47ms/epoch - 4ms/step\n",
      "Epoch 74/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0229 - 41ms/epoch - 3ms/step\n",
      "Epoch 75/400\n",
      "12/12 - 0s - loss: 0.0267 - val_loss: 0.0230 - 40ms/epoch - 3ms/step\n",
      "Epoch 76/400\n",
      "12/12 - 0s - loss: 0.0295 - val_loss: 0.0228 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0228 - 41ms/epoch - 3ms/step\n",
      "Epoch 78/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0226 - 40ms/epoch - 3ms/step\n",
      "Epoch 79/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0223 - 41ms/epoch - 3ms/step\n",
      "Epoch 80/400\n",
      "12/12 - 0s - loss: 0.0265 - val_loss: 0.0219 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/400\n",
      "12/12 - 0s - loss: 0.0284 - val_loss: 0.0216 - 39ms/epoch - 3ms/step\n",
      "Epoch 82/400\n",
      "12/12 - 0s - loss: 0.0292 - val_loss: 0.0213 - 38ms/epoch - 3ms/step\n",
      "Epoch 83/400\n",
      "12/12 - 0s - loss: 0.0259 - val_loss: 0.0214 - 38ms/epoch - 3ms/step\n",
      "Epoch 84/400\n",
      "12/12 - 0s - loss: 0.0256 - val_loss: 0.0213 - 39ms/epoch - 3ms/step\n",
      "Epoch 85/400\n",
      "12/12 - 0s - loss: 0.0274 - val_loss: 0.0209 - 40ms/epoch - 3ms/step\n",
      "Epoch 86/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0209 - 40ms/epoch - 3ms/step\n",
      "Epoch 87/400\n",
      "12/12 - 0s - loss: 0.0255 - val_loss: 0.0212 - 39ms/epoch - 3ms/step\n",
      "Epoch 88/400\n",
      "12/12 - 0s - loss: 0.0270 - val_loss: 0.0215 - 40ms/epoch - 3ms/step\n",
      "Epoch 89/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0213 - 41ms/epoch - 3ms/step\n",
      "Epoch 90/400\n",
      "12/12 - 0s - loss: 0.0303 - val_loss: 0.0211 - 40ms/epoch - 3ms/step\n",
      "Epoch 91/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0211 - 42ms/epoch - 3ms/step\n",
      "Epoch 92/400\n",
      "12/12 - 0s - loss: 0.0256 - val_loss: 0.0211 - 41ms/epoch - 3ms/step\n",
      "Epoch 93/400\n",
      "12/12 - 0s - loss: 0.0259 - val_loss: 0.0214 - 43ms/epoch - 4ms/step\n",
      "Epoch 94/400\n",
      "12/12 - 0s - loss: 0.0249 - val_loss: 0.0206 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/400\n",
      "12/12 - 0s - loss: 0.0248 - val_loss: 0.0206 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0211 - 44ms/epoch - 4ms/step\n",
      "Epoch 97/400\n",
      "12/12 - 0s - loss: 0.0245 - val_loss: 0.0203 - 42ms/epoch - 4ms/step\n",
      "Epoch 98/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0208 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/400\n",
      "12/12 - 0s - loss: 0.0258 - val_loss: 0.0204 - 43ms/epoch - 4ms/step\n",
      "Epoch 100/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0198 - 41ms/epoch - 3ms/step\n",
      "Epoch 101/400\n",
      "12/12 - 0s - loss: 0.0272 - val_loss: 0.0203 - 41ms/epoch - 3ms/step\n",
      "Epoch 102/400\n",
      "12/12 - 0s - loss: 0.0269 - val_loss: 0.0205 - 43ms/epoch - 4ms/step\n",
      "Epoch 103/400\n",
      "12/12 - 0s - loss: 0.0276 - val_loss: 0.0203 - 41ms/epoch - 3ms/step\n",
      "Epoch 104/400\n",
      "12/12 - 0s - loss: 0.0253 - val_loss: 0.0202 - 42ms/epoch - 4ms/step\n",
      "Epoch 105/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0199 - 43ms/epoch - 4ms/step\n",
      "Epoch 106/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0199 - 40ms/epoch - 3ms/step\n",
      "Epoch 107/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0193 - 42ms/epoch - 4ms/step\n",
      "Epoch 108/400\n",
      "12/12 - 0s - loss: 0.0243 - val_loss: 0.0194 - 41ms/epoch - 3ms/step\n",
      "Epoch 109/400\n",
      "12/12 - 0s - loss: 0.0256 - val_loss: 0.0196 - 43ms/epoch - 4ms/step\n",
      "Epoch 110/400\n",
      "12/12 - 0s - loss: 0.0244 - val_loss: 0.0197 - 41ms/epoch - 3ms/step\n",
      "Epoch 111/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0199 - 41ms/epoch - 3ms/step\n",
      "Epoch 112/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0193 - 42ms/epoch - 3ms/step\n",
      "Epoch 113/400\n",
      "12/12 - 0s - loss: 0.0249 - val_loss: 0.0193 - 42ms/epoch - 3ms/step\n",
      "Epoch 114/400\n",
      "12/12 - 0s - loss: 0.0251 - val_loss: 0.0193 - 41ms/epoch - 3ms/step\n",
      "Epoch 115/400\n",
      "12/12 - 0s - loss: 0.0250 - val_loss: 0.0194 - 42ms/epoch - 3ms/step\n",
      "Epoch 116/400\n",
      "12/12 - 0s - loss: 0.0272 - val_loss: 0.0199 - 41ms/epoch - 3ms/step\n",
      "Epoch 117/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0193 - 42ms/epoch - 4ms/step\n",
      "Epoch 118/400\n",
      "12/12 - 0s - loss: 0.0237 - val_loss: 0.0194 - 41ms/epoch - 3ms/step\n",
      "Epoch 119/400\n",
      "12/12 - 0s - loss: 0.0254 - val_loss: 0.0191 - 43ms/epoch - 4ms/step\n",
      "Epoch 120/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0189 - 42ms/epoch - 3ms/step\n",
      "Epoch 121/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0189 - 40ms/epoch - 3ms/step\n",
      "Epoch 122/400\n",
      "12/12 - 0s - loss: 0.0266 - val_loss: 0.0188 - 41ms/epoch - 3ms/step\n",
      "Epoch 123/400\n",
      "12/12 - 0s - loss: 0.0239 - val_loss: 0.0189 - 43ms/epoch - 4ms/step\n",
      "Epoch 124/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0188 - 42ms/epoch - 3ms/step\n",
      "Epoch 125/400\n",
      "12/12 - 0s - loss: 0.0268 - val_loss: 0.0188 - 43ms/epoch - 4ms/step\n",
      "Epoch 126/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0186 - 42ms/epoch - 3ms/step\n",
      "Epoch 127/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0189 - 41ms/epoch - 3ms/step\n",
      "Epoch 128/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0187 - 40ms/epoch - 3ms/step\n",
      "Epoch 129/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0187 - 41ms/epoch - 3ms/step\n",
      "Epoch 130/400\n",
      "12/12 - 0s - loss: 0.0239 - val_loss: 0.0183 - 39ms/epoch - 3ms/step\n",
      "Epoch 131/400\n",
      "12/12 - 0s - loss: 0.0239 - val_loss: 0.0187 - 38ms/epoch - 3ms/step\n",
      "Epoch 132/400\n",
      "12/12 - 0s - loss: 0.0252 - val_loss: 0.0186 - 38ms/epoch - 3ms/step\n",
      "Epoch 133/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0182 - 40ms/epoch - 3ms/step\n",
      "Epoch 134/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0184 - 40ms/epoch - 3ms/step\n",
      "Epoch 135/400\n",
      "12/12 - 0s - loss: 0.0280 - val_loss: 0.0181 - 46ms/epoch - 4ms/step\n",
      "Epoch 136/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0185 - 42ms/epoch - 4ms/step\n",
      "Epoch 137/400\n",
      "12/12 - 0s - loss: 0.0248 - val_loss: 0.0182 - 42ms/epoch - 3ms/step\n",
      "Epoch 138/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0180 - 42ms/epoch - 4ms/step\n",
      "Epoch 139/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0182 - 42ms/epoch - 4ms/step\n",
      "Epoch 140/400\n",
      "12/12 - 0s - loss: 0.0237 - val_loss: 0.0177 - 41ms/epoch - 3ms/step\n",
      "Epoch 141/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0175 - 41ms/epoch - 3ms/step\n",
      "Epoch 142/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0174 - 41ms/epoch - 3ms/step\n",
      "Epoch 143/400\n",
      "12/12 - 0s - loss: 0.0232 - val_loss: 0.0180 - 41ms/epoch - 3ms/step\n",
      "Epoch 144/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0177 - 42ms/epoch - 3ms/step\n",
      "Epoch 145/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0173 - 41ms/epoch - 3ms/step\n",
      "Epoch 146/400\n",
      "12/12 - 0s - loss: 0.0239 - val_loss: 0.0173 - 43ms/epoch - 4ms/step\n",
      "Epoch 147/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0173 - 42ms/epoch - 3ms/step\n",
      "Epoch 148/400\n",
      "12/12 - 0s - loss: 0.0253 - val_loss: 0.0173 - 42ms/epoch - 4ms/step\n",
      "Epoch 149/400\n",
      "12/12 - 0s - loss: 0.0248 - val_loss: 0.0175 - 41ms/epoch - 3ms/step\n",
      "Epoch 150/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0172 - 41ms/epoch - 3ms/step\n",
      "Epoch 151/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0173 - 42ms/epoch - 3ms/step\n",
      "Epoch 152/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0174 - 44ms/epoch - 4ms/step\n",
      "Epoch 153/400\n",
      "12/12 - 0s - loss: 0.0240 - val_loss: 0.0172 - 42ms/epoch - 3ms/step\n",
      "Epoch 154/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0176 - 43ms/epoch - 4ms/step\n",
      "Epoch 155/400\n",
      "12/12 - 0s - loss: 0.0257 - val_loss: 0.0178 - 41ms/epoch - 3ms/step\n",
      "Epoch 156/400\n",
      "12/12 - 0s - loss: 0.0243 - val_loss: 0.0182 - 41ms/epoch - 3ms/step\n",
      "Epoch 157/400\n",
      "12/12 - 0s - loss: 0.0255 - val_loss: 0.0180 - 42ms/epoch - 3ms/step\n",
      "Epoch 158/400\n",
      "12/12 - 0s - loss: 0.0221 - val_loss: 0.0175 - 42ms/epoch - 3ms/step\n",
      "Epoch 159/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0170 - 42ms/epoch - 4ms/step\n",
      "Epoch 160/400\n",
      "12/12 - 0s - loss: 0.0238 - val_loss: 0.0170 - 42ms/epoch - 3ms/step\n",
      "Epoch 161/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0169 - 42ms/epoch - 3ms/step\n",
      "Epoch 162/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0169 - 42ms/epoch - 3ms/step\n",
      "Epoch 163/400\n",
      "12/12 - 0s - loss: 0.0241 - val_loss: 0.0169 - 41ms/epoch - 3ms/step\n",
      "Epoch 164/400\n",
      "12/12 - 0s - loss: 0.0232 - val_loss: 0.0167 - 41ms/epoch - 3ms/step\n",
      "Epoch 165/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0168 - 42ms/epoch - 3ms/step\n",
      "Epoch 166/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0169 - 45ms/epoch - 4ms/step\n",
      "Epoch 167/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0173 - 42ms/epoch - 4ms/step\n",
      "Epoch 168/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0171 - 44ms/epoch - 4ms/step\n",
      "Epoch 169/400\n",
      "12/12 - 0s - loss: 0.0237 - val_loss: 0.0170 - 43ms/epoch - 4ms/step\n",
      "Epoch 170/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0172 - 41ms/epoch - 3ms/step\n",
      "Epoch 171/400\n",
      "12/12 - 0s - loss: 0.0246 - val_loss: 0.0173 - 41ms/epoch - 3ms/step\n",
      "Epoch 172/400\n",
      "12/12 - 0s - loss: 0.0232 - val_loss: 0.0169 - 43ms/epoch - 4ms/step\n",
      "Epoch 173/400\n",
      "12/12 - 0s - loss: 0.0232 - val_loss: 0.0168 - 42ms/epoch - 3ms/step\n",
      "Epoch 174/400\n",
      "12/12 - 0s - loss: 0.0250 - val_loss: 0.0165 - 39ms/epoch - 3ms/step\n",
      "Epoch 175/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0167 - 39ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/400\n",
      "12/12 - 0s - loss: 0.0249 - val_loss: 0.0172 - 45ms/epoch - 4ms/step\n",
      "Epoch 177/400\n",
      "12/12 - 0s - loss: 0.0237 - val_loss: 0.0175 - 39ms/epoch - 3ms/step\n",
      "Epoch 178/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0174 - 38ms/epoch - 3ms/step\n",
      "Epoch 179/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0172 - 39ms/epoch - 3ms/step\n",
      "Epoch 180/400\n",
      "12/12 - 0s - loss: 0.0241 - val_loss: 0.0170 - 40ms/epoch - 3ms/step\n",
      "Epoch 181/400\n",
      "12/12 - 0s - loss: 0.0250 - val_loss: 0.0178 - 42ms/epoch - 4ms/step\n",
      "Epoch 182/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0175 - 42ms/epoch - 3ms/step\n",
      "Epoch 183/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0173 - 42ms/epoch - 3ms/step\n",
      "Epoch 184/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0171 - 43ms/epoch - 4ms/step\n",
      "Epoch 185/400\n",
      "12/12 - 0s - loss: 0.0235 - val_loss: 0.0173 - 41ms/epoch - 3ms/step\n",
      "Epoch 186/400\n",
      "12/12 - 0s - loss: 0.0230 - val_loss: 0.0170 - 40ms/epoch - 3ms/step\n",
      "Epoch 187/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0171 - 42ms/epoch - 3ms/step\n",
      "Epoch 188/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0169 - 42ms/epoch - 4ms/step\n",
      "Epoch 189/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0171 - 42ms/epoch - 4ms/step\n",
      "Epoch 190/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0175 - 42ms/epoch - 4ms/step\n",
      "Epoch 191/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0170 - 44ms/epoch - 4ms/step\n",
      "Epoch 192/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0167 - 42ms/epoch - 4ms/step\n",
      "Epoch 193/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0165 - 41ms/epoch - 3ms/step\n",
      "Epoch 194/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0168 - 42ms/epoch - 3ms/step\n",
      "Epoch 195/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0168 - 42ms/epoch - 3ms/step\n",
      "Epoch 196/400\n",
      "12/12 - 0s - loss: 0.0243 - val_loss: 0.0169 - 43ms/epoch - 4ms/step\n",
      "Epoch 197/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0170 - 42ms/epoch - 4ms/step\n",
      "Epoch 198/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0168 - 43ms/epoch - 4ms/step\n",
      "Epoch 199/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0163 - 43ms/epoch - 4ms/step\n",
      "Epoch 200/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0167 - 42ms/epoch - 4ms/step\n",
      "Epoch 201/400\n",
      "12/12 - 0s - loss: 0.0230 - val_loss: 0.0166 - 42ms/epoch - 3ms/step\n",
      "Epoch 202/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0164 - 41ms/epoch - 3ms/step\n",
      "Epoch 203/400\n",
      "12/12 - 0s - loss: 0.0236 - val_loss: 0.0167 - 42ms/epoch - 3ms/step\n",
      "Epoch 204/400\n",
      "12/12 - 0s - loss: 0.0221 - val_loss: 0.0175 - 49ms/epoch - 4ms/step\n",
      "Epoch 205/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0167 - 52ms/epoch - 4ms/step\n",
      "Epoch 206/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0165 - 61ms/epoch - 5ms/step\n",
      "Epoch 207/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0165 - 41ms/epoch - 3ms/step\n",
      "Epoch 208/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0168 - 42ms/epoch - 3ms/step\n",
      "Epoch 209/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0163 - 52ms/epoch - 4ms/step\n",
      "Epoch 210/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0163 - 48ms/epoch - 4ms/step\n",
      "Epoch 211/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0162 - 52ms/epoch - 4ms/step\n",
      "Epoch 212/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0168 - 48ms/epoch - 4ms/step\n",
      "Epoch 213/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0165 - 50ms/epoch - 4ms/step\n",
      "Epoch 214/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0165 - 42ms/epoch - 3ms/step\n",
      "Epoch 215/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0160 - 42ms/epoch - 3ms/step\n",
      "Epoch 216/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 217/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0160 - 45ms/epoch - 4ms/step\n",
      "Epoch 218/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0161 - 41ms/epoch - 3ms/step\n",
      "Epoch 219/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0158 - 43ms/epoch - 4ms/step\n",
      "Epoch 220/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0160 - 39ms/epoch - 3ms/step\n",
      "Epoch 221/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0162 - 39ms/epoch - 3ms/step\n",
      "Epoch 222/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0160 - 39ms/epoch - 3ms/step\n",
      "Epoch 223/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0159 - 40ms/epoch - 3ms/step\n",
      "Epoch 224/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0160 - 41ms/epoch - 3ms/step\n",
      "Epoch 225/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0157 - 47ms/epoch - 4ms/step\n",
      "Epoch 226/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0157 - 44ms/epoch - 4ms/step\n",
      "Epoch 227/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0159 - 41ms/epoch - 3ms/step\n",
      "Epoch 228/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0161 - 41ms/epoch - 3ms/step\n",
      "Epoch 229/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0157 - 40ms/epoch - 3ms/step\n",
      "Epoch 230/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0157 - 40ms/epoch - 3ms/step\n",
      "Epoch 231/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0158 - 41ms/epoch - 3ms/step\n",
      "Epoch 232/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0159 - 42ms/epoch - 3ms/step\n",
      "Epoch 233/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0160 - 43ms/epoch - 4ms/step\n",
      "Epoch 234/400\n",
      "12/12 - 0s - loss: 0.0221 - val_loss: 0.0158 - 44ms/epoch - 4ms/step\n",
      "Epoch 235/400\n",
      "12/12 - 0s - loss: 0.0226 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 236/400\n",
      "12/12 - 0s - loss: 0.0246 - val_loss: 0.0161 - 41ms/epoch - 3ms/step\n",
      "Epoch 237/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0161 - 42ms/epoch - 4ms/step\n",
      "Epoch 238/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0164 - 41ms/epoch - 3ms/step\n",
      "Epoch 239/400\n",
      "12/12 - 0s - loss: 0.0234 - val_loss: 0.0161 - 42ms/epoch - 4ms/step\n",
      "Epoch 240/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0159 - 42ms/epoch - 3ms/step\n",
      "Epoch 241/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0161 - 43ms/epoch - 4ms/step\n",
      "Epoch 242/400\n",
      "12/12 - 0s - loss: 0.0221 - val_loss: 0.0158 - 44ms/epoch - 4ms/step\n",
      "Epoch 243/400\n",
      "12/12 - 0s - loss: 0.0214 - val_loss: 0.0166 - 43ms/epoch - 4ms/step\n",
      "Epoch 244/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0166 - 42ms/epoch - 4ms/step\n",
      "Epoch 245/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0167 - 41ms/epoch - 3ms/step\n",
      "Epoch 246/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0163 - 43ms/epoch - 4ms/step\n",
      "Epoch 247/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0160 - 42ms/epoch - 4ms/step\n",
      "Epoch 248/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0157 - 43ms/epoch - 4ms/step\n",
      "Epoch 249/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0160 - 43ms/epoch - 4ms/step\n",
      "Epoch 250/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0159 - 42ms/epoch - 4ms/step\n",
      "Epoch 251/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0158 - 42ms/epoch - 4ms/step\n",
      "Epoch 252/400\n",
      "12/12 - 0s - loss: 0.0231 - val_loss: 0.0157 - 44ms/epoch - 4ms/step\n",
      "Epoch 253/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0160 - 41ms/epoch - 3ms/step\n",
      "Epoch 254/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0156 - 41ms/epoch - 3ms/step\n",
      "Epoch 255/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0154 - 42ms/epoch - 3ms/step\n",
      "Epoch 256/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0159 - 42ms/epoch - 3ms/step\n",
      "Epoch 257/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0160 - 41ms/epoch - 3ms/step\n",
      "Epoch 258/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0154 - 45ms/epoch - 4ms/step\n",
      "Epoch 259/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0159 - 44ms/epoch - 4ms/step\n",
      "Epoch 260/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0156 - 42ms/epoch - 3ms/step\n",
      "Epoch 261/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 262/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0155 - 43ms/epoch - 4ms/step\n",
      "Epoch 263/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 264/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0158 - 39ms/epoch - 3ms/step\n",
      "Epoch 265/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0158 - 39ms/epoch - 3ms/step\n",
      "Epoch 266/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0159 - 40ms/epoch - 3ms/step\n",
      "Epoch 267/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 268/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0158 - 39ms/epoch - 3ms/step\n",
      "Epoch 269/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0159 - 39ms/epoch - 3ms/step\n",
      "Epoch 270/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0159 - 39ms/epoch - 3ms/step\n",
      "Epoch 271/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0161 - 42ms/epoch - 3ms/step\n",
      "Epoch 272/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0165 - 42ms/epoch - 4ms/step\n",
      "Epoch 273/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0159 - 41ms/epoch - 3ms/step\n",
      "Epoch 274/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0156 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0158 - 42ms/epoch - 4ms/step\n",
      "Epoch 276/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 277/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0155 - 44ms/epoch - 4ms/step\n",
      "Epoch 278/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0153 - 42ms/epoch - 4ms/step\n",
      "Epoch 279/400\n",
      "12/12 - 0s - loss: 0.0196 - val_loss: 0.0156 - 43ms/epoch - 4ms/step\n",
      "Epoch 280/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0160 - 44ms/epoch - 4ms/step\n",
      "Epoch 281/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0162 - 43ms/epoch - 4ms/step\n",
      "Epoch 282/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0169 - 43ms/epoch - 4ms/step\n",
      "Epoch 283/400\n",
      "12/12 - 0s - loss: 0.0246 - val_loss: 0.0164 - 42ms/epoch - 4ms/step\n",
      "Epoch 284/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0167 - 42ms/epoch - 4ms/step\n",
      "Epoch 285/400\n",
      "12/12 - 0s - loss: 0.0196 - val_loss: 0.0162 - 42ms/epoch - 4ms/step\n",
      "Epoch 286/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0159 - 43ms/epoch - 4ms/step\n",
      "Epoch 287/400\n",
      "12/12 - 0s - loss: 0.0220 - val_loss: 0.0163 - 43ms/epoch - 4ms/step\n",
      "Epoch 288/400\n",
      "12/12 - 0s - loss: 0.0242 - val_loss: 0.0167 - 42ms/epoch - 3ms/step\n",
      "Epoch 289/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0166 - 43ms/epoch - 4ms/step\n",
      "Epoch 290/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 291/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0155 - 44ms/epoch - 4ms/step\n",
      "Epoch 292/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0157 - 42ms/epoch - 3ms/step\n",
      "Epoch 293/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0160 - 41ms/epoch - 3ms/step\n",
      "Epoch 294/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0158 - 41ms/epoch - 3ms/step\n",
      "Epoch 295/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0156 - 42ms/epoch - 3ms/step\n",
      "Epoch 296/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0160 - 42ms/epoch - 3ms/step\n",
      "Epoch 297/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0163 - 44ms/epoch - 4ms/step\n",
      "Epoch 298/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0158 - 46ms/epoch - 4ms/step\n",
      "Epoch 299/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0152 - 43ms/epoch - 4ms/step\n",
      "Epoch 300/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 301/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 302/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0157 - 42ms/epoch - 4ms/step\n",
      "Epoch 303/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0156 - 42ms/epoch - 4ms/step\n",
      "Epoch 304/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0153 - 45ms/epoch - 4ms/step\n",
      "Epoch 305/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0155 - 43ms/epoch - 4ms/step\n",
      "Epoch 306/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0155 - 43ms/epoch - 4ms/step\n",
      "Epoch 307/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0154 - 42ms/epoch - 4ms/step\n",
      "Epoch 308/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0154 - 44ms/epoch - 4ms/step\n",
      "Epoch 309/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0154 - 40ms/epoch - 3ms/step\n",
      "Epoch 310/400\n",
      "12/12 - 0s - loss: 0.0225 - val_loss: 0.0153 - 39ms/epoch - 3ms/step\n",
      "Epoch 311/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0150 - 38ms/epoch - 3ms/step\n",
      "Epoch 312/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0154 - 41ms/epoch - 3ms/step\n",
      "Epoch 313/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0151 - 41ms/epoch - 3ms/step\n",
      "Epoch 314/400\n",
      "12/12 - 0s - loss: 0.0190 - val_loss: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 315/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0150 - 38ms/epoch - 3ms/step\n",
      "Epoch 316/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0148 - 39ms/epoch - 3ms/step\n",
      "Epoch 317/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0154 - 41ms/epoch - 3ms/step\n",
      "Epoch 318/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0150 - 42ms/epoch - 4ms/step\n",
      "Epoch 319/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0148 - 42ms/epoch - 3ms/step\n",
      "Epoch 320/400\n",
      "12/12 - 0s - loss: 0.0218 - val_loss: 0.0151 - 42ms/epoch - 4ms/step\n",
      "Epoch 321/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0149 - 42ms/epoch - 4ms/step\n",
      "Epoch 322/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0149 - 42ms/epoch - 3ms/step\n",
      "Epoch 323/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0151 - 43ms/epoch - 4ms/step\n",
      "Epoch 324/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0152 - 43ms/epoch - 4ms/step\n",
      "Epoch 325/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0155 - 42ms/epoch - 4ms/step\n",
      "Epoch 326/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 327/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0149 - 43ms/epoch - 4ms/step\n",
      "Epoch 328/400\n",
      "12/12 - 0s - loss: 0.0208 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 329/400\n",
      "12/12 - 0s - loss: 0.0193 - val_loss: 0.0153 - 41ms/epoch - 3ms/step\n",
      "Epoch 330/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0153 - 51ms/epoch - 4ms/step\n",
      "Epoch 331/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0150 - 43ms/epoch - 4ms/step\n",
      "Epoch 332/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0151 - 42ms/epoch - 3ms/step\n",
      "Epoch 333/400\n",
      "12/12 - 0s - loss: 0.0193 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 334/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0151 - 45ms/epoch - 4ms/step\n",
      "Epoch 335/400\n",
      "12/12 - 0s - loss: 0.0183 - val_loss: 0.0155 - 42ms/epoch - 4ms/step\n",
      "Epoch 336/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0152 - 41ms/epoch - 3ms/step\n",
      "Epoch 337/400\n",
      "12/12 - 0s - loss: 0.0201 - val_loss: 0.0156 - 44ms/epoch - 4ms/step\n",
      "Epoch 338/400\n",
      "12/12 - 0s - loss: 0.0187 - val_loss: 0.0156 - 43ms/epoch - 4ms/step\n",
      "Epoch 339/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0154 - 42ms/epoch - 4ms/step\n",
      "Epoch 340/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 341/400\n",
      "12/12 - 0s - loss: 0.0212 - val_loss: 0.0156 - 44ms/epoch - 4ms/step\n",
      "Epoch 342/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0155 - 42ms/epoch - 4ms/step\n",
      "Epoch 343/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0155 - 41ms/epoch - 3ms/step\n",
      "Epoch 344/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 345/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0151 - 43ms/epoch - 4ms/step\n",
      "Epoch 346/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 347/400\n",
      "12/12 - 0s - loss: 0.0193 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 348/400\n",
      "12/12 - 0s - loss: 0.0188 - val_loss: 0.0153 - 44ms/epoch - 4ms/step\n",
      "Epoch 349/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0156 - 43ms/epoch - 4ms/step\n",
      "Epoch 350/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0157 - 42ms/epoch - 4ms/step\n",
      "Epoch 351/400\n",
      "12/12 - 0s - loss: 0.0199 - val_loss: 0.0156 - 43ms/epoch - 4ms/step\n",
      "Epoch 352/400\n",
      "12/12 - 0s - loss: 0.0211 - val_loss: 0.0154 - 42ms/epoch - 4ms/step\n",
      "Epoch 353/400\n",
      "12/12 - 0s - loss: 0.0215 - val_loss: 0.0160 - 44ms/epoch - 4ms/step\n",
      "Epoch 354/400\n",
      "12/12 - 0s - loss: 0.0224 - val_loss: 0.0150 - 42ms/epoch - 3ms/step\n",
      "Epoch 355/400\n",
      "12/12 - 0s - loss: 0.0227 - val_loss: 0.0152 - 40ms/epoch - 3ms/step\n",
      "Epoch 356/400\n",
      "12/12 - 0s - loss: 0.0229 - val_loss: 0.0162 - 40ms/epoch - 3ms/step\n",
      "Epoch 357/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0157 - 41ms/epoch - 3ms/step\n",
      "Epoch 358/400\n",
      "12/12 - 0s - loss: 0.0228 - val_loss: 0.0155 - 39ms/epoch - 3ms/step\n",
      "Epoch 359/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0155 - 40ms/epoch - 3ms/step\n",
      "Epoch 360/400\n",
      "12/12 - 0s - loss: 0.0217 - val_loss: 0.0154 - 40ms/epoch - 3ms/step\n",
      "Epoch 361/400\n",
      "12/12 - 0s - loss: 0.0195 - val_loss: 0.0154 - 41ms/epoch - 3ms/step\n",
      "Epoch 362/400\n",
      "12/12 - 0s - loss: 0.0191 - val_loss: 0.0153 - 45ms/epoch - 4ms/step\n",
      "Epoch 363/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0154 - 43ms/epoch - 4ms/step\n",
      "Epoch 364/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 365/400\n",
      "12/12 - 0s - loss: 0.0192 - val_loss: 0.0154 - 43ms/epoch - 4ms/step\n",
      "Epoch 366/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 367/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0157 - 44ms/epoch - 4ms/step\n",
      "Epoch 368/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 369/400\n",
      "12/12 - 0s - loss: 0.0205 - val_loss: 0.0149 - 44ms/epoch - 4ms/step\n",
      "Epoch 370/400\n",
      "12/12 - 0s - loss: 0.0219 - val_loss: 0.0153 - 43ms/epoch - 4ms/step\n",
      "Epoch 371/400\n",
      "12/12 - 0s - loss: 0.0216 - val_loss: 0.0152 - 44ms/epoch - 4ms/step\n",
      "Epoch 372/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0146 - 43ms/epoch - 4ms/step\n",
      "Epoch 373/400\n",
      "12/12 - 0s - loss: 0.0214 - val_loss: 0.0150 - 43ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/400\n",
      "12/12 - 0s - loss: 0.0197 - val_loss: 0.0149 - 42ms/epoch - 3ms/step\n",
      "Epoch 375/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0148 - 43ms/epoch - 4ms/step\n",
      "Epoch 376/400\n",
      "12/12 - 0s - loss: 0.0194 - val_loss: 0.0154 - 43ms/epoch - 4ms/step\n",
      "Epoch 377/400\n",
      "12/12 - 0s - loss: 0.0223 - val_loss: 0.0154 - 42ms/epoch - 4ms/step\n",
      "Epoch 378/400\n",
      "12/12 - 0s - loss: 0.0233 - val_loss: 0.0149 - 43ms/epoch - 4ms/step\n",
      "Epoch 379/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0148 - 42ms/epoch - 3ms/step\n",
      "Epoch 380/400\n",
      "12/12 - 0s - loss: 0.0213 - val_loss: 0.0149 - 42ms/epoch - 3ms/step\n",
      "Epoch 381/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0153 - 44ms/epoch - 4ms/step\n",
      "Epoch 382/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0149 - 44ms/epoch - 4ms/step\n",
      "Epoch 383/400\n",
      "12/12 - 0s - loss: 0.0186 - val_loss: 0.0148 - 42ms/epoch - 3ms/step\n",
      "Epoch 384/400\n",
      "12/12 - 0s - loss: 0.0206 - val_loss: 0.0148 - 42ms/epoch - 3ms/step\n",
      "Epoch 385/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0151 - 41ms/epoch - 3ms/step\n",
      "Epoch 386/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0151 - 42ms/epoch - 4ms/step\n",
      "Epoch 387/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0154 - 44ms/epoch - 4ms/step\n",
      "Epoch 388/400\n",
      "12/12 - 0s - loss: 0.0200 - val_loss: 0.0150 - 42ms/epoch - 4ms/step\n",
      "Epoch 389/400\n",
      "12/12 - 0s - loss: 0.0203 - val_loss: 0.0153 - 44ms/epoch - 4ms/step\n",
      "Epoch 390/400\n",
      "12/12 - 0s - loss: 0.0196 - val_loss: 0.0149 - 63ms/epoch - 5ms/step\n",
      "Epoch 391/400\n",
      "12/12 - 0s - loss: 0.0222 - val_loss: 0.0151 - 43ms/epoch - 4ms/step\n",
      "Epoch 392/400\n",
      "12/12 - 0s - loss: 0.0189 - val_loss: 0.0152 - 42ms/epoch - 4ms/step\n",
      "Epoch 393/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0148 - 44ms/epoch - 4ms/step\n",
      "Epoch 394/400\n",
      "12/12 - 0s - loss: 0.0202 - val_loss: 0.0147 - 44ms/epoch - 4ms/step\n",
      "Epoch 395/400\n",
      "12/12 - 0s - loss: 0.0207 - val_loss: 0.0151 - 43ms/epoch - 4ms/step\n",
      "Epoch 396/400\n",
      "12/12 - 0s - loss: 0.0204 - val_loss: 0.0153 - 46ms/epoch - 4ms/step\n",
      "Epoch 397/400\n",
      "12/12 - 0s - loss: 0.0198 - val_loss: 0.0151 - 44ms/epoch - 4ms/step\n",
      "Epoch 398/400\n",
      "12/12 - 0s - loss: 0.0214 - val_loss: 0.0148 - 42ms/epoch - 3ms/step\n",
      "Epoch 399/400\n",
      "12/12 - 0s - loss: 0.0210 - val_loss: 0.0147 - 41ms/epoch - 3ms/step\n",
      "Epoch 400/400\n",
      "12/12 - 0s - loss: 0.0209 - val_loss: 0.0147 - 39ms/epoch - 3ms/step\n",
      "COMPRESSED VECTOR SIZE: 3\n",
      "Loss in the autoencoder: 0.01473930012434721\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "##preparing data\n",
    "from modnet.preprocessing import MODData\n",
    "data=MODData.load('../DATAFILES/matbench_perovskites_moddata.pkl.gz')\n",
    "## partial data to test\n",
    "Xtoencode=data.df_featurized.filter(regex=\"Atomic*\").sample(200,random_state=1)\n",
    "y = data.df_targets['e_form'].sample(200,random_state=1)\n",
    "## full data for script\n",
    "# Xtoencode=data.df_featurized\n",
    "# y = data.df_targets['e_form']\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtoencode, y, test_size=0.1, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# number of input columns\n",
    "n_inputs = Xtoencode.shape[1]\n",
    "results=[]\n",
    "name_encoder=\"PerovskitesMODNet\"\n",
    "with open(f'EncoderResults_{name_encoder}.txt', 'w') as f:\n",
    "    f.write(f'''# Training {name_encoder} # Initial Number of Features: {n_inputs}\n",
    "n_bottleneck_ratio n_bottleneck train_loss val_loss\\n''')\n",
    "for n_bottleneck_ratio in list(np.arange(1,0,-0.2)):\n",
    "    # define encoder\n",
    "    visible = Input(shape=(n_inputs,))\n",
    "    e = Dense(n_inputs*2)(visible)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = ReLU()(e)\n",
    "    # define bottleneck\n",
    "    n_bottleneck = int(n_inputs*n_bottleneck_ratio)\n",
    "    print(f\"Compressed layer size: {n_bottleneck}\")\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    # define decoder\n",
    "    d = Dense(n_inputs*2)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = ReLU()(d)\n",
    "    # output layer\n",
    "    output = Dense(n_inputs, activation='linear')(d)\n",
    "    # define autoencoder model\n",
    "    model = Model(inputs=visible, outputs=output)\n",
    "    # compile autoencoder model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # model.summary()\n",
    "    # fit the autoencoder model to reconstruct input\n",
    "    history = model.fit(X_train, X_train, epochs=400, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "    # plot loss\n",
    "    print(f\"COMPRESSED VECTOR SIZE: {n_bottleneck}\")    \n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    print(f\"Loss in the autoencoder: {history.history['val_loss'][-1]}\")\n",
    "    results=(np.round(n_bottleneck_ratio,3), n_bottleneck, \n",
    "             history.history['loss'][-1], history.history['val_loss'][-1])\n",
    "    with open(f'EncoderResults_{name_encoder}.txt', 'a') as f:\n",
    "        f.write(' '.join(map(str,results)))\n",
    "        f.write('\\n')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig(f\"{name_encoder}_{np.round(n_bottleneck_ratio,2)}.png\")\n",
    "    pyplot.clf()\n",
    "    # define an encoder model (without the decoder)\n",
    "    encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "    # plot_model(encoder, 'encoder.png', show_shapes=True)\n",
    "    # save the encoder to file\n",
    "    encoder.save(f'encoder_compressionratio_{np.round(n_bottleneck_ratio,2)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c7124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "554639a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "rm: cannot remove 'results.txt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1364105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011666204780340195"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906a8a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8839b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9222356 , -1.1342809 ,  1.9126492 , ...,  0.8987368 ,\n",
       "         -0.6316383 ,  1.3506067 ],\n",
       "        [ 0.30656615, -2.7538586 , -0.21310006, ..., -0.14656411,\n",
       "         -1.0240393 , -0.65034515],\n",
       "        [ 0.17662506, -2.204924  , -0.07599185, ..., -0.56000376,\n",
       "         -1.2530621 , -0.12195865],\n",
       "        ...,\n",
       "        [ 0.9638708 , -1.5714529 ,  1.1597657 , ...,  1.1572444 ,\n",
       "         -0.4189967 , -0.7472342 ],\n",
       "        [ 0.8436815 , -2.9039395 , -0.6101377 , ..., -0.2877049 ,\n",
       "         -1.3820343 , -1.1874201 ],\n",
       "        [ 0.8935609 , -1.2426273 ,  2.698875  , ...,  1.0865065 ,\n",
       "         -2.5131147 ,  2.1531916 ]], dtype=float32),\n",
       " array([[ 0.5868315 , -1.783126  ,  1.7621084 , ..., -0.2391154 ,\n",
       "         -1.2371608 ,  1.7642552 ],\n",
       "        [ 0.09818484, -1.1204567 ,  1.044807  , ...,  0.64768916,\n",
       "         -1.6107126 ,  1.6020889 ],\n",
       "        [ 0.8476728 , -1.8304179 ,  1.6455642 , ...,  1.5488914 ,\n",
       "         -0.91954654, -1.4548612 ],\n",
       "        ...,\n",
       "        [ 0.7731933 , -2.1887553 ,  0.25559998, ...,  0.07350025,\n",
       "         -0.8387626 , -0.5877008 ],\n",
       "        [ 0.10646848, -1.9288805 ,  0.21007782, ...,  0.34231177,\n",
       "         -1.0043197 , -0.69137233],\n",
       "        [ 1.127653  , -2.0882468 ,  1.246875  , ...,  2.3152735 ,\n",
       "         -1.6930703 ,  2.403849  ]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "X_train_encode, X_test_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abaf12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_feat=featurizer.featurize_dataframe(data.df_structure.iloc[[5530]], 'structure')\n",
    "# #df_feat, \n",
    "# def nspec(x):\n",
    "#     return len(x.species)\n",
    "# data.df_structure['species']= data.df_structure['structure'].apply(nspec) #.iloc[5530].values[0].species\n",
    "# data.df_structure['species'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfbdf11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in [(1.2,2,3),(1.2,2,3),(1.2,2,3)]:\n",
    "    with open('results.txt', 'a') as f:\n",
    "        f.write(' '.join(map(str,results)))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09e2dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/c/Users/roger/Documents/programas/UCLouvain/env_modnet/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "1.2 2 31.2 2 31.2 2 31.2 2 3\r\n",
      "1.2 2 3\r\n",
      "1.2 2 3\r\n"
     ]
    }
   ],
   "source": [
    "!cat results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20cb0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 3.930170626613603 3.930170626613603 3.930170626613603\n",
       " angles : 90.0 90.0 90.0\n",
       " volume : 60.706363276205764\n",
       "      A : 3.930170626613603 0.0 0.0\n",
       "      B : 0.0 3.930170626613603 0.0\n",
       "      C : 0.0 0.0 3.930170626613603\n",
       "PeriodicSite: Ta (2.6090, 3.9302, 0.0000) [0.6638, 1.0000, 0.0000]\n",
       "PeriodicSite: Ga (0.0259, 1.9651, 1.9651) [0.0066, 0.5000, 0.5000]\n",
       "PeriodicSite: N (3.5263, 3.9302, 1.9651) [0.8972, 1.0000, 0.5000]\n",
       "PeriodicSite: N (3.5263, 1.9651, 3.9302) [0.8972, 0.5000, 1.0000]\n",
       "PeriodicSite: N (1.9054, 1.9651, 1.9651) [0.4848, 0.5000, 0.5000]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "data.df_structure.iloc[5529]['structure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ad8b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique=np.array([112,313,145,222,233])\n",
    "# ex0=np.array([0.2,0.5])\n",
    "# ex=np.array([112,145])\n",
    "# zeros=np.zeros(len(unique))\n",
    "\n",
    "# toinsert=np.nonzero(np.in1d(unique,ex))[0]\n",
    "# unique,ex,ex0,zeros,toinsert\n",
    "# zeros[toinsert]=ex0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
